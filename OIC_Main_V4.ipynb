{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "800fb403-e420-4880-bc3d-e94769a87c6c",
   "metadata": {},
   "source": [
    "# Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5c0974",
   "metadata": {},
   "source": [
    "### **Summary of the Deployment**\n",
    "\n",
    "This deployment incorporates a robust and efficient Federated Learning (FL) system that leverages advanced techniques to address challenges in large-scale, decentralized IoT networks. Hereâ€™s an overview of the entire system:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Device Clustering Using GNN-KMeans**\n",
    "- **Objective**: Cluster devices into logical groups based on their data distribution, device characteristics, and network constraints.\n",
    "- **Process**:\n",
    "  - A **Graph Neural Network (GNN)** is used to model the relationship between devices, capturing both their features and interconnectivity.\n",
    "  - A **KMeans clustering algorithm** operates on the embeddings generated by the GNN, grouping devices with similar characteristics.\n",
    "  - Clusters represent groups of devices that share common traits, enabling efficient resource allocation and training at the edge level.\n",
    "- **Outcome**: Devices are assigned to clusters, ensuring devices with similar data and characteristics are grouped, which reduces variance in model aggregation and improves performance.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Hybrid Data Redistribution**\n",
    "- **Objective**: Balance the data distribution across devices within a cluster to enhance the representativeness of local models.\n",
    "- **Process**:\n",
    "  - Devices within a cluster exchange a portion of their local datasets based on a **hybrid redistribution policy**.\n",
    "  - A **threshold-based strategy** ensures that redistribution prioritizes devices with less diverse data while maintaining privacy constraints.\n",
    "  - Label diversity and sample quantity are considered during redistribution to improve local model training.\n",
    "- **Outcome**: Each device within a cluster holds a more balanced dataset, reducing model bias and improving global model accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Device Assignment Using DRL PPO**\n",
    "- **Objective**: Optimize the assignment of devices to edge servers and the scheduling of active devices for FL tasks.\n",
    "- **Key Steps**:\n",
    "  - **Cluster Assignment**:\n",
    "    - A **Deep Reinforcement Learning (DRL)** agent, using the **Proximal Policy Optimization (PPO)** algorithm, determines the best edge server for each cluster based on available bandwidth and server capacity.\n",
    "    - The goal is to minimize load imbalance and maximize resource utilization across edge servers.\n",
    "  - **Device Scheduling**:\n",
    "    - A second DRL PPO agent selects the optimal subset of devices within each cluster to participate in training.\n",
    "    - Scheduling decisions consider factors such as energy usage, bandwidth availability, and data diversity.\n",
    "- **Outcome**:\n",
    "  - Efficient utilization of edge server resources and reduced communication overhead.\n",
    "  - Active devices are strategically chosen to improve model training efficiency and accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Semi-Synchronous Federated Learning**\n",
    "- **Objective**: Combine the benefits of synchronous and asynchronous training to balance efficiency and performance.\n",
    "- **Key Features**:\n",
    "  - **Edge-Level Independence**:\n",
    "    - Each edge server trains its devices sequentially but independently of other edge servers.\n",
    "    - Training on edge devices incorporates **device-specific characteristics** like CPU power and memory.\n",
    "  - **Synchronous Aggregation**:\n",
    "    - After training, all devices within an edge server aggregate their models synchronously.\n",
    "    - The aggregated models from edge servers are then sent to the cloud for global aggregation.\n",
    "  - **Dynamic Adaptation**:\n",
    "    - Device characteristics (e.g., energy, bandwidth) are dynamically updated after each global iteration.\n",
    "    - Device assignments and schedules are recalculated using the trained DRL agents.\n",
    "- **Outcome**:\n",
    "  - Reduced global synchronization bottlenecks due to edge-level independence.\n",
    "  - Enhanced scalability and adaptability for large-scale IoT networks.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Key Innovations and Metrics**\n",
    "#### **CPU and Memory Effects in Training**\n",
    "- Local training accounts for device-specific CPU power and memory capacity, influencing:\n",
    "  - Batch size (larger for devices with higher memory).\n",
    "  - Training time (faster for devices with higher CPU power).\n",
    "  - Energy consumption (lower for devices with efficient CPUs).\n",
    "\n",
    "#### **Concurrency Control**\n",
    "- Limits the number of concurrently active edge servers during training, ensuring resource constraints are respected.\n",
    "\n",
    "#### **Comprehensive Metrics**\n",
    "- Tracks and logs **energy consumption**, **time delays**, and **bandwidth usage** across devices, edge servers, and the cloud.\n",
    "- Metrics are saved as JSON files for analysis and debugging.\n",
    "\n",
    "---\n",
    "\n",
    "### **System Workflow**\n",
    "1. **Data Distribution**:\n",
    "   - Data is distributed across devices, followed by clustering using GNN-KMeans.\n",
    "2. **Data Balancing**:\n",
    "   - Hybrid redistribution balances data within clusters.\n",
    "3. **Device Assignment**:\n",
    "   - DRL PPO agents assign clusters to edge servers and schedule active devices.\n",
    "4. **Training**:\n",
    "   - Each edge server independently trains its devices.\n",
    "   - Models are aggregated at the edge and then globally in a semi-synchronous manner.\n",
    "5. **Dynamic Adaptation**:\n",
    "   - Device assignments and schedules are updated after each global iteration.\n",
    "6. **Metrics Logging**:\n",
    "   - Energy, time, and bandwidth metrics are tracked and saved for analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### **Benefits of the System**\n",
    "- **Efficiency**:\n",
    "  - Optimized use of computational resources at devices and edge servers.\n",
    "  - Reduced communication costs and delays.\n",
    "- **Scalability**:\n",
    "  - Supports large-scale IoT networks with diverse devices and dynamic conditions.\n",
    "- **Accuracy**:\n",
    "  - Balanced data distribution and optimal scheduling enhance global model performance.\n",
    "- **Adaptability**:\n",
    "  - Dynamic adjustments in device assignments and training configurations ensure sustained performance in changing environments.\n",
    "\n",
    "---\n",
    "\n",
    "This deployment demonstrates the integration of state-of-the-art techniques to create a scalable and adaptive Federated Learning system tailored for decentralized IoT networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcd6cb3",
   "metadata": {},
   "source": [
    "# Gap & Weaknesses \n",
    "\n",
    "---\n",
    "\n",
    "### **1. Gaps in Device Clustering**\n",
    "- **Dynamic Clustering**: \n",
    "  - The current clustering approach is static, performed at the initial stage. This assumes that device characteristics remain constant throughout the process. However, real-world IoT devices often experience dynamic changes in energy levels, connectivity, or data characteristics.\n",
    "  - **Improvement**: Implement periodic re-clustering or incremental updates to clusters as device characteristics change over time.\n",
    "\n",
    "- **Limited Clustering Criteria**:\n",
    "  - GNN-KMeans primarily focuses on predefined features like data similarity, energy, and bandwidth. It does not account for latent patterns or new relationships that may emerge during training.\n",
    "  - **Improvement**: Introduce more sophisticated clustering methods, such as self-organizing maps or adaptive GNNs, to capture evolving patterns.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Gaps in Hybrid Data Redistribution**\n",
    "- **Privacy Concerns**:\n",
    "  - Although data redistribution enhances diversity, it may lead to privacy concerns if sensitive data is shared, even partially.\n",
    "  - **Improvement**: Introduce differential privacy mechanisms to ensure that data redistribution does not compromise user privacy.\n",
    "\n",
    "- **Data Heterogeneity**:\n",
    "  - Redistribution assumes that sharing data samples improves diversity, but it may not adequately handle devices with fundamentally skewed data distributions (e.g., devices with single-label datasets).\n",
    "  - **Improvement**: Include a more robust mechanism to detect and address extreme data heterogeneity using synthetic data generation or federated augmentation.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Weaknesses in Device Assignment Using DRL PPO**\n",
    "- **Training Overhead**:\n",
    "  - Training DRL agents for cluster assignment and device scheduling introduces computational overhead, particularly if the system requires frequent retraining due to dynamic conditions.\n",
    "  - **Improvement**: Explore lightweight or offline RL models that are faster to train and deploy in dynamic environments.\n",
    "\n",
    "- **Single Objective Optimization**:\n",
    "  - The current DRL approach optimizes resource utilization and scheduling but does not account for multi-objective trade-offs, such as fairness in device participation or minimizing latency for specific applications.\n",
    "  - **Improvement**: Extend the DRL framework to support multi-objective optimization with trade-offs between fairness, latency, and resource efficiency.\n",
    "\n",
    "- **Scalability Issues**:\n",
    "  - As the number of devices and clusters increases, the action space for DRL agents grows exponentially, making training and decision-making more complex.\n",
    "  - **Improvement**: Use hierarchical DRL or distributed RL frameworks to handle large-scale deployments more effectively.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Weaknesses in Semi-Synchronous Federated Learning**\n",
    "- **Limited Parallelism at Edge**:\n",
    "  - The concurrency control limits the number of edge servers that can train simultaneously. While this ensures resource constraints are respected, it can reduce overall training efficiency in underutilized environments.\n",
    "  - **Improvement**: Introduce dynamic concurrency based on resource availability, allowing more edge servers to operate in low-load conditions.\n",
    "\n",
    "- **Device-Specific Constraints**:\n",
    "  - The system now considers CPU power and memory for batch size and training time, but it does not fully address device-specific constraints like hardware failures, intermittent connectivity, or overheating.\n",
    "  - **Improvement**: Incorporate failure detection and mitigation strategies, such as proactive device handover or redundant training on backup devices.\n",
    "\n",
    "- **Synchronization Delays**:\n",
    "  - Semi-synchronous aggregation requires edge servers to wait for slow devices within their cluster, potentially leading to bottlenecks.\n",
    "  - **Improvement**: Introduce straggler mitigation techniques, such as partial aggregation or stale model updates, to reduce delays.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Gaps in Metrics and Monitoring**\n",
    "- **Lack of Real-Time Feedback**:\n",
    "  - Metrics are logged and saved but do not provide real-time feedback or visualization for dynamic decision-making.\n",
    "  - **Improvement**: Implement a real-time monitoring dashboard to visualize energy, time, and bandwidth usage, helping operators make proactive adjustments.\n",
    "\n",
    "- **Limited Metrics Granularity**:\n",
    "  - Current metrics focus on high-level energy, time, and bandwidth usage but lack detailed insights into individual device contributions or network bottlenecks.\n",
    "  - **Improvement**: Add more granular metrics, such as per-device latency, packet loss, or model divergence, for detailed analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Potential Weaknesses in Energy Efficiency**\n",
    "- **High Communication Overhead**:\n",
    "  - While communication energy is calculated, the frequent exchange of model updates during aggregation can still be expensive in large-scale deployments.\n",
    "  - **Improvement**: Use model compression techniques like quantization, sparsification, or knowledge distillation to reduce communication costs.\n",
    "\n",
    "- **Unbalanced Energy Usage**:\n",
    "  - Devices with higher energy reserves are not prioritized for participation, potentially leading to early dropouts of low-energy devices.\n",
    "  - **Improvement**: Implement energy-aware scheduling to balance the energy consumption across devices and prolong the overall system lifetime.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Weaknesses in Security and Privacy**\n",
    "- **Vulnerability to Model Poisoning**:\n",
    "  - The system does not explicitly address the risk of malicious devices introducing poisoned updates during model aggregation.\n",
    "  - **Improvement**: Introduce defense mechanisms like robust aggregation techniques (e.g., median aggregation) or anomaly detection for updates.\n",
    "\n",
    "- **Data Privacy Compliance**:\n",
    "  - While the system ensures data remains on devices, the hybrid redistribution may conflict with privacy regulations like GDPR if not properly managed.\n",
    "  - **Improvement**: Ensure compliance with privacy laws by integrating secure multi-party computation or federated differential privacy.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Gaps in Adaptability and Scalability**\n",
    "- **Edge Server Scalability**:\n",
    "  - The system assumes a fixed number of edge servers, which may not scale well as the number of devices grows.\n",
    "  - **Improvement**: Introduce dynamic edge server provisioning, where additional edge servers can be deployed as needed.\n",
    "\n",
    "- **Cloud Aggregation Bottleneck**:\n",
    "  - The cloud server becomes a single point of aggregation, potentially leading to delays in large-scale systems.\n",
    "  - **Improvement**: Use a hierarchical aggregation structure, where intermediate aggregators reduce the load on the central cloud server.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary of Gaps and Weaknesses**\n",
    "While the current system demonstrates innovative features and significant performance gains, addressing the gaps mentioned above will further enhance its robustness, scalability, and adaptability. Future improvements should focus on dynamic clustering, advanced data redistribution, multi-objective DRL optimization, enhanced privacy and security measures, and real-time monitoring to make the system more resilient and efficient in real-world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f28b19",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "| **Step**                           | **Metrics**                                                                                         | **Description**                                                                                               |\n",
    "|-------------------------------------|-----------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------|\n",
    "| **1. Device Clustering**            | - **Intra-Cluster Similarity**                                                                      | Measures similarity of devices within a cluster based on characteristics (e.g., hardware, datasets).         |\n",
    "|                                     | - **Inter-Cluster Separation**                                                                     | Measures distinction between clusters to ensure clear boundaries.                                             |\n",
    "|                                     | - **Time to Cluster**                                                                              | Time taken to cluster devices dynamically.                                                                    |\n",
    "|                                     | - **Energy Consumption**                                                                           | Energy used by devices during clustering (e.g., for communication or feature extraction).                     |\n",
    "|                                     | - **Cluster Size Balance**                                                                         | Checks if clusters are balanced in size or data diversity.                                                    |\n",
    "|                                     | - **Communication Overhead**                                                                       | Measures data exchanged during clustering (e.g., device features).                                            |\n",
    "| **2. Hybrid Data Redistribution**   | - **Dataset Label Distribution**                                                                   | Tracks the uniformity of specific labels across clusters.                                                     |\n",
    "|                                     | - **Data Transfer Time**                                                                           | Time required to transfer datasets between devices.                                                           |\n",
    "|                                     | - **Energy Consumption**                                                                           | Energy used by devices for transferring data.                                                                 |\n",
    "|                                     | - **Communication Bandwidth Utilization**                                                          | Measures bandwidth usage during data redistribution.                                                          |\n",
    "|                                     | - **Redundancy Reduction**                                                                         | Assesses whether redundant data copies have been minimized.                                                   |\n",
    "|                                     | - **Data Quality**                                                                                 | Evaluates if data is corrupted or degraded during redistribution.                                             |\n",
    "| **3. Resource Allocation**          | - **Edge Server Load**                                                                             | Tracks the current load (CPU, memory, bandwidth) on each edge server.                                         |\n",
    "|                                     | - **Device-Edge Latency**                                                                          | Measures the delay between devices and their assigned edge servers.                                           |\n",
    "|                                     | - **Energy Consumption**                                                                           | Energy used for communication and computation during allocation.                                              |\n",
    "|                                     | - **Bandwidth Utilization**                                                                        | Tracks how well edge server bandwidth is being used.                                                          |\n",
    "|                                     | - **Fairness Index**                                                                               | Ensures equal resource distribution across devices and servers.                                               |\n",
    "|                                     | - **Resource Utilization Efficiency**                                                              | Percentage of available resources (e.g., CPU, memory) effectively utilized.                                   |\n",
    "|                                     | - **Mapping Accuracy**                                                                             | Evaluates how well the resource allocation matches device needs.                                              |\n",
    "| **4. Federated Learning**           | - **Model Accuracy**                                                                               | Tracks the performance of the global model.                                                                   |\n",
    "|                                     | - **Convergence Speed**                                                                            | Measures how quickly the global model converges to an optimal state.                                          |\n",
    "|                                     | - **Communication Rounds**                                                                         | Number of communication rounds required to reach a certain accuracy.                                          |\n",
    "|                                     | - **Device Contribution Diversity**                                                                | Evaluates the diversity of data contributions from devices.                                                   |\n",
    "|                                     | - **Energy Consumption**                                                                           | Energy used during model training and communication.                                                          |\n",
    "|                                     | - **Straggler Count**                                                                              | Number of slow devices causing delays in training.                                                            |\n",
    "|                                     | - **Latency (Device-Edge, Edge-Cloud)**                                                            | Measures delays in transferring model updates between layers.                                                 |\n",
    "|                                     | - **Resource Utilization (Edge and Cloud)**                                                        | Monitors CPU, memory, and storage usage at edge and cloud levels.                                             |\n",
    "|                                     | - **Training Completion Time**                                                                     | Overall time taken to complete a training iteration.                                                          |\n",
    "|                                     | - **Global Model Stability**                                                                       | Tracks stability in model updates to avoid oscillations.                                                      |\n",
    "\n",
    "---\n",
    "\n",
    "### **How Metrics Interrelate**\n",
    "- **Clustering Metrics** directly influence **Redistribution Metrics**, as well-formed clusters lead to efficient data balancing.\n",
    "- **Resource Allocation Metrics** depend on the output of clustering and redistribution to allocate resources optimally.\n",
    "- **Federated Learning Metrics** are influenced by all previous steps, as better clustering, redistribution, and allocation enhance training efficiency.\n",
    "\n",
    "Using these metrics allows you to identify bottlenecks, monitor real-time performance, and ensure efficient system operation. Moreover, you can feed these metrics as part of the **state** in your **DRL framework** for adaptive optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13961c7",
   "metadata": {},
   "source": [
    "## **1. Device Clustering**\n",
    "\n",
    "### **Metrics:**\n",
    "\n",
    "1. **Clustering Quality Metrics:**\n",
    "   - **Silhouette Score:**\n",
    "     - Measures how similar a device is to its own cluster compared to other clusters.\n",
    "     - **Range:** -1 (incorrect clustering) to +1 (ideal clustering).\n",
    "   - **Davies-Bouldin Index (DBI):**\n",
    "     - Evaluates intra-cluster similarity and inter-cluster differences.\n",
    "     - **Lower values** indicate better clustering.\n",
    "   - **Calinski-Harabasz Index (CHI):**\n",
    "     - Ratio of between-cluster dispersion to within-cluster dispersion.\n",
    "     - **Higher values** indicate better-defined clusters.\n",
    "\n",
    "2. **Cluster Size Distribution:**\n",
    "   - **Number of Devices per Cluster:**\n",
    "     - Shows how devices are distributed among clusters.\n",
    "   - **Cluster Imbalance Ratio:**\n",
    "     - Ratio of sizes between the largest and smallest clusters.\n",
    "\n",
    "3. **Cluster Feature Statistics:**\n",
    "   - **Within-Cluster Variance:**\n",
    "     - Variance of device features (e.g., CPU power, memory) within each cluster.\n",
    "   - **Between-Cluster Variance:**\n",
    "     - Variance of cluster centroids to assess distinctiveness.\n",
    "\n",
    "4. **Visualization Metrics:**\n",
    "   - **t-SNE or PCA Projections:**\n",
    "     - Visual representation of high-dimensional data in 2D or 3D space.\n",
    "     - Devices colored by cluster assignments.\n",
    "\n",
    "### **Plots:**\n",
    "\n",
    "- **Bar Chart:** Number of devices per cluster.\n",
    "- **Box Plot:** Feature distributions (e.g., energy usage) within clusters.\n",
    "- **Silhouette Plot:** Silhouette scores for each device.\n",
    "- **Scatter Plot (t-SNE/PCA):** Visualizing clusters in reduced dimensions.\n",
    "\n",
    "### **Examples:**\n",
    "\n",
    "1. **Cluster Size Distribution Plot:**\n",
    "\n",
    "   <img src=\"https://example.com/cluster_size_distribution.png\" alt=\"Cluster Size Distribution\" width=\"400\"/>\n",
    "\n",
    "2. **Silhouette Scores Plot:**\n",
    "\n",
    "   <img src=\"https://example.com/silhouette_scores.png\" alt=\"Silhouette Scores\" width=\"400\"/>\n",
    "\n",
    "3. **t-SNE Visualization:**\n",
    "\n",
    "   <img src=\"https://example.com/tsne_clusters.png\" alt=\"t-SNE Clusters\" width=\"400\"/>\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Data Redistribution**\n",
    "\n",
    "### **Metrics:**\n",
    "\n",
    "1. **Data Distribution Metrics:**\n",
    "   - **Label Distribution per Device (Before and After):**\n",
    "     - Proportion of samples for each label on each device.\n",
    "   - **Average Label Entropy:**\n",
    "     - Measures diversity of labels on devices.\n",
    "     - **Higher entropy** indicates more balanced label distribution.\n",
    "\n",
    "2. **Redistribution Effectiveness:**\n",
    "   - **Kullback-Leibler (KL) Divergence:**\n",
    "     - Quantifies the difference between device label distributions and the global distribution.\n",
    "   - **Total Data Transferred:**\n",
    "     - Amount of data moved during redistribution.\n",
    "\n",
    "3. **Resource Impact:**\n",
    "   - **Change in Device Data Volume:**\n",
    "     - Number of samples before and after redistribution.\n",
    "   - **Energy and Bandwidth Consumption:**\n",
    "     - Resources used during data redistribution.\n",
    "\n",
    "### **Plots:**\n",
    "\n",
    "- **Histogram:** Label distribution per device before and after redistribution.\n",
    "- **Box Plot:** Entropy of label distributions across devices.\n",
    "- **Line Plot:** KL divergence over iterations (if redistribution is iterative).\n",
    "- **Heatmap:** Device-to-device data transfer matrix.\n",
    "\n",
    "### **Examples:**\n",
    "\n",
    "1. **Label Distribution Histogram (Before and After):**\n",
    "\n",
    "   <img src=\"https://example.com/label_distribution.png\" alt=\"Label Distribution\" width=\"400\"/>\n",
    "\n",
    "2. **Entropy Box Plot:**\n",
    "\n",
    "   <img src=\"https://example.com/entropy_boxplot.png\" alt=\"Label Entropy\" width=\"400\"/>\n",
    "\n",
    "3. **KL Divergence Over Time:**\n",
    "\n",
    "   <img src=\"https://example.com/kl_divergence.png\" alt=\"KL Divergence\" width=\"400\"/>\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Device Assignment**\n",
    "\n",
    "### **Metrics:**\n",
    "\n",
    "1. **Edge Server Load Metrics:**\n",
    "   - **Number of Devices per Edge Server:**\n",
    "     - Shows load distribution across edge servers.\n",
    "   - **Edge Server Capacity Utilization:**\n",
    "     - Ratio of assigned load to edge server capacity.\n",
    "   - **Load Variance:**\n",
    "     - Variance in the number of devices or total bandwidth per edge server.\n",
    "\n",
    "2. **Scheduling Metrics:**\n",
    "   - **Scheduled vs. Unscheduled Devices:**\n",
    "     - Counts and percentages of devices participating in training.\n",
    "   - **Average Device Resources:**\n",
    "     - Mean CPU power, memory, energy, and bandwidth of scheduled devices.\n",
    "\n",
    "3. **Assignment Efficiency Metrics:**\n",
    "   - **Resource Utilization Efficiency:**\n",
    "     - Comparison of actual resource usage against maximum available.\n",
    "   - **Assignment Optimality Score:**\n",
    "     - Evaluated using custom criteria or baseline comparisons.\n",
    "\n",
    "### **Plots:**\n",
    "\n",
    "- **Bar Chart:** Number of devices assigned to each edge server.\n",
    "- **Pie Chart:** Proportion of scheduled vs. unscheduled devices.\n",
    "- **Stacked Bar Chart:** Resource usage per edge server.\n",
    "- **Heatmap:** Edge server capacity utilization.\n",
    "\n",
    "### **Examples:**\n",
    "\n",
    "1. **Edge Server Load Bar Chart:**\n",
    "\n",
    "   <img src=\"https://example.com/edge_server_load.png\" alt=\"Edge Server Load\" width=\"400\"/>\n",
    "\n",
    "2. **Device Scheduling Pie Chart:**\n",
    "\n",
    "   <img src=\"https://example.com/device_scheduling.png\" alt=\"Device Scheduling\" width=\"400\"/>\n",
    "\n",
    "3. **Resource Utilization Heatmap:**\n",
    "\n",
    "   <img src=\"https://example.com/resource_utilization.png\" alt=\"Resource Utilization\" width=\"400\"/>\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Federated Learning**\n",
    "\n",
    "### **Metrics:**\n",
    "\n",
    "1. **Performance Metrics:**\n",
    "   - **Global Model Accuracy Over Iterations:**\n",
    "     - Test accuracy after each global aggregation.\n",
    "   - **Edge Model Accuracies:**\n",
    "     - Validation accuracy at each edge server before global aggregation.\n",
    "   - **Local Model Accuracies:**\n",
    "     - Training accuracy on devices after local epochs.\n",
    "\n",
    "2. **Convergence Metrics:**\n",
    "   - **Loss Over Time:**\n",
    "     - Training loss on devices, edge servers, and global model.\n",
    "   - **Accuracy vs. Communication Rounds:**\n",
    "     - Relationship between model performance and number of communication rounds.\n",
    "\n",
    "3. **Resource Consumption Metrics:**\n",
    "   - **Energy Consumption:**\n",
    "     - Total energy used by devices, edge servers, and cloud server.\n",
    "     - Energy consumption per iteration.\n",
    "   - **Time Delays:**\n",
    "     - Computation and communication time at each level.\n",
    "     - Total time per global iteration.\n",
    "   - **Bandwidth Usage:**\n",
    "     - Amount of data transmitted during model updates.\n",
    "     - Bandwidth used per iteration.\n",
    "\n",
    "4. **Participation Metrics:**\n",
    "   - **Active Devices per Iteration:**\n",
    "     - Number of devices participating in each global iteration.\n",
    "   - **Device Dropout Rate:**\n",
    "     - Percentage of devices that fail or drop out over time.\n",
    "\n",
    "5. **System Efficiency Metrics:**\n",
    "   - **Training Speed:**\n",
    "     - Time taken to reach specific accuracy thresholds.\n",
    "   - **Communication Efficiency:**\n",
    "     - Model accuracy achieved per unit of data transmitted.\n",
    "\n",
    "### **Plots:**\n",
    "\n",
    "- **Line Plot:** Global accuracy over iterations.\n",
    "- **Loss Curve:** Global and edge model loss over iterations.\n",
    "- **Bar Chart:** Energy consumption per iteration.\n",
    "- **Stacked Area Chart:** Bandwidth usage over time.\n",
    "- **Scatter Plot:** Energy consumption vs. accuracy.\n",
    "- **Box Plot:** Time delays across devices or edge servers.\n",
    "\n",
    "### **Examples:**\n",
    "\n",
    "1. **Global Accuracy Over Iterations:**\n",
    "\n",
    "   <img src=\"https://example.com/global_accuracy.png\" alt=\"Global Accuracy\" width=\"400\"/>\n",
    "\n",
    "2. **Energy Consumption Bar Chart:**\n",
    "\n",
    "   <img src=\"https://example.com/energy_consumption.png\" alt=\"Energy Consumption\" width=\"400\"/>\n",
    "\n",
    "3. **Bandwidth Usage Stacked Area Chart:**\n",
    "\n",
    "   <img src=\"https://example.com/bandwidth_usage.png\" alt=\"Bandwidth Usage\" width=\"400\"/>\n",
    "\n",
    "4. **Participation Rate Line Plot:**\n",
    "\n",
    "   <img src=\"https://example.com/participation_rate.png\" alt=\"Participation Rate\" width=\"400\"/>\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Additional Metrics and Comparisons**\n",
    "\n",
    "### **Scalability Metrics:**\n",
    "\n",
    "- **Performance vs. Number of Devices:**\n",
    "  - Analyze how increasing the number of devices affects accuracy, training time, and resource consumption.\n",
    "\n",
    "- **Communication Overhead:**\n",
    "  - Total data transmitted as the network scales.\n",
    "\n",
    "### **Comparative Analysis:**\n",
    "\n",
    "- **Baseline Comparisons:**\n",
    "  - Compare your system's metrics with baseline methods (e.g., centralized training, traditional FL without optimizations).\n",
    "\n",
    "- **Impact of Device Characteristics:**\n",
    "  - Correlate device-specific metrics (e.g., CPU power, memory) with local training performance.\n",
    "\n",
    "### **Plots:**\n",
    "\n",
    "- **Line Plot:** Accuracy vs. number of devices.\n",
    "- **Bar Chart:** Communication overhead for different scaling scenarios.\n",
    "- **Correlation Matrix:** Relationships between device characteristics and performance.\n",
    "\n",
    "---\n",
    "\n",
    "## **Implementing and Visualizing Metrics**\n",
    "\n",
    "To effectively collect and visualize these metrics:\n",
    "\n",
    "1. **Logging and Storage:**\n",
    "   - Implement logging mechanisms at each step to record metrics.\n",
    "   - Use structured formats (e.g., JSON, CSV) for easy data manipulation.\n",
    "\n",
    "2. **Data Analysis Tools:**\n",
    "   - Utilize data analysis libraries like **Pandas** for data manipulation.\n",
    "   - Employ **Matplotlib** or **Seaborn** for plotting.\n",
    "   - For interactive visualizations, consider **Plotly** or **Bokeh**.\n",
    "\n",
    "3. **Reproducibility:**\n",
    "   - Ensure that experiments are conducted under controlled settings to make fair comparisons.\n",
    "   - Document hyperparameters and configurations for each run.\n",
    "\n",
    "4. **Reporting:**\n",
    "   - Summarize findings in reports or dashboards.\n",
    "   - Highlight key improvements or insights gained from the metrics.\n",
    "\n",
    "---\n",
    "\n",
    "## **Example Workflow for Generating Plots**\n",
    "\n",
    "1. **Collect Metrics:**\n",
    "\n",
    "   ```python\n",
    "   # Example: Collecting global accuracy over iterations\n",
    "   global_accuracies = federated_system.accuracies['global_iterations']\n",
    "   iterations = list(range(1, len(global_accuracies) + 1))\n",
    "   ```\n",
    "\n",
    "2. **Plot Metrics:**\n",
    "\n",
    "   ```python\n",
    "   import matplotlib.pyplot as plt\n",
    "\n",
    "   # Plotting Global Accuracy Over Iterations\n",
    "   plt.figure(figsize=(10, 6))\n",
    "   plt.plot(iterations, global_accuracies, marker='o')\n",
    "   plt.title('Global Model Accuracy Over Iterations')\n",
    "   plt.xlabel('Global Iteration')\n",
    "   plt.ylabel('Accuracy (%)')\n",
    "   plt.grid(True)\n",
    "   plt.show()\n",
    "   ```\n",
    "\n",
    "3. **Save Plots:**\n",
    "\n",
    "   ```python\n",
    "   plt.savefig('global_accuracy_over_iterations.png')\n",
    "   ```\n",
    "\n",
    "4. **Analyze Results:**\n",
    "   - Interpret the trends observed in the plots.\n",
    "   - Identify any anomalies or unexpected behaviors.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "By systematically collecting and visualizing these metrics, you can gain deep insights into each component of your federated learning system. This allows you to:\n",
    "\n",
    "- **Validate** the effectiveness of each step.\n",
    "- **Identify** areas for improvement.\n",
    "- **Demonstrate** the advantages of your approach over baseline methods.\n",
    "- **Communicate** your findings to stakeholders through clear and informative visualizations.\n",
    "\n",
    "Remember to tailor the metrics and plots to align with your specific objectives and the aspects of the system you wish to highlight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb4b6c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Scenario-Based Explanation of Dynamic Device Assignment Using PPO in Federated Learning**\n",
    "\n",
    "Imagine you are managing a large-scale **Federated Learning (FL)** system deployed across multiple **Edge Servers** and numerous **Devices** (like smartphones, IoT devices, etc.). Your goal is to efficiently distribute computational tasks to these edge servers and devices to optimize performance metrics such as **accuracy**, **energy consumption**, and **communication costs**. To achieve this, you employ **Deep Reinforcement Learning (DRL)** techniques, specifically **Proximal Policy Optimization (PPO)**, to dynamically assign clusters of devices to edge servers and further schedule individual devices within these clusters.\n",
    "\n",
    "Let's walk through how each component of your system works together in this scenario.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Understanding the Environment: The Real-World Setup**\n",
    "\n",
    "**Entities Involved:**\n",
    "- **Devices:** Each device has unique characteristics like **bandwidth usage**, **energy consumption**, **memory**, and **CPU power**.\n",
    "- **Clusters:** Devices are grouped into clusters based on certain criteria (e.g., geographical location, data similarity).\n",
    "- **Edge Servers:** These servers handle computational tasks for the devices. Each edge server has a limited **capacity** in terms of **bandwidth** and **computational resources**.\n",
    "\n",
    "**Objective:**\n",
    "- **Cluster Assignment:** Assign each cluster of devices to an appropriate edge server such that the server's capacity is optimally utilized without overloading.\n",
    "- **Device Scheduling:** Within each cluster, dynamically assign individual devices to edge servers to further optimize performance metrics.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Cluster Assignment with PPO: Assigning Clusters to Edge Servers**\n",
    "\n",
    "**Environment Setup: `ClusterAssignmentEnv`**\n",
    "\n",
    "- **Purpose:** This environment simulates the process of assigning clusters of devices to edge servers. The PPO agent learns to make optimal assignments based on the current state of the system.\n",
    "\n",
    "**Key Components:**\n",
    "\n",
    "1. **State Representation:**\n",
    "   - **Normalized Bandwidth:** Represents the bandwidth requirements of each cluster, normalized to ensure numerical stability.\n",
    "   - **Normalized Capacities:** Reflects the capacity of each edge server, also normalized.\n",
    "   - **Unused Capacities:** Indicates how much capacity remains unused on each server after assignments.\n",
    "\n",
    "2. **Action Space:**\n",
    "   - **MultiDiscrete Actions:** Each action corresponds to assigning a cluster to one of the available edge servers. If there are `N` clusters and `M` edge servers, the action space is a vector of length `N`, where each element can take a value from `0` to `M-1` (representing the server IDs).\n",
    "\n",
    "3. **Reward Function:**\n",
    "   - **Overload Penalty:** Penalizes assignments that exceed an edge server's capacity.\n",
    "   - **Load Variance Penalty:** Discourages imbalanced load distributions across servers.\n",
    "   - **Resource Utilization Incentive:** Rewards assignments that maximize the usage of available resources without overloading.\n",
    "   \n",
    "   The reward is a weighted combination of these factors, encouraging the PPO agent to find assignments that are balanced, efficient, and within capacity constraints.\n",
    "\n",
    "**Training Process:**\n",
    "\n",
    "- **Initialization:** The environment initializes with the current bandwidth requirements of clusters and the capacities of edge servers.\n",
    "- **Learning:** The PPO agent interacts with this environment, making assignments and receiving rewards based on the effectiveness of those assignments.\n",
    "- **Optimization:** Over multiple iterations (`timesteps`), the agent learns policies that maximize cumulative rewards, effectively learning to assign clusters to servers optimally.\n",
    "\n",
    "**Deployment:**\n",
    "\n",
    "Once trained, the **Cluster Assignment Agent** can predict the best cluster-to-server assignments for new or dynamic configurations of devices and servers.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Device Scheduling with PPO: Dynamically Assigning Devices Within Clusters**\n",
    "\n",
    "**Environment Setup: `DeviceSchedulingEnv`**\n",
    "\n",
    "- **Purpose:** After clusters are assigned to specific edge servers, this environment handles the dynamic assignment of individual devices within those clusters to the designated servers. The PPO agent optimizes device scheduling to further enhance performance metrics.\n",
    "\n",
    "**Key Components:**\n",
    "\n",
    "1. **State Representation:**\n",
    "   - **Normalized Bandwidth Usage:** Represents the bandwidth consumption of each device.\n",
    "   - **Normalized Energy Usage:** Reflects the energy consumption of each device.\n",
    "   - **Diversity Scores:** Calculated using entropy to measure the heterogeneity of data labels each device possesses, normalized between `[0, 1]`.\n",
    "\n",
    "2. **Action Space:**\n",
    "   - **MultiBinary Actions:** Each action represents whether a device is selected (`1`) or not (`0`) for scheduling. The action space is a binary vector where each element corresponds to a device.\n",
    "\n",
    "3. **Reward Function:**\n",
    "   - **Accuracy Improvement:** Rewards the selection of devices that contribute to improving the global model's accuracy.\n",
    "   - **Communication Cost Penalty:** Penalizes the total bandwidth used for communication.\n",
    "   - **Energy Consumption Penalty:** Penalizes the total energy consumed by the selected devices.\n",
    "\n",
    "   The reward function balances the benefits of selecting devices that enhance model accuracy against the costs associated with their bandwidth and energy usage.\n",
    "\n",
    "**Training Process:**\n",
    "\n",
    "- **Initialization:** The environment is initialized with device characteristics and the static `cluster_to_server_map`.\n",
    "- **Learning:** The PPO agent learns to select devices that offer the best trade-off between improving model accuracy and minimizing costs.\n",
    "- **Optimization:** Through extensive training (`timesteps`), the agent fine-tunes its policies to make effective scheduling decisions.\n",
    "\n",
    "**Deployment:**\n",
    "\n",
    "The **Device Scheduling Agent** can dynamically decide which devices within each cluster should participate in training rounds, adapting to changes in device availability, energy levels, or network conditions.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Orchestrating Assignments: The Role of `MainAgent`**\n",
    "\n",
    "**Class Overview: `MainAgent`**\n",
    "\n",
    "- **Purpose:** Acts as the central coordinator that integrates both the Cluster Assignment and Device Scheduling agents. It manages the overall workflow, ensuring that clusters are assigned to edge servers and devices are scheduled appropriately before initiating the federated learning process.\n",
    "\n",
    "**Key Functions:**\n",
    "\n",
    "1. **Initialization:**\n",
    "   - **Data Preparation:** Aggregates device bandwidth requirements and determines edge server capacities.\n",
    "   - **Environment Creation:** Sets up both `ClusterAssignmentEnv` and `DeviceSchedulingEnv` with the necessary parameters.\n",
    "   - **Agent Loading:** Loads the trained PPO agents for cluster assignment and device scheduling.\n",
    "\n",
    "2. **Run Method:**\n",
    "   - **Cluster Assignment:**\n",
    "     - **State Reset:** Resets the cluster assignment environment to get the initial state.\n",
    "     - **Action Prediction:** Uses the Cluster Assignment Agent to predict the best assignments of clusters to edge servers.\n",
    "     - **DataFrame Update:** Updates the `devices_df` with the predicted `assigned_servers` based on cluster assignments.\n",
    "   \n",
    "   - **Device Scheduling:**\n",
    "     - **State Reset:** Resets the device scheduling environment to get the initial state.\n",
    "     - **Action Prediction:** Uses the Device Scheduling Agent to decide which devices to schedule for participation.\n",
    "     - **DataFrame Update:** Updates the `devices_df` with the `is_scheduled` flag based on scheduling decisions.\n",
    "   \n",
    "   - **Federated Learning Integration:**\n",
    "     - **Parameter Preparation:** Extracts necessary parameters for the federated learning system.\n",
    "     - **System Initialization:** Initializes the `FederatedLearningSystem` with the updated device assignments and scheduling information.\n",
    "     - **Learning Execution:** Initiates the federated learning process, which involves training global models based on the scheduled devices and assigned clusters.\n",
    "\n",
    "**Deployment:**\n",
    "\n",
    "When `MainAgent.run()` is called, it seamlessly integrates the cluster and device assignments into the federated learning workflow, ensuring that each training round is optimized based on current system states and learned policies.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Deploying Dynamic Device Assignment: Step-by-Step Workflow**\n",
    "\n",
    "**Step 1: Configuration and Initialization**\n",
    "\n",
    "- **Configurations:** Define different setups for experiments, specifying parameters like the number of devices, edge servers, dataset names, and iteration counts.\n",
    "- **Metrics Directory:** Create a dedicated folder to store performance metrics for analysis.\n",
    "\n",
    "**Step 2: Data Distribution and Clustering**\n",
    "\n",
    "- **Data Distributor (`GNNClustering`):**\n",
    "  - **Distribute Data:** Allocates data to devices based on the specified dataset.\n",
    "  - **Clustering Devices:** Groups devices into clusters using Graph Neural Networks (GNN) or other clustering methods.\n",
    "\n",
    "**Step 3: Hybrid Data Redistribution**\n",
    "\n",
    "- **Data Redistributor (`HybridDataRedistributor`):**\n",
    "  - **Redistribute Data:** Adjusts data distribution among devices to balance workloads and ensure diversity, based on a percentage threshold.\n",
    "\n",
    "**Step 4: Training the Cluster Assignment Agent**\n",
    "\n",
    "- **Bandwidth and Capacity Calculation:**\n",
    "  - **Cluster Bandwidth:** Sum of bandwidth requirements for each cluster.\n",
    "  - **Edge Server Capacities:** Determined based on total bandwidth needed and individual server capabilities.\n",
    "  \n",
    "- **Agent Training (`train_cluster_assignment_agent`):**\n",
    "  - **Environment Setup:** Initializes `ClusterAssignmentEnv` with current cluster bandwidths and edge server capacities.\n",
    "  - **PPO Training:** Trains the PPO agent to learn optimal cluster-to-server assignments.\n",
    "  - **Model Saving:** Saves the trained Cluster Assignment Agent for future use.\n",
    "  \n",
    "- **Cluster-to-Server Map Generation:**\n",
    "  - **Prediction:** Uses the trained agent to predict the best assignments.\n",
    "  - **Mapping:** Creates a dictionary mapping each cluster to its assigned edge server.\n",
    "\n",
    "**Step 5: Training the Device Scheduling Agent**\n",
    "\n",
    "- **Agent Training (`train_device_scheduling_agent`):**\n",
    "  - **Environment Setup:** Initializes `DeviceSchedulingEnv` with device data and the static `cluster_to_server_map`.\n",
    "  - **PPO Training:** Trains the PPO agent to learn optimal device scheduling within clusters.\n",
    "  - **Model Saving:** Saves the trained Device Scheduling Agent for future use.\n",
    "\n",
    "**Step 6: Orchestrating with MainAgent**\n",
    "\n",
    "- **Initialization:**\n",
    "  - **Agent Loading:** Loads both the Cluster Assignment and Device Scheduling agents.\n",
    "  - **Environment Creation:** Sets up the respective environments with the necessary mappings.\n",
    "  \n",
    "- **Execution:**\n",
    "  - **Cluster Assignment:** Uses the Cluster Assignment Agent to assign clusters to servers.\n",
    "  - **Device Scheduling:** Uses the Device Scheduling Agent to schedule devices within clusters.\n",
    "  - **Federated Learning Integration:** Passes the assignments and schedules to the `FederatedLearningSystem` and initiates training.\n",
    "\n",
    "**Step 7: Federated Learning Execution**\n",
    "\n",
    "- **FederatedLearningSystem:**\n",
    "  - **Local Training:** Devices train local models based on assignments and schedules.\n",
    "  - **Edge Aggregation:** Edge servers aggregate models from their assigned devices.\n",
    "  - **Global Aggregation:** The cloud server aggregates models from all edge servers to update the global model.\n",
    "  - **Evaluation:** Periodically evaluates the global model's accuracy and logs performance metrics.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Deploying Dynamic Device Assignment: Detailed Process**\n",
    "\n",
    "Let's visualize how dynamic device assignment is deployed using the provided code through a comprehensive scenario.\n",
    "\n",
    "**Scenario:**  \n",
    "You are deploying an FL system for the **MNIST** dataset with **20 devices** distributed across **5 edge servers**. Each device has varying bandwidth and energy profiles. Your goal is to optimize the assignment of clusters and devices to edge servers to achieve high model accuracy while minimizing communication costs and energy consumption.\n",
    "\n",
    "**Workflow Steps:**\n",
    "\n",
    "1. **Setup and Configuration:**\n",
    "   - **Define Configuration:** Specify parameters such as the number of devices, edge servers, dataset, and iteration counts.\n",
    "   - **Initialize Metrics Directory:** Create a folder (`metrics/`) to store training metrics for each configuration.\n",
    "\n",
    "2. **Data Distribution and Clustering:**\n",
    "   - **Initialize `GNNClustering`:**\n",
    "     - Distribute the MNIST dataset among 20 devices.\n",
    "     - Cluster the devices into 5 clusters based on data characteristics using GNN-based clustering.\n",
    "   - **Redistribute Data:**\n",
    "     - Use `HybridDataRedistributor` to balance data distribution among devices, ensuring diversity and load balancing.\n",
    "\n",
    "3. **Cluster Assignment:**\n",
    "   - **Calculate Bandwidth and Capacities:**\n",
    "     - Sum the bandwidth requirements for each cluster.\n",
    "     - Determine edge server capacities based on total bandwidth needs and server capabilities.\n",
    "   - **Train Cluster Assignment Agent:**\n",
    "     - Initialize `ClusterAssignmentEnv` with current cluster bandwidths and server capacities.\n",
    "     - Train the PPO agent using `train_cluster_assignment_agent`, allowing it to learn optimal cluster-to-server assignments over 10,000 timesteps.\n",
    "     - Save the trained Cluster Assignment Agent for future predictions.\n",
    "   - **Generate Cluster-to-Server Map:**\n",
    "     - Use the trained agent to predict assignments.\n",
    "     - Create a mapping dictionary that assigns each cluster to a specific edge server.\n",
    "\n",
    "4. **Device Scheduling:**\n",
    "   - **Train Device Scheduling Agent:**\n",
    "     - Initialize `DeviceSchedulingEnv` with device data and the static `cluster_to_server_map`.\n",
    "     - Train the PPO agent using `train_device_scheduling_agent` over 10,000 timesteps to learn optimal device scheduling within clusters.\n",
    "     - Save the trained Device Scheduling Agent.\n",
    "\n",
    "5. **Orchestrate Assignments with `MainAgent`:**\n",
    "   - **Initialize `MainAgent`:**\n",
    "     - Load both the Cluster Assignment and Device Scheduling agents.\n",
    "     - Set up environments with the current device data and cluster-to-server mappings.\n",
    "   - **Run Assignments and Federated Learning:**\n",
    "     - **Cluster Assignment:** Assign clusters to edge servers using the Cluster Assignment Agent.\n",
    "     - **Device Scheduling:** Schedule devices within clusters using the Device Scheduling Agent.\n",
    "     - **Initialize Federated Learning:** Pass the assignments and schedules to `FederatedLearningSystem`.\n",
    "     - **Execute Federated Learning:** Start the training process, where devices train local models, edge servers aggregate them, and the global model is updated iteratively.\n",
    "\n",
    "6. **Federated Learning Execution:**\n",
    "   - **Local Model Training:**\n",
    "     - Each scheduled device trains its local model based on assigned data and device-specific configurations.\n",
    "     - Track and log energy consumption and communication costs.\n",
    "   - **Edge Server Aggregation:**\n",
    "     - Edge servers aggregate models from their assigned devices, considering communication costs and energy metrics.\n",
    "     - Perform multiple edge iterations before global aggregation.\n",
    "   - **Global Model Aggregation:**\n",
    "     - The cloud server aggregates models from all edge servers to update the global model.\n",
    "     - Evaluate the global model's accuracy using the test dataset.\n",
    "     - Log performance metrics and save summaries for analysis.\n",
    "\n",
    "7. **Dynamic Adaptation:**\n",
    "   - **Device Characteristics Update:**\n",
    "     - After each global iteration, simulate changes in device energy and bandwidth profiles to reflect real-world dynamics.\n",
    "   - **Reassignment:**\n",
    "     - Re-run the Cluster Assignment and Device Scheduling agents to adapt to the updated device states.\n",
    "     - Ensure that assignments remain optimal as device conditions evolve.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Key Benefits of This Deployment Approach**\n",
    "\n",
    "- **Optimized Resource Utilization:**\n",
    "  - **Cluster Assignment:** Ensures that each edge server is assigned clusters in a way that maximizes resource utilization without overloading any server.\n",
    "  - **Device Scheduling:** Dynamically selects devices that contribute most effectively to model training, balancing accuracy improvements against energy and communication costs.\n",
    "\n",
    "- **Scalability and Flexibility:**\n",
    "  - The system can easily scale to accommodate more devices or edge servers by adjusting configurations and retraining the PPO agents as needed.\n",
    "  - Dynamic adaptation allows the system to respond to changes in device availability or network conditions in real-time.\n",
    "\n",
    "- **Enhanced Performance Metrics:**\n",
    "  - By leveraging DRL, the system continuously learns and improves its assignment strategies, leading to higher model accuracies and lower operational costs over time.\n",
    "\n",
    "- **Modular Design:**\n",
    "  - The separation of cluster assignment and device scheduling into distinct environments and agents promotes modularity, making the system easier to maintain and extend.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Practical Considerations for Deployment**\n",
    "\n",
    "**A. Training Considerations:**\n",
    "\n",
    "- **Training Duration:** PPO agents require substantial training (`timesteps=10,000` in your case) to learn effective policies. Ensure sufficient computational resources and time.\n",
    "- **Environment Accuracy:** The state representations and reward functions must accurately reflect real-world conditions to guide the PPO agents effectively.\n",
    "- **Reward Balancing:** Properly balance the reward components to ensure that agents prioritize critical metrics (e.g., accuracy over energy consumption).\n",
    "\n",
    "**B. System Integration:**\n",
    "\n",
    "- **Agent Synchronization:** Ensure that both Cluster Assignment and Device Scheduling agents are trained and loaded correctly before initiating federated learning.\n",
    "- **Error Handling:** Implement robust error handling, especially in multi-threaded environments (e.g., during edge server training) to prevent failures from cascading.\n",
    "\n",
    "**C. Real-Time Adaptation:**\n",
    "\n",
    "- **Dynamic Updates:** The system should periodically reassess and update assignments based on changing device states to maintain optimal performance.\n",
    "- **Feedback Loops:** Incorporate feedback mechanisms to continuously monitor performance metrics and trigger retraining or adjustments as necessary.\n",
    "\n",
    "**D. Monitoring and Logging:**\n",
    "\n",
    "- **Metrics Tracking:** Consistently log key metrics like model accuracy, energy consumption, communication costs, and assignment efficiencies for analysis and debugging.\n",
    "- **Visualization:** Utilize dashboards or visualization tools to monitor the system's performance in real-time, facilitating quick responses to issues or inefficiencies.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Conclusion**\n",
    "\n",
    "Deploying dynamic device assignment in a federated learning system using PPO-based DRL agents involves a well-coordinated interplay between cluster assignment and device scheduling. By leveraging the strengths of PPO in optimizing complex decision-making processes, your system can achieve efficient resource utilization, adapt to dynamic environments, and maintain high model accuracies while minimizing operational costs.\n",
    "\n",
    "This scenario-based approach provides a comprehensive understanding of how each component functions and interacts within the system, ensuring that your federated learning deployment is both effective and resilient.\n",
    "\n",
    "Feel free to reach out if you need further clarifications or assistance with specific aspects of your deployment!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a82e7",
   "metadata": {},
   "source": [
    "Certainly! Let's explore **Proximal Policy Optimization (PPO)**, a prominent algorithm in the field of **Deep Reinforcement Learning (DRL)**, and understand how it's seamlessly integrated into your federated learning system through your provided code. This explanation will cover the foundational aspects of PPO and elucidate its specific implementation within your clustering and device scheduling environments.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Understanding Proximal Policy Optimization (PPO)**\n",
    "\n",
    "### **1.1. What is Proximal Policy Optimization (PPO)?**\n",
    "\n",
    "**Proximal Policy Optimization (PPO)** is a type of **policy gradient** algorithm in reinforcement learning, introduced by OpenAI as a more efficient and stable alternative to earlier methods like Trust Region Policy Optimization (TRPO). PPO is designed to optimize the policyâ€”the strategy by which an agent selects actionsâ€”while ensuring that updates to the policy are neither too drastic nor too conservative.\n",
    "\n",
    "### **1.2. Key Features of PPO**\n",
    "\n",
    "1. **Clipping Mechanism:**\n",
    "   - PPO introduces a **clipping** strategy that restricts the policy updates to stay within a small, predefined range. This prevents the new policy from deviating excessively from the old policy, enhancing training stability.\n",
    "\n",
    "2. **Surrogate Objective Function:**\n",
    "   - PPO optimizes a **surrogate objective** that balances between improving the policy and maintaining proximity to the previous policy. This dual focus helps in efficient learning without large policy shifts.\n",
    "\n",
    "3. **Sample Efficiency:**\n",
    "   - Unlike some algorithms that require fresh data for each update, PPO can reuse the same batch of data multiple times (through multiple epochs) to update the policy, making it more sample-efficient.\n",
    "\n",
    "4. **Ease of Implementation:**\n",
    "   - PPO is relatively straightforward to implement compared to more complex algorithms, while still achieving high performance across a variety of tasks.\n",
    "\n",
    "### **1.3. Why Choose PPO?**\n",
    "\n",
    "- **Stability:** The clipping mechanism ensures that policy updates remain within a \"proximal\" region, preventing unstable or divergent learning.\n",
    "- **Performance:** PPO consistently delivers strong performance across diverse environments and tasks.\n",
    "- **Flexibility:** It is versatile, working effectively with both discrete and continuous action spaces.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. PPO in the Context of Your Federated Learning System**\n",
    "\n",
    "Your federated learning system involves optimizing two critical components:\n",
    "\n",
    "1. **Cluster Assignment:** Deciding which clusters of devices should be assigned to which edge servers.\n",
    "2. **Device Scheduling:** Selecting which devices should participate in the training process at any given time.\n",
    "\n",
    "Both of these components are formulated as reinforcement learning problems, where PPO serves as the underlying algorithm to learn optimal policies for decision-making.\n",
    "\n",
    "### **2.1. Cluster Assignment with PPO**\n",
    "\n",
    "- **Environment:** The `ClusterAssignmentEnv` simulates the scenario where clusters of devices need to be assigned to edge servers based on factors like bandwidth and server capacities.\n",
    "  \n",
    "- **Agent:** A PPO-based agent interacts with this environment to learn how to assign clusters to servers optimally. The agent observes the current state of server loads, bandwidth requirements, and capacities, then decides on assignments that maximize overall system efficiency.\n",
    "\n",
    "- **Reward Function:** The reward is crafted to encourage:\n",
    "  - **High Resource Utilization:** Maximizing the use of server capacities.\n",
    "  - **Minimizing Overload:** Avoiding assignments that exceed server capacities.\n",
    "  - **Balancing Load:** Ensuring that server loads are evenly distributed to prevent bottlenecks.\n",
    "\n",
    "### **2.2. Device Scheduling with PPO**\n",
    "\n",
    "- **Environment:** The `DeviceSchedulingEnv` models the process of selecting devices for participation in training. It considers device-specific metrics like bandwidth usage and energy consumption.\n",
    "\n",
    "- **Agent:** Another PPO-based agent operates within this environment to determine which devices should be active in the training process, balancing the trade-off between improving model accuracy and conserving resources.\n",
    "\n",
    "- **Reward Function:** The reward structure incentivizes:\n",
    "  - **Accuracy Improvement:** Selecting more devices can lead to better model performance.\n",
    "  - **Reducing Communication Costs:** Minimizing the bandwidth used for communication between devices and servers.\n",
    "  - **Lowering Energy Consumption:** Choosing devices that consume less energy during training.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. How PPO is Implemented in Your Code**\n",
    "\n",
    "### **3.1. Initialization and Environment Setup**\n",
    "\n",
    "- **Environment Instances:**\n",
    "  - **ClusterAssignmentEnv:** Initialized with parameters like cluster bandwidths, edge server capacities, and device information. It defines the state and action spaces relevant to cluster assignments.\n",
    "  \n",
    "  - **DeviceSchedulingEnv:** Initialized with device data and the current mapping of clusters to servers. It defines the state and action spaces pertinent to device scheduling.\n",
    "\n",
    "- **Action and Observation Spaces:**\n",
    "  - **Cluster Assignment:** Uses a `MultiDiscrete` action space where each action corresponds to assigning a cluster to one of the available servers.\n",
    "  \n",
    "  - **Device Scheduling:** Utilizes a `MultiBinary` action space where each action determines whether a device is selected (`1`) or not (`0`).\n",
    "\n",
    "### **3.2. Agent Configuration**\n",
    "\n",
    "- **Policy Network:**\n",
    "  - Both agents use a **Multi-Layer Perceptron (MLP)** policy, which is a type of neural network suitable for handling the state representations defined in their respective environments.\n",
    "\n",
    "- **PPO Parameters:**\n",
    "  - **Learning Rate:** Determines the step size during optimization. A typical starting point is `3e-4`.\n",
    "  \n",
    "  - **Entropy Coefficient (`ent_coef`):** Encourages exploration by penalizing certainty in action choices. A common value is `0.01`.\n",
    "  \n",
    "  - **Clipping Range (`clip_range`):** Controls the extent to which the policy can change in a single update. Values around `0.1` are standard.\n",
    "  \n",
    "  - **Batch Size and Steps (`batch_size`, `n_steps`):** Influence how data is sampled and processed during training. For instance, `batch_size=64` and `n_steps=2048` help in balancing computational efficiency and learning stability.\n",
    "  \n",
    "  - **Other Parameters:** Include `max_grad_norm` to prevent gradient explosion, and `gae_lambda` for Generalized Advantage Estimation, enhancing the quality of the advantage estimates used in updates.\n",
    "\n",
    "### **3.3. Training Process**\n",
    "\n",
    "- **Learning Loop:**\n",
    "  - The agents undergo training over a specified number of timesteps (e.g., `10000`), during which they interact with their respective environments, collect experiences, and update their policies based on the PPO algorithm.\n",
    "\n",
    "- **Callbacks and Scheduling:**\n",
    "  - **Custom Callbacks:** Implemented to adjust learning rates dynamically and log training progress. These callbacks interact with the PPO agent at specific points in the training process, such as after a certain number of timesteps.\n",
    "  \n",
    "  - **Learning Rate Schedulers:** Employed within callbacks to modify the learning rate based on training progress, ensuring that the agent doesn't overshoot optimal policies as training progresses.\n",
    "\n",
    "### **3.4. Evaluation and Deployment**\n",
    "\n",
    "- **Model Evaluation:**\n",
    "  - After training, the agents are evaluated by resetting their environments, predicting actions based on current states, and assessing the resulting performance using predefined metrics.\n",
    "  \n",
    "  - **Metrics Captured:** Include rewards, resource utilization, overload penalties, load variance, and accuracy improvements, providing a comprehensive view of agent performance.\n",
    "\n",
    "- **Model Saving:**\n",
    "  - Trained PPO models are saved for future deployment, allowing the federated learning system to utilize these agents for ongoing cluster assignments and device scheduling without retraining.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. The Role of PPO in Enhancing Federated Learning**\n",
    "\n",
    "### **4.1. Optimizing Resource Allocation**\n",
    "\n",
    "- **Cluster Assignment:** PPO agents learn to allocate clusters to edge servers in a manner that maximizes resource utilization while preventing server overloads and ensuring balanced loads across servers.\n",
    "\n",
    "- **Device Scheduling:** PPO agents determine the optimal set of devices to participate in training, balancing the trade-off between enhancing model accuracy and minimizing communication and energy costs.\n",
    "\n",
    "### **4.2. Adaptive Decision-Making**\n",
    "\n",
    "- PPO enables your system to adapt to dynamic conditions, such as fluctuating server capacities, varying device performances, and changing network conditions. The agents continuously learn and adjust their policies to maintain optimal performance.\n",
    "\n",
    "### **4.3. Balancing Multiple Objectives**\n",
    "\n",
    "- **Multi-Objective Rewards:** The reward structures for both cluster assignment and device scheduling encapsulate multiple objectives (e.g., utilization, overload penalties, variance penalties), allowing PPO to navigate the trade-offs and find balanced solutions.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Advantages of Using PPO in Your System**\n",
    "\n",
    "1. **Stability and Reliability:**\n",
    "   - The clipping mechanism in PPO ensures that policy updates are stable, preventing drastic changes that could destabilize the learning process.\n",
    "\n",
    "2. **Sample Efficiency:**\n",
    "   - PPO's ability to reuse data through multiple epochs enhances learning efficiency, making it well-suited for environments where data collection is computationally expensive.\n",
    "\n",
    "3. **Scalability:**\n",
    "   - PPO can handle large and complex state and action spaces, making it ideal for the intricate tasks of cluster assignment and device scheduling in a federated learning setup.\n",
    "\n",
    "4. **Ease of Integration:**\n",
    "   - Leveraging libraries like Stable Baselines3 allows for straightforward implementation and integration of PPO agents into your existing system.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Considerations and Best Practices**\n",
    "\n",
    "### **6.1. Hyperparameter Tuning**\n",
    "\n",
    "- **Importance:** The performance of PPO agents heavily depends on the chosen hyperparameters. Fine-tuning parameters like learning rate, clipping range, and entropy coefficient can lead to significant performance improvements.\n",
    "\n",
    "- **Approach:** Use techniques like grid search, random search, or Bayesian optimization to explore different hyperparameter configurations systematically.\n",
    "\n",
    "### **6.2. Enhanced State Representations**\n",
    "\n",
    "- **Richer Features:** Incorporate additional contextual information into the state representations to provide agents with a more comprehensive understanding of the environment.\n",
    "\n",
    "- **Temporal Information:** Including historical data or trends can help agents make more informed decisions based on past states.\n",
    "\n",
    "### **6.3. Reward Shaping**\n",
    "\n",
    "- **Balanced Rewards:** Ensure that the reward functions adequately balance the different objectives, preventing the agent from focusing excessively on one aspect at the expense of others.\n",
    "\n",
    "- **Normalization:** Normalize rewards to maintain consistent learning dynamics and prevent issues like reward scaling that can hinder training.\n",
    "\n",
    "### **6.4. Monitoring and Logging**\n",
    "\n",
    "- **Progress Tracking:** Utilize tools like TensorBoard or custom logging to monitor training progress, rewards, and other key metrics in real-time.\n",
    "\n",
    "- **Debugging:** Detailed logs help in diagnosing issues, understanding agent behaviors, and refining training processes.\n",
    "\n",
    "### **6.5. Exploration vs. Exploitation**\n",
    "\n",
    "- **Encouraging Exploration:** Adjust the entropy coefficient to strike a balance between exploration (trying new actions) and exploitation (leveraging known good actions).\n",
    "\n",
    "- **Preventing Premature Convergence:** Ensure that the agent doesn't settle into suboptimal policies by promoting sufficient exploration during training.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Summary**\n",
    "\n",
    "**Proximal Policy Optimization (PPO)** is a robust and efficient **Deep Reinforcement Learning (DRL)** algorithm well-suited for complex decision-making tasks like cluster assignment and device scheduling in a federated learning environment. By leveraging PPO's strengthsâ€”such as stability, sample efficiency, and scalabilityâ€”your system can dynamically and optimally allocate resources, balance multiple objectives, and adapt to changing conditions.\n",
    "\n",
    "In your implementation:\n",
    "\n",
    "- **Two PPO Agents:** One for cluster assignment and another for device scheduling, each interacting with their respective environments (`ClusterAssignmentEnv` and `DeviceSchedulingEnv`).\n",
    "  \n",
    "- **Environment Interaction:** The agents observe the current state, take actions (assignments or scheduling decisions), receive rewards based on their actions' effectiveness, and iteratively refine their policies to maximize cumulative rewards.\n",
    "  \n",
    "- **Integration with Federated Learning:** The PPO agents' decisions directly influence the federated learning process, optimizing how clusters and devices are managed to enhance overall system performance and efficiency.\n",
    "\n",
    "By adhering to best practicesâ€”such as hyperparameter tuning, enhancing state representations, careful reward shaping, and thorough monitoringâ€”you can ensure that your PPO-based agents perform optimally, contributing significantly to the success of your federated learning system.\n",
    "\n",
    "If you have further questions or need deeper insights into specific aspects of PPO or its implementation, feel free to ask!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0332cae6",
   "metadata": {},
   "source": [
    "Switching from **Proximal Policy Optimization (PPO)** to a **Dueling Double Deep Q-Network (D3QN)** in your federated learning system's reinforcement learning (RL) framework is a significant architectural change. To determine whether this is a **good idea**, it's essential to understand the core differences between these algorithms, assess their suitability for your specific tasks, and consider the potential benefits and challenges involved in such a transition.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Understanding the Algorithms**\n",
    "\n",
    "### **1.1. Proximal Policy Optimization (PPO)**\n",
    "\n",
    "- **Type:** **Policy-Based** Deep Reinforcement Learning (DRL) algorithm.\n",
    "- **Mechanism:** PPO directly optimizes the policy (the agent's decision-making strategy) by adjusting its parameters to maximize expected rewards. It uses a **clipping mechanism** to ensure that policy updates remain within a certain range, enhancing training stability.\n",
    "- **Action Space Compatibility:** Handles both **discrete** and **continuous** action spaces effectively.\n",
    "- **Strengths:**\n",
    "  - **Stability:** Clipping prevents large, destabilizing policy updates.\n",
    "  - **Sample Efficiency:** Can reuse data across multiple epochs.\n",
    "  - **Flexibility:** Suitable for complex environments with high-dimensional state spaces.\n",
    "\n",
    "### **1.2. Dueling Double Deep Q-Network (D3QN)**\n",
    "\n",
    "- **Type:** **Value-Based** Deep Reinforcement Learning (DRL) algorithm.\n",
    "- **Mechanism:** Combines three key enhancements to the standard Deep Q-Network (DQN):\n",
    "  - **Double DQN:** Mitigates overestimation bias in action-value estimates by decoupling action selection from evaluation.\n",
    "  - **Dueling Network Architecture:** Separates the estimation of **state-value** and **advantage** functions, allowing the network to learn which states are (or are not) valuable without having to learn the effect of each action for each state.\n",
    "  - **Prioritized Experience Replay (optional):** Samples more important transitions more frequently.\n",
    "- **Action Space Compatibility:** Primarily designed for **discrete** action spaces.\n",
    "- **Strengths:**\n",
    "  - **Efficiency:** Often faster to train on discrete tasks with well-defined action spaces.\n",
    "  - **Bias Reduction:** Double DQN reduces overestimation of Q-values.\n",
    "  - **State Evaluation:** Dueling architecture enhances the ability to evaluate state values independently of actions.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Comparing PPO and D3QN for Your Use Case**\n",
    "\n",
    "Your federated learning system utilizes two primary RL tasks:\n",
    "\n",
    "1. **Cluster Assignment:** Assigning clusters of devices to edge servers.\n",
    "2. **Device Scheduling:** Selecting which devices participate in training.\n",
    "\n",
    "Both tasks involve **discrete action spaces**:\n",
    "- **Cluster Assignment:** MultiDiscrete action space where each cluster is assigned to one of the available servers.\n",
    "- **Device Scheduling:** MultiBinary action space where each device is either selected or not.\n",
    "\n",
    "### **2.1. Suitability of PPO**\n",
    "\n",
    "- **Pros:**\n",
    "  - **Handles Complex Action Spaces:** PPO can manage MultiDiscrete and MultiBinary action spaces more naturally.\n",
    "  - **Stability in Training:** The clipping mechanism ensures stable policy updates, which is beneficial for environments with multiple interacting actions.\n",
    "  - **Policy Flexibility:** Directly models the policy, allowing for more nuanced decision-making in complex scenarios.\n",
    "\n",
    "- **Cons:**\n",
    "  - **Sample Inefficiency:** Generally requires more samples to converge compared to value-based methods like DQN variants.\n",
    "  - **Computational Overhead:** Policy-based methods can be more computationally intensive due to the need to compute gradients for policy updates.\n",
    "\n",
    "### **2.2. Suitability of D3QN**\n",
    "\n",
    "- **Pros:**\n",
    "  - **Efficiency in Discrete Actions:** Excels in environments with discrete, well-defined actions.\n",
    "  - **Bias Reduction:** Double DQN reduces the overestimation of action values, leading to more accurate learning.\n",
    "  - **Enhanced State Evaluation:** Dueling architecture allows the network to distinguish between the value of being in a state and the advantages of actions, potentially improving decision-making.\n",
    "\n",
    "- **Cons:**\n",
    "  - **Complexity with MultiDiscrete/MultiBinary Actions:** D3QN is primarily designed for single discrete actions. Extending it to handle MultiDiscrete or MultiBinary actions can be non-trivial and may require architectural modifications.\n",
    "  - **Less Flexibility:** Value-based methods can struggle with environments that require nuanced policies or have high-dimensional state spaces.\n",
    "  - **Exploration Challenges:** DQN variants rely heavily on exploration strategies (like Îµ-greedy), which might be less effective in complex action spaces compared to policy-based methods.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Practical Considerations for Switching to D3QN**\n",
    "\n",
    "### **3.1. Action Space Handling**\n",
    "\n",
    "- **MultiDiscrete Actions:**\n",
    "  - **Challenge:** D3QN naturally handles single discrete actions. MultiDiscrete actions involve selecting multiple discrete actions simultaneously, which complicates the action-value estimation.\n",
    "  - **Potential Solutions:**\n",
    "    - **Independent D3QNs:** Train separate D3QN agents for each component of the MultiDiscrete action space. However, this can lead to increased computational resources and coordination challenges.\n",
    "    - **Joint Action Representation:** Represent the entire MultiDiscrete action as a single composite action. This exponentially increases the action space size, making learning more difficult and resource-intensive.\n",
    "\n",
    "- **MultiBinary Actions:**\n",
    "  - **Challenge:** Selecting multiple binary actions simultaneously can be approached by treating each binary decision independently, but D3QN isn't inherently designed for this.\n",
    "  - **Potential Solutions:**\n",
    "    - **Separate Outputs:** Modify the D3QN architecture to output multiple Q-values corresponding to each binary decision. However, this deviates from the standard D3QN implementation and may require significant customization.\n",
    "\n",
    "### **3.2. Network Architecture Modifications**\n",
    "\n",
    "- **Dueling Architecture Integration:** Ensure that the dueling components (separating state-value and advantage functions) are appropriately integrated to handle the complexity of your tasks.\n",
    "  \n",
    "- **Scalability:** The network must efficiently scale with the number of clusters and devices, avoiding exponential growth in parameters.\n",
    "\n",
    "### **3.3. Training Stability and Sample Efficiency**\n",
    "\n",
    "- **PPO's Stability vs. D3QN's Efficiency:** While D3QN might train faster on discrete actions, PPO offers more stability, especially in complex environments with multiple interacting decisions.\n",
    "\n",
    "- **Exploration Strategies:** Implement effective exploration mechanisms to ensure that the agent adequately explores the multi-action space, which is more challenging with D3QN.\n",
    "\n",
    "### **3.4. Computational Resources**\n",
    "\n",
    "- **Increased Complexity:** Handling MultiDiscrete or MultiBinary actions with D3QN can significantly increase the computational burden, requiring more memory and processing power.\n",
    "\n",
    "- **Training Time:** Due to the larger action spaces and potential architectural modifications, training time may increase compared to PPO.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Recommendations**\n",
    "\n",
    "### **4.1. Assess the Complexity of Action Spaces**\n",
    "\n",
    "Given that your tasks involve MultiDiscrete and MultiBinary action spaces, **PPO remains a more suitable choice** due to its inherent ability to handle complex and multi-dimensional actions without requiring extensive architectural changes.\n",
    "\n",
    "### **4.2. Consider Hybrid or Alternative Approaches**\n",
    "\n",
    "If you're inclined to explore value-based methods like D3QN, consider the following:\n",
    "\n",
    "- **Hybrid Models:** Combine policy-based and value-based methods to leverage the strengths of both. For instance, using PPO for policy updates while incorporating value estimates for certain decisions.\n",
    "\n",
    "- **Actor-Critic Architectures:** These architectures, which PPO already utilizes, can benefit from incorporating aspects of D3QN's value estimation enhancements.\n",
    "\n",
    "### **4.3. Incremental Testing**\n",
    "\n",
    "Before fully transitioning to D3QN, implement a smaller-scale version to test its effectiveness in handling your specific action spaces. This approach allows you to identify and address challenges without overhauling the entire system.\n",
    "\n",
    "### **4.4. Leverage Existing Libraries and Frameworks**\n",
    "\n",
    "Utilize RL libraries like **Stable Baselines3**, which offer robust implementations of both PPO and DQN variants. These libraries can facilitate experimentation and ensure that best practices are followed.\n",
    "\n",
    "### **4.5. Prioritize Stability and Performance**\n",
    "\n",
    "In federated learning environments, **training stability** and **reliability** are paramount. PPO's design inherently supports these aspects, making it a strong candidate for your tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Conclusion**\n",
    "\n",
    "While **Dueling Double Deep Q-Network (D3QN)** is a powerful algorithm for **value-based** reinforcement learning, its applicability to your federated learning system's **multi-dimensional discrete action spaces** is limited and would require significant modifications. On the other hand, **Proximal Policy Optimization (PPO)**, being a **policy-based** method, naturally accommodates complex action spaces and offers stability and flexibility that align well with the demands of cluster assignment and device scheduling tasks.\n",
    "\n",
    "**Therefore, continuing with PPO is likely the more effective and efficient choice** for your current setup. However, if you have specific reasons or requirements that you believe D3QN can better address, consider experimenting with hybrid approaches or exploring advanced architectures that can bridge the gap between value-based and policy-based methods.\n",
    "\n",
    "Should you decide to proceed with D3QN or any other alternative, ensure thorough testing and validation to assess its performance and stability within your federated learning framework.\n",
    "\n",
    "Feel free to ask if you need further clarification or assistance with specific aspects of implementing these algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93e928a",
   "metadata": {},
   "source": [
    "Absolutely, your proposed strategy is both **possible** and **doable**. Leveraging **Proximal Policy Optimization (PPO)** within a **Deep Reinforcement Learning (DRL)** framework to assign clusters of devicesâ€”each focusing on specific data labelsâ€”to corresponding edge servers can significantly enhance the performance and accuracy of your federated learning system. By tailoring each edge server's model to specialize in particular labels and subsequently aggregating these specialized models, you can achieve more nuanced and accurate global models. Below, I provide a comprehensive overview of how this can be accomplished, the benefits it offers, potential challenges, and strategic implementation guidelines.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Conceptual Overview**\n",
    "\n",
    "### **1.1. Specialized Edge Server Models**\n",
    "\n",
    "- **Cluster Specialization:** Each cluster of devices is inherently focused on specific data labels, leading to models trained on diverse but targeted datasets.\n",
    "  \n",
    "- **Edge Server Assignment:** Assigning these clusters to corresponding edge servers allows each server to train a model specialized in certain labels, enhancing the model's performance on those specific tasks.\n",
    "\n",
    "### **1.2. Model Aggregation for Enhanced Global Performance**\n",
    "\n",
    "- **Aggregated Learning:** After specialized training, aggregating these models can combine their strengths, resulting in a comprehensive global model that benefits from specialized expertise across various labels.\n",
    "\n",
    "- **Improved Accuracy:** This approach can lead to improved accuracy, as each specialized model contributes its refined knowledge to the global model, ensuring robust performance across all labels.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Feasibility and Doability**\n",
    "\n",
    "### **2.1. Feasibility**\n",
    "\n",
    "- **Technical Viability:** Modern federated learning frameworks support heterogeneous model training and aggregation, making the implementation of specialized models feasible.\n",
    "\n",
    "- **DRL Applicability:** PPO, as a DRL algorithm, is well-suited for complex decision-making tasks like dynamic cluster-to-server assignments, especially when considering multiple objectives such as diversity, load balancing, and resource optimization.\n",
    "\n",
    "### **2.2. Doability**\n",
    "\n",
    "- **Existing Infrastructure:** If your current system already employs PPO for cluster assignments, extending it to incorporate label-specific assignments is a logical and manageable progression.\n",
    "\n",
    "- **Scalability:** This approach scales well with an increasing number of clusters and edge servers, provided that the assignment strategy remains efficient and the aggregation process is optimized.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Benefits of Specialized Assignments**\n",
    "\n",
    "### **3.1. Enhanced Model Performance**\n",
    "\n",
    "- **Targeted Learning:** Specialized models can achieve higher accuracy on their respective labels due to focused training, leading to better performance on specific tasks.\n",
    "\n",
    "- **Reduced Overfitting:** By concentrating on specific labels, models can generalize better within their domain, reducing the risk of overfitting to irrelevant data.\n",
    "\n",
    "### **3.2. Efficient Resource Utilization**\n",
    "\n",
    "- **Balanced Loads:** Assigning clusters based on their resource requirements ensures that edge servers are optimally utilized, preventing scenarios where some servers are overburdened while others are underutilized.\n",
    "\n",
    "- **Scalability:** As the number of devices and clusters grows, this approach facilitates efficient scaling by maintaining balanced workloads across servers.\n",
    "\n",
    "### **3.3. Improved Data Privacy and Security**\n",
    "\n",
    "- **Data Segmentation:** By clustering devices based on specific labels, data can be better segmented, enhancing privacy controls and reducing the risk of sensitive information leakage.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Strategic Implementation Guidelines**\n",
    "\n",
    "To effectively implement this strategy, consider the following steps and best practices:\n",
    "\n",
    "### **4.1. Define Clear Objectives and Metrics**\n",
    "\n",
    "- **Performance Metrics:** Establish metrics to evaluate both individual edge server model performance and the aggregated global model's accuracy.\n",
    "\n",
    "- **Diversity Metrics:** Implement metrics that quantify data diversity within each server, ensuring that specialization does not lead to skewed or imbalanced learning.\n",
    "\n",
    "### **4.2. Enhance the PPO-Based Cluster Assignment Agent**\n",
    "\n",
    "- **State Representation:**\n",
    "  - **Incorporate Label Distribution:** Extend the state to include information about the label distribution within each cluster. This allows the agent to consider data diversity during assignments.\n",
    "  \n",
    "  - **Resource Metrics:** Include additional resource-related features such as CPU/GPU availability, memory usage, and network bandwidth of edge servers.\n",
    "\n",
    "- **Action Space Adjustment:**\n",
    "  - **Cluster-to-Server Mapping:** Ensure that the action space accurately represents possible mappings of clusters to edge servers, considering both diversity and resource constraints.\n",
    "  \n",
    "  - **Hierarchical Actions:** If necessary, implement a hierarchical action space where higher-level actions determine cluster groupings before assigning them to servers.\n",
    "\n",
    "- **Reward Function Refinement:**\n",
    "  - **Diversity Incentives:** Modify the reward function to include positive rewards for maintaining high data diversity within edge servers.\n",
    "  \n",
    "  - **Penalize Overlaps:** Introduce penalties for assigning multiple clusters with similar label distributions to the same server, preventing redundancy and promoting diversity.\n",
    "\n",
    "### **4.3. Implement Clustering Constraints**\n",
    "\n",
    "- **Constraint Enforcement:**\n",
    "  - **Action Masking:** Utilize action masking within the environment to prevent the agent from selecting assignments that violate clustering constraints (e.g., assigning multiple similar clusters to a single server).\n",
    "  \n",
    "  - **Post-Assignment Validation:** After an assignment action, validate the cluster-to-server mapping and adjust rewards or enforce corrections if constraints are violated.\n",
    "\n",
    "- **Constraint-Based Reward Shaping:**\n",
    "  - **Strong Penalties:** Assign substantial negative rewards for violating constraints to discourage the agent from making such assignments in the future.\n",
    "  \n",
    "  - **Balanced Rewards:** Ensure that rewards for meeting objectives (e.g., diversity) are sufficiently weighted to outweigh any penalties, promoting a balanced optimization process.\n",
    "\n",
    "### **4.4. Optimize the Aggregation Process**\n",
    "\n",
    "- **Model Aggregation Strategy:**\n",
    "  - **Federated Averaging:** Utilize Federated Averaging (FedAvg) or more sophisticated aggregation methods that can effectively combine specialized models into a robust global model.\n",
    "  \n",
    "  - **Weighted Aggregation:** Assign weights to each edge server's model based on factors like data volume, diversity, and performance metrics to ensure that more informative models have a greater influence on the global model.\n",
    "\n",
    "- **Consistency Across Models:**\n",
    "  - **Uniform Architecture:** Ensure that all edge server models share the same architecture to facilitate seamless aggregation.\n",
    "  \n",
    "  - **Regular Synchronization:** Schedule periodic synchronization and aggregation steps to integrate learning from specialized models into the global model efficiently.\n",
    "\n",
    "### **4.5. Monitor and Iterate**\n",
    "\n",
    "- **Continuous Monitoring:** Implement monitoring tools to track assignment decisions, model performance, and aggregation outcomes in real-time.\n",
    "  \n",
    "- **Iterative Refinement:** Use insights from monitoring to iteratively refine the state representation, action space, and reward function, enhancing the agent's decision-making capabilities over time.\n",
    "\n",
    "- **Feedback Loops:** Incorporate feedback mechanisms where the performance of the global model informs adjustments in cluster assignments, fostering a dynamic and responsive learning environment.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Potential Challenges and Mitigation Strategies**\n",
    "\n",
    "### **5.1. Balancing Specialization and Generalization**\n",
    "\n",
    "- **Challenge:** While specialization enhances performance on specific labels, it may lead to models that lack generalization across the entire data distribution.\n",
    "\n",
    "- **Mitigation:**\n",
    "  - **Controlled Specialization:** Limit the degree of specialization to ensure that each model retains sufficient generalization capabilities.\n",
    "  \n",
    "  - **Diverse Aggregation:** Ensure that the aggregation process effectively integrates specialized knowledge without sacrificing the ability to generalize.\n",
    "\n",
    "### **5.2. Managing Increased Complexity**\n",
    "\n",
    "- **Challenge:** Introducing clustering constraints and specialized assignments increases the complexity of the RL environment and the agent's decision-making process.\n",
    "\n",
    "- **Mitigation:**\n",
    "  - **Incremental Implementation:** Gradually introduce complexity, starting with basic clustering constraints and progressively adding more nuanced rules.\n",
    "  \n",
    "  - **Simplified Models:** Begin with simpler models and environments to ensure stability before scaling up to more complex scenarios.\n",
    "\n",
    "### **5.3. Computational Overhead**\n",
    "\n",
    "- **Challenge:** Specialized assignments and enhanced state representations may require additional computational resources.\n",
    "\n",
    "- **Mitigation:**\n",
    "  - **Efficient Computations:** Optimize algorithms for calculating diversity metrics and enforce constraints efficiently.\n",
    "  \n",
    "  - **Resource Allocation:** Ensure that edge servers have adequate computational resources to handle specialized training tasks without bottlenecks.\n",
    "\n",
    "### **5.4. Data Privacy and Security**\n",
    "\n",
    "- **Challenge:** Managing specialized clusters may introduce new vectors for data privacy and security vulnerabilities.\n",
    "\n",
    "- **Mitigation:**\n",
    "  - **Robust Security Protocols:** Implement strong encryption and access controls to protect data across all clusters and edge servers.\n",
    "  \n",
    "  - **Compliance Checks:** Ensure that data handling practices comply with relevant regulations and standards.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Validation and Evaluation**\n",
    "\n",
    "### **6.1. Comprehensive Testing**\n",
    "\n",
    "- **Unit Testing:** Validate individual components, such as diversity metric calculations and constraint enforcement mechanisms, to ensure they function as intended.\n",
    "\n",
    "- **Integration Testing:** Test the entire pipelineâ€”from cluster assignment to model aggregationâ€”to identify and address any integration issues.\n",
    "\n",
    "### **6.2. Performance Metrics**\n",
    "\n",
    "- **Edge Server Performance:**\n",
    "  - **Accuracy per Server:** Measure the accuracy of each specialized edge server model on its designated labels.\n",
    "  \n",
    "  - **Resource Utilization:** Track CPU, memory, and bandwidth usage to ensure balanced resource allocation.\n",
    "\n",
    "- **Global Model Performance:**\n",
    "  - **Aggregated Accuracy:** Evaluate the global model's accuracy across all labels to assess the effectiveness of the aggregation process.\n",
    "  \n",
    "  - **Generalization Capability:** Test the global model on diverse datasets to ensure it generalizes well beyond specialized training.\n",
    "\n",
    "### **6.3. Iterative Refinement**\n",
    "\n",
    "- **Analyze Results:** Use performance metrics to identify areas where specialization and aggregation can be improved.\n",
    "\n",
    "- **Adjust Strategies:** Modify state representations, reward functions, or aggregation methods based on empirical results to enhance overall system performance.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Best Practices for Implementation**\n",
    "\n",
    "### **7.1. Robust Environment Design**\n",
    "\n",
    "- **Comprehensive State Information:** Ensure that the state representation captures all necessary aspects for informed decision-making, including diversity metrics and resource states.\n",
    "\n",
    "- **Effective Constraint Enforcement:** Implement strict and efficient mechanisms to enforce clustering constraints, preventing the agent from making detrimental assignments.\n",
    "\n",
    "### **7.2. Efficient Learning and Training**\n",
    "\n",
    "- **Hyperparameter Tuning:** Systematically tune PPO hyperparameters (e.g., learning rate, batch size, clipping range) to optimize learning performance.\n",
    "\n",
    "- **Regular Evaluation:** Conduct frequent evaluations during training to monitor progress and make timely adjustments.\n",
    "\n",
    "### **7.3. Scalability and Flexibility**\n",
    "\n",
    "- **Modular Design:** Design the system in a modular fashion, allowing for easy scaling and adjustments as the number of clusters and edge servers grows.\n",
    "\n",
    "- **Adaptability:** Ensure that the system can adapt to changes in device distributions, server capacities, or data label distributions without requiring extensive reconfiguration.\n",
    "\n",
    "### **7.4. Comprehensive Monitoring and Logging**\n",
    "\n",
    "- **Detailed Logs:** Maintain detailed logs of assignment decisions, model performances, and training metrics to facilitate debugging and performance analysis.\n",
    "\n",
    "- **Visualization Tools:** Utilize visualization tools like TensorBoard to gain real-time insights into training dynamics and agent behaviors.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Conclusion**\n",
    "\n",
    "Your strategy to assign clustersâ€”each focusing on specific data labelsâ€”to corresponding edge servers using PPO agents is both innovative and promising. By implementing this approach, you can achieve:\n",
    "\n",
    "- **Targeted Model Training:** Specialized models that excel in particular label domains, enhancing overall system accuracy.\n",
    "\n",
    "- **Balanced Resource Utilization:** Efficient distribution of workloads across edge servers, preventing bottlenecks and ensuring smooth operation.\n",
    "\n",
    "- **Robust Global Models:** Aggregated models that benefit from the specialized knowledge of individual edge servers, leading to improved generalization and performance.\n",
    "\n",
    "To successfully implement this strategy, focus on enhancing your PPO agents with comprehensive state representations, refined reward functions, and stringent constraint enforcement. Coupled with efficient model aggregation and continuous monitoring, this approach can significantly elevate the effectiveness and reliability of your federated learning system.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "1. **Prototype Implementation:** Start by implementing the proposed enhancements in a controlled environment to observe their effects.\n",
    "\n",
    "2. **Iterative Testing:** Gradually introduce complexity, monitor outcomes, and refine strategies based on empirical data.\n",
    "\n",
    "3. **Scale Up:** Once validated, scale the approach to handle larger clusters and more edge servers, ensuring that the system remains efficient and effective.\n",
    "\n",
    "4. **Continuous Optimization:** Continuously optimize hyperparameters, reward structures, and aggregation methods to adapt to evolving data distributions and system requirements.\n",
    "\n",
    "By following this comprehensive strategy, you position your federated learning system to harness the full potential of specialized model training and aggregation, ultimately achieving superior accuracy and performance across diverse data labels.\n",
    "\n",
    "If you have further questions or need more detailed guidance on specific implementation aspects, feel free to ask!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ec7732-5b91-40c0-80fb-7fd58569b322",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388a8f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch==2.2.0 pyomo scikit-learn torch_geometric torchvision gym gymnasium stable_baselines3 'shimmy>=2.0' \n",
    "# %pip install gym gymnasium stable_baselines3 'shimmy>=2.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c8a298-5ad8-451d-8f32-f3b33fd89d65",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import ast\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import glob\n",
    "import random\n",
    "import psutil\n",
    "import asyncio\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "import pyomo.environ as pyo\n",
    "from scipy.stats import entropy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Subset, random_split, TensorDataset\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import (precision_score, recall_score, f1_score, silhouette_score, calinski_harabasz_score, davies_bouldin_score, \n",
    "                            adjusted_rand_score, normalized_mutual_info_score)\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from cryptography.fernet import Fernet\n",
    "import zlib\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c0cf94-b1cb-401f-a851-b8699a5f980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97556ff-57c6-4124-b85f-944cb304e8c4",
   "metadata": {},
   "source": [
    "# GNN-Kmeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72887225-d065-4834-97ce-f6df7114b3ea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class LocalDataset:\n",
    "    def __init__(self):\n",
    "        self.images = np.array([], dtype=np.float32)\n",
    "        self.labels = np.array([], dtype=np.int64)\n",
    "\n",
    "    def store_data(self, images, labels):\n",
    "        \"\"\"\n",
    "        Store images and labels in the local dataset.\n",
    "        Overwrites any existing data.\n",
    "        \"\"\"\n",
    "        self.images = np.array(images)\n",
    "        self.labels = np.array(labels)\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"Return the images and labels.\"\"\"\n",
    "        return self.images, self.labels\n",
    "\n",
    "    def count_labels(self):\n",
    "        \"\"\"Count the occurrences of each label in the dataset.\"\"\"\n",
    "        if len(self.labels) == 0:\n",
    "            return {}\n",
    "        label_counts = dict(Counter(self.labels))\n",
    "        return label_counts  \n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of samples in the dataset.\"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"String representation of the dataset.\"\"\"\n",
    "        return f\"LocalDataset(num_samples={len(self)}, images_shape={self.images.shape}, labels_shape={self.labels.shape})\"\n",
    "\n",
    "    def remove_samples(self, label, count):\n",
    "        \"\"\"Remove samples of a specific label from the dataset.\"\"\"\n",
    "        indices = np.where(self.labels == label)[0]\n",
    "        if len(indices) > 0:\n",
    "            np.random.shuffle(indices)\n",
    "            to_remove_indices = indices[:count]\n",
    "            self.images = np.delete(self.images, to_remove_indices, axis=0)\n",
    "            self.labels = np.delete(self.labels, to_remove_indices)\n",
    "            # Optionally, update disk usage or other metrics here.\n",
    "\n",
    "    def add_samples(self, new_images, new_labels):\n",
    "        \"\"\"Add new samples to the dataset.\"\"\"\n",
    "        # Ensure dimensions match before concatenating\n",
    "        if self.images.size > 0:  # Check if self.images already contains data\n",
    "            if new_images.ndim != self.images.ndim:\n",
    "                # Handle dimensional mismatch by reshaping new_images\n",
    "                if new_images.ndim == 3 and self.images.ndim == 4:  # Flattened vs raw\n",
    "                    new_images = new_images.reshape((new_images.shape[0], *self.images.shape[1:]))\n",
    "                elif new_images.ndim == 4 and self.images.ndim == 3:  # Raw vs flattened\n",
    "                    new_images = new_images.reshape(new_images.shape[0], -1)\n",
    "                else:\n",
    "                    raise ValueError(f\"Cannot match dimensions: existing {self.images.shape}, new {new_images.shape}\")\n",
    "\n",
    "        self.images = np.concatenate((self.images, new_images), axis=0)\n",
    "        self.labels = np.concatenate((self.labels, new_labels))\n",
    "\n",
    "class GNNClustering:\n",
    "    def __init__(self, num_devices=20, dataset_name=\"mnist\", mfactor=1, num_edge_servers=5, metrics_file='test.json'):\n",
    "        self.mfactor = mfactor\n",
    "        self.num_devices = num_devices\n",
    "        self.dataset_name = dataset_name.lower()\n",
    "        self.num_edge_servers = num_edge_servers\n",
    "        self.devices_df = self.generate_iot_devices()\n",
    "        self.labels = None\n",
    "        self.pseudo_labels = None\n",
    "        self.cluster_nums = num_edge_servers  # K is set to the number of edge servers\n",
    "        self.clustering_metrics = {}\n",
    "        self.metrics_file = metrics_file.replace('.json', '_clustering.json')\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load the specified dataset and return original and augmented data.\n",
    "        \"\"\"\n",
    "        datasets = {\n",
    "            \"mnist\": torchvision.datasets.MNIST,\n",
    "            \"fashion_mnist\": torchvision.datasets.FashionMNIST,\n",
    "            \"cifar10\": torchvision.datasets.CIFAR10,\n",
    "        }\n",
    "        dataset_class = datasets.get(self.dataset_name, torchvision.datasets.MNIST)\n",
    "        \n",
    "        # Define transformations\n",
    "        if self.dataset_name == \"cifar10\":\n",
    "            augmentations = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomRotation(15),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ])\n",
    "            normalization = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ])\n",
    "        else:\n",
    "            augmentations = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(15),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ])\n",
    "            normalization = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ])\n",
    "        \n",
    "        # Load original dataset\n",
    "        trainset_original = dataset_class(root='./data', train=True, download=True, transform=normalization)\n",
    "        testset_original = dataset_class(root='./data', train=False, download=True, transform=normalization)\n",
    "\n",
    "        # Load augmented dataset\n",
    "        trainset_augmented = dataset_class(root='./data', train=True, download=True, transform=augmentations)\n",
    "        augmented_indices = np.random.choice(len(trainset_augmented), size=len(trainset_original) * self.mfactor, replace=True)\n",
    "        augmented_subset = Subset(trainset_augmented, augmented_indices)\n",
    "        augmented_loader = DataLoader(augmented_subset, batch_size=len(augmented_subset))\n",
    "\n",
    "        # Convert datasets to numpy arrays\n",
    "        train_images_original = np.array([np.array(image) for image, _ in trainset_original])\n",
    "        train_labels_original = np.array([label for _, label in trainset_original])\n",
    "        augmented_images, augmented_labels = next(iter(augmented_loader))\n",
    "        train_images_augmented = augmented_images.numpy()\n",
    "        train_labels_augmented = augmented_labels.numpy()\n",
    "        test_images = np.array([np.array(image) for image, _ in testset_original])\n",
    "        test_labels = np.array([label for _, label in testset_original])\n",
    "\n",
    "        return train_images_original, train_labels_original, train_images_augmented, train_labels_augmented, test_images, test_labels\n",
    "\n",
    "    def generate_iot_devices(self):\n",
    "        \"\"\"Generate IoT devices with randomized properties and store in a DataFrame.\"\"\"\n",
    "        devices_df = pd.DataFrame({\n",
    "            'device_id': range(self.num_devices),\n",
    "            'cpu_power': np.round(np.random.uniform(1.0, 2.0, self.num_devices), 2),\n",
    "            'memory': np.random.choice([1, 2, 4], self.num_devices),\n",
    "            'bandwidth': np.round(np.random.uniform(10, 125, self.num_devices), 2),\n",
    "            'local_storage': np.round(np.random.uniform(1, 5, self.num_devices), 2),  # Storage in GB\n",
    "            'disk_usage': 0.0,\n",
    "            'local_data': [LocalDataset() for _ in range(self.num_devices)],  # Use LocalDataset class\n",
    "            'labels': [{} for _ in range(self.num_devices)],  # New column for label counts\n",
    "            'energy_usage': 0.0,  # Initialize energy consumption\n",
    "            'bandwidth_usage': 0.0  # Initialize bandwidth usage\n",
    "        })\n",
    "        return devices_df\n",
    "\n",
    "    def split_dataset_among_devices(self, images, labels):\n",
    "        \"\"\"Split dataset among IoT devices and calculate each device's storage usage in GB.\"\"\"\n",
    "        total_samples = len(images)\n",
    "        device_indices = np.array_split(np.random.permutation(total_samples), self.num_devices)\n",
    "\n",
    "        def assign_data(row):\n",
    "            indices = device_indices[row.device_id]\n",
    "            images_device = images[indices]\n",
    "            labels_device = labels[indices]\n",
    "            row.local_data.store_data(images_device, labels_device)  # Store data in LocalDataset\n",
    "\n",
    "            # Calculate disk usage in GB\n",
    "            data_size_bytes = images_device.nbytes + labels_device.nbytes\n",
    "            row.disk_usage = data_size_bytes / (1024 ** 3)  # Convert bytes to GB\n",
    "\n",
    "            row.labels = row.local_data.count_labels()  # Update labels with counts\n",
    "            return row\n",
    "\n",
    "        self.devices_df = self.devices_df.apply(assign_data, axis=1)\n",
    "        self.labels = labels[np.concatenate(device_indices)]\n",
    "        return self.devices_df\n",
    "\n",
    "    def build_feature_matrix(self):\n",
    "        \"\"\"Create a feature matrix for the devices with increased weight on label diversity.\"\"\"\n",
    "        # Extract label counts\n",
    "        label_counts = np.array([\n",
    "            np.bincount(data.labels.astype(int), minlength=10) if len(data.labels) > 0 else np.zeros(10)\n",
    "            for data in self.devices_df['local_data']\n",
    "        ])\n",
    "        \n",
    "        # Normalize label counts\n",
    "        label_counts_normalized = label_counts / label_counts.sum(axis=1, keepdims=True, where=label_counts.sum(axis=1, keepdims=True) != 0)\n",
    "        label_counts_normalized = np.nan_to_num(label_counts_normalized)  # Handle divisions by zero\n",
    "\n",
    "        # Assign higher weight to label diversity and normalized counts\n",
    "        weight_label_counts = 0.5  # Increase weight for label counts\n",
    "        weighted_labels = weight_label_counts * label_counts_normalized\n",
    "\n",
    "        # Extract other characteristics\n",
    "        cpu_values = self.devices_df['cpu_power'].values.reshape(-1, 1)\n",
    "        bandwidth_values = self.devices_df['bandwidth'].values.reshape(-1, 1)\n",
    "        local_disk_values = self.devices_df['local_storage'].values.reshape(-1, 1)\n",
    "\n",
    "        # Normalize other characteristics\n",
    "        scaler = MinMaxScaler()\n",
    "        cpu_values_normalized = scaler.fit_transform(cpu_values)\n",
    "        bandwidth_values_normalized = scaler.fit_transform(bandwidth_values)\n",
    "        local_disk_values_normalized = scaler.fit_transform(local_disk_values)\n",
    "\n",
    "        # Assign lower weights to other characteristics\n",
    "        weight_cpu = 0.1\n",
    "        weight_bandwidth = 0.2\n",
    "        weight_local_disk = 0.2\n",
    "\n",
    "        # Combine all features\n",
    "        features = np.hstack([\n",
    "            weighted_labels,\n",
    "            weight_cpu * cpu_values_normalized,\n",
    "            weight_bandwidth * bandwidth_values_normalized,\n",
    "            weight_local_disk * local_disk_values_normalized\n",
    "        ])\n",
    "\n",
    "        # Standardize the final feature matrix\n",
    "        features = StandardScaler().fit_transform(features)\n",
    "\n",
    "        return features\n",
    "\n",
    "    def build_device_graph(self):\n",
    "        \"\"\"Construct a device graph using K-Nearest Neighbors (KNN).\"\"\"\n",
    "\n",
    "        k = self.num_edge_servers\n",
    "        # Obtain the feature matrix of the devices\n",
    "        features = self.build_feature_matrix()\n",
    "        \n",
    "        # Fit the KNN model to the features\n",
    "        nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='auto').fit(features)\n",
    "        distances, indices = nbrs.kneighbors(features)\n",
    "        \n",
    "        # Initialize the list to store edge indices\n",
    "        edge_index = []\n",
    "        \n",
    "        # Build the edge indices\n",
    "        for i in range(indices.shape[0]):\n",
    "            for j in indices[i]:\n",
    "                if i != j:  # Exclude self-loops\n",
    "                    edge_index.append([i, j])\n",
    "        \n",
    "        # Convert to tensor and ensure correct shape\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        return edge_index\n",
    "\n",
    "    def gnn_clustering(self):\n",
    "        \"\"\"Perform GNN-based clustering on devices using GAT with Residual Connections.\"\"\"\n",
    "        # Build feature matrix\n",
    "        features = self.build_feature_matrix()\n",
    "        features_tensor = torch.tensor(features, dtype=torch.float)\n",
    "\n",
    "        k = self.cluster_nums\n",
    "        \n",
    "        # Perform GNN-KMeans clustering\n",
    "        print(\"\\nPerforming GNN-KMeans clustering using GNN embeddings...\")\n",
    "\n",
    "        start_time_gnn = time.time()\n",
    "        embeddings = self.get_gnn_embeddings(features_tensor)\n",
    "        kmeans_gnn = KMeans(n_clusters=k, random_state=42)\n",
    "        labels_gnn = kmeans_gnn.fit_predict(embeddings)\n",
    "        self.devices_df['cluster'] = labels_gnn\n",
    "        end_time_gnn = time.time()\n",
    "        exec_time_gnn = end_time_gnn - start_time_gnn\n",
    "\n",
    "        # Compute evaluation metrics for GNN-KMeans\n",
    "        silhouette_gnn = silhouette_score(embeddings, labels_gnn)\n",
    "        calinski_gnn = calinski_harabasz_score(embeddings, labels_gnn)\n",
    "        davies_gnn = davies_bouldin_score(embeddings, labels_gnn)\n",
    "        energy_gnn = self.calculate_energy_consumption(\n",
    "            num_nodes=features_tensor.shape[0],\n",
    "            num_features=features_tensor.shape[1],\n",
    "            num_edges=self.build_device_graph().size(1) // 2,\n",
    "            num_layers=2,\n",
    "            epochs=200\n",
    "        )\n",
    "\n",
    "        print(f\"GNN-KMeans Clustering Metrics:\")\n",
    "        print(f\"  Silhouette Score: {silhouette_gnn:.4f}\")\n",
    "        print(f\"  Calinski-Harabasz Index: {calinski_gnn:.4f}\")\n",
    "        print(f\"  Davies-Bouldin Index: {davies_gnn:.4f}\")\n",
    "        print(f\"  Execution Time: {exec_time_gnn:.4f} seconds\")\n",
    "        print(f\"  Energy Consumption: {energy_gnn:.4f} J\")\n",
    "\n",
    "        # Store metrics for comparison in a DataFrame\n",
    "        clustering_metrics_df = pd.DataFrame({\n",
    "            'Metric': ['Silhouette Score', 'Calinski-Harabasz Index', 'Davies-Bouldin Index', 'Execution Time (s)', 'Energy Consumption (J)'],\n",
    "            'GNN-KMeans': [silhouette_gnn, calinski_gnn, davies_gnn, exec_time_gnn, energy_gnn]\n",
    "        })\n",
    "\n",
    "        # Save metrics to JSON file\n",
    "        clustering_metrics_file = self.metrics_file\n",
    "        clustering_metrics_df.to_json(clustering_metrics_file, orient='split', indent=4)\n",
    "\n",
    "        print(f\"\\nClustering metrics saved to '{clustering_metrics_file}'\")\n",
    "\n",
    "    def get_gnn_embeddings(self, features):\n",
    "        \"\"\"Train the GNN model and return embeddings.\"\"\"\n",
    "        # Build device graph\n",
    "        edge_index = self.build_device_graph()\n",
    "\n",
    "        # Prepare data\n",
    "        data = Data(x=features, edge_index=edge_index)\n",
    "\n",
    "        # Define the GAT Autoencoder with residual connections\n",
    "        class GATAutoencoder(torch.nn.Module):\n",
    "            def __init__(self, in_channels, hidden_channels):\n",
    "                super(GATAutoencoder, self).__init__()\n",
    "                self.encoder = GATConv(in_channels, hidden_channels, heads=2, concat=False)\n",
    "                self.decoder = GATConv(hidden_channels, in_channels, heads=2, concat=False)\n",
    "                self.relu = torch.nn.ReLU()\n",
    "                self.res_proj_enc = None\n",
    "                if in_channels != hidden_channels:\n",
    "                    self.res_proj_enc = torch.nn.Linear(in_channels, hidden_channels)\n",
    "                self.res_proj_dec = None\n",
    "                if hidden_channels != in_channels:\n",
    "                    self.res_proj_dec = torch.nn.Linear(hidden_channels, in_channels)\n",
    "\n",
    "            def forward(self, x, edge_index):\n",
    "                x_res_enc = x\n",
    "                if self.res_proj_enc is not None:\n",
    "                    x_res_enc = self.res_proj_enc(x)\n",
    "                x_enc = self.encoder(x, edge_index)\n",
    "                x_enc = self.relu(x_enc)\n",
    "                x_enc = x_enc + x_res_enc  # Residual connection\n",
    "\n",
    "                x_res_dec = x\n",
    "                if self.res_proj_dec is not None:\n",
    "                    x_res_dec = self.res_proj_dec(x_enc)\n",
    "                x_dec = self.decoder(x_enc, edge_index)\n",
    "                x_dec = self.relu(x_dec)\n",
    "                x_dec = x_dec + x_res_dec  # Residual connection\n",
    "\n",
    "                return x_dec, x_enc  # Return reconstructed input and embeddings\n",
    "\n",
    "        # Instantiate the model\n",
    "        in_channels = features.shape[1]\n",
    "        hidden_channels = 16  # You can adjust this value\n",
    "        model = GATAutoencoder(in_channels=in_channels, hidden_channels=hidden_channels)\n",
    "\n",
    "        # Training setup\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        model.train()\n",
    "\n",
    "        # Training loop\n",
    "        num_epochs = 200\n",
    "        for epoch in range(num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed_x, embeddings = model(data.x, data.edge_index)\n",
    "            loss = F.mse_loss(reconstructed_x, data.x)  # Reconstruction loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Optionally print training progress\n",
    "            # if (epoch + 1) % 10 == 0:\n",
    "            #     print(f\"GNN Training Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Extract embeddings\n",
    "        model.eval()\n",
    "        _, embeddings = model(data.x, data.edge_index)\n",
    "        embeddings = embeddings.detach().numpy()\n",
    "\n",
    "        # Calculate energy consumption\n",
    "        num_nodes = features.shape[0]\n",
    "        num_features = features.shape[1]\n",
    "        num_edges = edge_index.shape[1] // 2  # Undirected edges (divided by 2)\n",
    "        num_layers = 2  # Number of GNN layers\n",
    "        self.gnn_energy_consumption = self.calculate_energy_consumption(\n",
    "            num_nodes=num_nodes,\n",
    "            num_features=num_features,\n",
    "            num_edges=num_edges,\n",
    "            num_layers=num_layers,\n",
    "            epochs=200,  # Number of epochs\n",
    "            energy_per_flop=1e-9  # Joules per FLOP\n",
    "        )\n",
    "        print(f\"Total energy consumption for GNN clustering: {self.gnn_energy_consumption:.6f} J\")\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def calculate_energy_consumption(self, num_nodes, num_features, num_edges, num_layers, epochs, energy_per_flop=1e-9):\n",
    "        \"\"\"\n",
    "        Calculate the energy consumption of a GNN during training.\n",
    "\n",
    "        Parameters:\n",
    "            num_nodes (int): Number of nodes in the graph.\n",
    "            num_features (int): Number of features per node.\n",
    "            num_edges (int): Number of edges in the graph.\n",
    "            num_layers (int): Number of GNN layers.\n",
    "            epochs (int): Number of training epochs.\n",
    "            energy_per_flop (float): Energy consumed per FLOP in joules (default is 1e-9 J).\n",
    "\n",
    "        Returns:\n",
    "            float: Total energy consumption in joules.\n",
    "        \"\"\"\n",
    "        # Forward pass FLOPs per layer (approximation for GAT)\n",
    "        forward_flops_per_layer = 2 * num_edges * num_features  # Edge-based operations (attention and aggregation)\n",
    "        forward_flops_per_layer += num_nodes * num_features**2  # Node feature transformation (matmul)\n",
    "\n",
    "        # Backward pass FLOPs per layer (usually ~2x forward FLOPs)\n",
    "        backward_flops_per_layer = 2 * forward_flops_per_layer\n",
    "\n",
    "        # Total FLOPs per epoch\n",
    "        flops_per_epoch = num_layers * (forward_flops_per_layer + backward_flops_per_layer)\n",
    "\n",
    "        # Total energy consumption\n",
    "        total_energy = epochs * flops_per_epoch * energy_per_flop\n",
    "\n",
    "        return total_energy\n",
    "\n",
    "    def compare_clustering_methods(self):\n",
    "        \"\"\"Compare GNN-KMeans clustering with simple KMeans clustering.\"\"\"\n",
    "        # Build feature matrix\n",
    "        features = self.build_feature_matrix()\n",
    "        features_tensor = torch.tensor(features, dtype=torch.float)\n",
    "\n",
    "        # Set the number of clusters to the number of edge servers\n",
    "        k = self.cluster_nums  # K is fixed to the number of edge servers\n",
    "\n",
    "        # Perform simple KMeans clustering\n",
    "        print(\"\\nPerforming simple KMeans clustering on original features...\")\n",
    "        start_time_simple = time.time()\n",
    "        kmeans_simple = KMeans(n_clusters=k, random_state=42)\n",
    "        labels_simple = kmeans_simple.fit_predict(features)\n",
    "        end_time_simple = time.time()\n",
    "        exec_time_simple = end_time_simple - start_time_simple\n",
    "\n",
    "        # Compute evaluation metrics for simple KMeans\n",
    "        silhouette_simple = silhouette_score(features, labels_simple)\n",
    "        calinski_simple = calinski_harabasz_score(features, labels_simple)\n",
    "        davies_simple = davies_bouldin_score(features, labels_simple)\n",
    "\n",
    "        print(f\"Simple KMeans Clustering Metrics:\")\n",
    "        print(f\"  Silhouette Score: {silhouette_simple:.4f}\")\n",
    "        print(f\"  Calinski-Harabasz Index: {calinski_simple:.4f}\")\n",
    "        print(f\"  Davies-Bouldin Index: {davies_simple:.4f}\")\n",
    "        print(f\"  Execution Time: {exec_time_simple:.4f} seconds\")\n",
    "\n",
    "        # Perform GNN-KMeans clustering\n",
    "        print(\"\\nPerforming GNN-KMeans clustering using GNN embeddings...\")\n",
    "        start_time_gnn = time.time()\n",
    "        embeddings = self.get_gnn_embeddings(features_tensor)\n",
    "        kmeans_gnn = KMeans(n_clusters=k, random_state=42)\n",
    "        labels_gnn = kmeans_gnn.fit_predict(embeddings)\n",
    "        end_time_gnn = time.time()\n",
    "        exec_time_gnn = end_time_gnn - start_time_gnn\n",
    "\n",
    "        # Compute evaluation metrics for GNN-KMeans\n",
    "        silhouette_gnn = silhouette_score(embeddings, labels_gnn)\n",
    "        calinski_gnn = calinski_harabasz_score(embeddings, labels_gnn)\n",
    "        davies_gnn = davies_bouldin_score(embeddings, labels_gnn)\n",
    "        energy_gnn = self.calculate_energy_consumption(\n",
    "            num_nodes=features_tensor.shape[0],\n",
    "            num_features=features_tensor.shape[1],\n",
    "            num_edges=self.build_device_graph().size(1) // 2,\n",
    "            num_layers=2,\n",
    "            epochs=200\n",
    "        )\n",
    "\n",
    "        print(f\"GNN-KMeans Clustering Metrics:\")\n",
    "        print(f\"  Silhouette Score: {silhouette_gnn:.4f}\")\n",
    "        print(f\"  Calinski-Harabasz Index: {calinski_gnn:.4f}\")\n",
    "        print(f\"  Davies-Bouldin Index: {davies_gnn:.4f}\")\n",
    "        print(f\"  Execution Time: {exec_time_gnn:.4f} seconds\")\n",
    "        print(f\"  Energy Consumption: {energy_gnn:.4f} J\")\n",
    "\n",
    "        # Store metrics for comparison in a DataFrame\n",
    "        clustering_metrics_df = pd.DataFrame({\n",
    "            'Metric': ['Silhouette Score', 'Calinski-Harabasz Index', 'Davies-Bouldin Index', 'Execution Time (s)', 'Energy Consumption (J)'],\n",
    "            'GNN-KMeans': [silhouette_gnn, calinski_gnn, davies_gnn, exec_time_gnn, energy_gnn]\n",
    "        })\n",
    "\n",
    "        # Save metrics to JSON file\n",
    "        clustering_metrics_file = \"clustering_metrics.json\"\n",
    "        clustering_metrics_df.to_json(clustering_metrics_file, orient='split', indent=4)\n",
    "\n",
    "        print(f\"\\nClustering metrics saved to '{clustering_metrics_file}'\")\n",
    "\n",
    "    def distribute_data(self):\n",
    "        \"\"\"Main method to distribute data among devices and cluster them.\"\"\"\n",
    "        # Load data\n",
    "        train_images_original, train_labels_original, train_images_augmented, train_labels_augmented, test_images, test_labels = self.load_data()\n",
    "\n",
    "        # Combine original and augmented data\n",
    "        train_images = np.concatenate((train_images_original, train_images_augmented), axis=0)\n",
    "        train_labels = np.concatenate((train_labels_original, train_labels_augmented), axis=0)\n",
    "\n",
    "        # Split data among devices\n",
    "        self.devices_df = self.split_dataset_among_devices(train_images, train_labels)\n",
    "\n",
    "        return test_images, test_labels\n",
    "\n",
    "    def clustering_devices(self):\n",
    "        \"\"\"Main method to distribute data among devices and cluster them.\"\"\"\n",
    "        # Perform clustering\n",
    "        clustering_start_time = time.time()\n",
    "        self.gnn_clustering()\n",
    "        clustering_stop_time = time.time()\n",
    "        print(f'Clustering Part Took {abs(clustering_start_time - clustering_stop_time)} seconds to process.')\n",
    "\n",
    "        return self.devices_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a64a76",
   "metadata": {},
   "source": [
    "# Hybrid Data Redistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e499d2d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class HybridDataRedistributor:\n",
    "    def __init__(self, devices_df, dataset_name=\"mnist\", metrics_file='test.json'):\n",
    "        self.devices_df = devices_df.reset_index(drop=True)\n",
    "        self.dataset_name = dataset_name.lower()\n",
    "        self.metrics = {}  # Dictionary to store the results\n",
    "        self.metrics_file = metrics_file.replace('.json', '_redistribution.json')\n",
    "\n",
    "    def calculate_label_distribution(self):\n",
    "        \"\"\"Calculate the label distribution for each device.\"\"\"\n",
    "        label_distribution = {}\n",
    "        total_samples = sum(len(row.local_data) for _, row in self.devices_df.iterrows())\n",
    "\n",
    "        for _, row in self.devices_df.iterrows():\n",
    "            device_label_counts = row.local_data.count_labels()\n",
    "            total_device_samples = sum(device_label_counts.values())\n",
    "            label_distribution[row.device_id] = {\n",
    "                label: count / total_device_samples if total_device_samples > 0 else 0\n",
    "                for label, count in device_label_counts.items()\n",
    "            }\n",
    "\n",
    "        return label_distribution\n",
    "\n",
    "    def calculate_global_distribution(self):\n",
    "        \"\"\"Calculate the global label distribution across all devices.\"\"\"\n",
    "        total_label_counts = Counter()\n",
    "        for _, row in self.devices_df.iterrows():\n",
    "            total_label_counts.update(row.local_data.count_labels())\n",
    "\n",
    "        total_samples = sum(total_label_counts.values())\n",
    "        global_distribution = {\n",
    "            label: count / total_samples if total_samples > 0 else 0\n",
    "            for label, count in total_label_counts.items()\n",
    "        }\n",
    "\n",
    "        return global_distribution\n",
    "\n",
    "    def calculate_kl_divergence(self, device_distributions, global_distribution):\n",
    "        \"\"\"Calculate KL divergence for each device.\"\"\"\n",
    "        kl_divergences = {}\n",
    "\n",
    "        for device_id, device_dist in device_distributions.items():\n",
    "            kl_divergence = 0\n",
    "            for label, p in device_dist.items():\n",
    "                q = global_distribution.get(label, 1e-10)  # Avoid log(0)\n",
    "                if p > 0:\n",
    "                    kl_divergence += p * np.log(p / q)\n",
    "\n",
    "            kl_divergences[device_id] = kl_divergence\n",
    "\n",
    "        return kl_divergences\n",
    "\n",
    "    def summarize_data_volume(self):\n",
    "        \"\"\"Summarize the data volume per device.\"\"\"\n",
    "        data_volumes = {\n",
    "            row.device_id: len(row.local_data)\n",
    "            for _, row in self.devices_df.iterrows()\n",
    "        }\n",
    "        return data_volumes\n",
    "\n",
    "    def summarize_label_presence_by_cluster(self):\n",
    "        \"\"\"Summarize and sort the presence of labels in each cluster.\"\"\"\n",
    "        label_presence = {}\n",
    "\n",
    "        for cluster_id in self.devices_df['cluster'].unique():\n",
    "            cluster_devices = self.devices_df[self.devices_df['cluster'] == cluster_id]\n",
    "            combined_labels = Counter()\n",
    "\n",
    "            for labels_dict in cluster_devices['labels']:\n",
    "                if isinstance(labels_dict, dict):  # Ensure it's a dictionary\n",
    "                    combined_labels.update(labels_dict)\n",
    "\n",
    "            # Sort the labels in ascending order\n",
    "            sorted_labels = dict(sorted(combined_labels.items()))\n",
    "            label_presence[cluster_id] = sorted_labels\n",
    "\n",
    "        return label_presence\n",
    "\n",
    "    def assign_labels_by_density(self):\n",
    "        \"\"\"Assign labels to clusters based on density (starting from the highest density).\"\"\"\n",
    "        # Calculate total occurrences of each label across all devices\n",
    "        total_label_counts = self.calculate_total_label_counts()\n",
    "\n",
    "        # Sort labels by their density in descending order\n",
    "        sorted_labels = sorted(total_label_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Initialize the cluster-to-label mapping\n",
    "        num_clusters = len(self.devices_df['cluster'].unique())\n",
    "        cluster_labels = {i: [] for i in range(num_clusters)}\n",
    "\n",
    "        # Distribute labels to clusters\n",
    "        for label, _ in sorted_labels:\n",
    "            # Find the cluster with the fewest total assigned labels\n",
    "            cluster_id = min(cluster_labels.keys(), key=lambda k: len(cluster_labels[k]))\n",
    "            cluster_labels[cluster_id].append(label)\n",
    "\n",
    "        print(f\"Assigned Labels for Clusters (by density): {cluster_labels}\")\n",
    "        return cluster_labels\n",
    "\n",
    "    def print_cluster_summary(self, label_presence):\n",
    "        \"\"\"Print the summary of label presence in clusters.\"\"\"\n",
    "        print(\"\\nCluster Summary:\\n\" + \"-\" * 30)\n",
    "\n",
    "        for cluster_id, labels in sorted(label_presence.items()):\n",
    "            print(f\"Cluster {cluster_id}:\")\n",
    "            for label, count in labels.items():\n",
    "                print(f\"  {label}: {count}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "    def hybrid_data_redistribution(self, percentage_threshold=0.3):\n",
    "        \"\"\"Perform data redistribution to balance labels across clusters.\"\"\"\n",
    "        cluster_labels = self.assign_labels_by_density()\n",
    "        total_label_counts = self.calculate_total_label_counts()\n",
    "        print(f\"Total label counts across all devices: {total_label_counts}\\n\")\n",
    "\n",
    "        device_data_info = {\n",
    "            row.device_id: {\n",
    "                'local_data': row.local_data,\n",
    "                'cluster': row.cluster,\n",
    "                'label_counts': row.local_data.count_labels(),\n",
    "                'energy_usage': row.energy_usage,\n",
    "                'bandwidth_usage': row.bandwidth_usage,\n",
    "                'bandwidth': row.bandwidth,\n",
    "                'cpu_power': row.cpu_power,\n",
    "            } for _, row in self.devices_df.iterrows()\n",
    "        }\n",
    "\n",
    "        total_time_delay = 0\n",
    "        total_energy_consumption = 0\n",
    "        total_bandwidth_usage = 0\n",
    "        image_size_in_bytes = self.get_image_size_in_bytes()\n",
    "\n",
    "        for cluster_id, labels in cluster_labels.items():\n",
    "            print(f\"\\nProcessing Cluster {cluster_id} with assigned labels: {labels}\")\n",
    "\n",
    "            cluster_devices = self.devices_df[self.devices_df['cluster'] == cluster_id]\n",
    "            combined_label_counts = Counter()\n",
    "            for device in cluster_devices['local_data']:\n",
    "                combined_label_counts.update(device.count_labels())\n",
    "\n",
    "            for label in labels:\n",
    "                current_label_count = combined_label_counts.get(label, 0)\n",
    "                total_label_count_in_dataset = total_label_counts.get(label, 1)\n",
    "                label_percentage = (current_label_count / total_label_count_in_dataset) if total_label_count_in_dataset > 0 else 0\n",
    "\n",
    "                if label_percentage < percentage_threshold:\n",
    "                    shortage = int((percentage_threshold * total_label_count_in_dataset) - current_label_count)\n",
    "                    print(f\"Cluster {cluster_id} needs {shortage} additional samples of label '{label}'.\")\n",
    "\n",
    "                    donor_devices = [\n",
    "                        (dev_id, info) for dev_id, info in device_data_info.items()\n",
    "                        if info['label_counts'].get(label, 0) > 0 and info['cluster'] != cluster_id\n",
    "                    ]\n",
    "                    donor_devices.sort(key=lambda x: (x[1]['label_counts'].get(label, 0), x[1]['bandwidth']), reverse=True)\n",
    "\n",
    "                    for donor_device_id, donor_info in donor_devices:\n",
    "                        available_samples = donor_info['label_counts'].get(label, 0)\n",
    "                        request_count = min(shortage, available_samples)\n",
    "\n",
    "                        if request_count > 0:\n",
    "                            transfer_time, energy_consumed, bandwidth_used = self.simulate_data_transfer(\n",
    "                                donor_device_id, cluster_devices, request_count, image_size_in_bytes,\n",
    "                                donor_info['bandwidth'], 1e-9, device_data_info\n",
    "                            )\n",
    "\n",
    "                            total_time_delay += transfer_time\n",
    "                            total_energy_consumption += energy_consumed\n",
    "                            total_bandwidth_usage += bandwidth_used\n",
    "\n",
    "                            self.update_devices_after_transfer(\n",
    "                                donor_device_id, donor_info['local_data'], cluster_devices, label, request_count,\n",
    "                                image_size_in_bytes, device_data_info\n",
    "                            )\n",
    "\n",
    "                            shortage -= request_count\n",
    "                            if shortage <= 0:\n",
    "                                break\n",
    "\n",
    "        print(f\"\\nTotal Time Delay: {total_time_delay:.2f} seconds\")\n",
    "        print(f\"Total Energy Consumption: {total_energy_consumption:.6f} joules\")\n",
    "        print(f\"Total Bandwidth Usage: {total_bandwidth_usage / (1024 ** 2):.2f} MB\")\n",
    "\n",
    "        for device_id, info in device_data_info.items():\n",
    "            idx = self.devices_df.index[self.devices_df['device_id'] == device_id][0]\n",
    "            self.devices_df.at[idx, 'energy_usage'] = info['energy_usage']\n",
    "            self.devices_df.at[idx, 'bandwidth_usage'] = info['bandwidth_usage']\n",
    "            self.devices_df.at[idx, 'local_data'] = info['local_data']\n",
    "            self.devices_df.at[idx, 'labels'] = info['local_data'].count_labels()\n",
    "\n",
    "        return total_bandwidth_usage, total_energy_consumption, total_time_delay\n",
    "\n",
    "    def calculate_total_label_counts(self):\n",
    "        \"\"\"Calculate the total label counts across all devices in devices_df.\"\"\"\n",
    "        total_label_counts = Counter()\n",
    "        for _, row in self.devices_df.iterrows():\n",
    "            device_labels = row.local_data.count_labels()\n",
    "            total_label_counts.update(device_labels)\n",
    "        return total_label_counts\n",
    "\n",
    "    def get_image_size_in_bytes(self):\n",
    "        \"\"\"Get the image size in bytes based on the dataset.\"\"\"\n",
    "        if self.dataset_name in [\"mnist\", \"fashion_mnist\"]:\n",
    "            return 28 * 28\n",
    "        else:\n",
    "            return 32 * 32 * 3\n",
    "\n",
    "    def simulate_data_transfer(self, donor_device_id, cluster_devices, request_count, image_size_in_bytes,\n",
    "                               donor_bandwidth, energy_per_byte, device_data_info):\n",
    "        \"\"\"\n",
    "        Simulate data transfer and calculate time delay, energy consumption, and bandwidth usage,\n",
    "        incorporating CPU power and bandwidth limitations.\n",
    "        \"\"\"\n",
    "        total_data_size = request_count * image_size_in_bytes  # Total data size in bytes\n",
    "\n",
    "        # Donor device CPU power and bandwidth\n",
    "        donor_info = device_data_info[donor_device_id]\n",
    "        donor_cpu_power = donor_info['cpu_power']\n",
    "        donor_bandwidth = donor_info['bandwidth']  # Bandwidth in Mbps\n",
    "\n",
    "        # Recipient devices' CPU power and bandwidth\n",
    "        recipient_bandwidths = cluster_devices['bandwidth'].values\n",
    "        recipient_cpu_powers = cluster_devices['cpu_power'].values\n",
    "\n",
    "        # Effective bandwidth: consider the lowest bandwidth between donor and recipients\n",
    "        effective_bandwidth = min(donor_bandwidth, recipient_bandwidths.min())  # in Mbps\n",
    "\n",
    "        # Compute transfer time based on effective bandwidth\n",
    "        transfer_time = total_data_size / (effective_bandwidth * (1024 ** 2) / 8)  # Convert Mbps to bytes/sec\n",
    "\n",
    "        # Factor in the CPU processing time for both donor and recipients\n",
    "        # Simplified: Processing time = Data size / CPU power\n",
    "        processing_time_donor = total_data_size / (donor_cpu_power * 1e9)  # CPU power in GHz\n",
    "        processing_time_recipients = total_data_size / (recipient_cpu_powers.min() * 1e9)\n",
    "\n",
    "        # Total transfer time includes network transfer and processing delays\n",
    "        total_transfer_time = transfer_time + processing_time_donor + processing_time_recipients\n",
    "\n",
    "        # Energy consumption for data transfer\n",
    "        energy_consumed_transfer = total_data_size * energy_per_byte  # Energy per byte transferred\n",
    "        energy_consumed_processing_donor = processing_time_donor * donor_cpu_power * 1e9 * energy_per_byte\n",
    "        energy_consumed_processing_recipients = (\n",
    "            processing_time_recipients * recipient_cpu_powers.mean() * 1e9 * energy_per_byte\n",
    "        )\n",
    "\n",
    "        total_energy_consumption = (\n",
    "            energy_consumed_transfer + energy_consumed_processing_donor + energy_consumed_processing_recipients\n",
    "        )\n",
    "\n",
    "        # Bandwidth usage\n",
    "        total_bandwidth_used = total_data_size  # Total bytes transferred\n",
    "\n",
    "        # Update donor metrics\n",
    "        donor_info['energy_usage'] += (energy_consumed_transfer / 2) + energy_consumed_processing_donor\n",
    "        donor_info['bandwidth_usage'] += total_bandwidth_used / 2  # Half bandwidth usage for donor\n",
    "\n",
    "        # Update recipient devices' metrics\n",
    "        num_recipients = len(cluster_devices)\n",
    "        energy_per_recipient = (energy_consumed_transfer / 2) / num_recipients\n",
    "        bandwidth_per_recipient = (total_bandwidth_used / 2) / num_recipients\n",
    "\n",
    "        for _, device_row in cluster_devices.iterrows():\n",
    "            device_id = device_row.device_id\n",
    "            recipient_info = device_data_info[device_id]\n",
    "            recipient_info['energy_usage'] += energy_per_recipient + energy_consumed_processing_recipients / num_recipients\n",
    "            recipient_info['bandwidth_usage'] += bandwidth_per_recipient\n",
    "\n",
    "        return total_transfer_time, total_energy_consumption, total_bandwidth_used\n",
    "\n",
    "    def update_devices_after_transfer(self, donor_device_id, donor_device, cluster_devices, label, request_count,\n",
    "                                      image_size_in_bytes, device_data_info):\n",
    "        \"\"\"Update devices after data transfer.\"\"\"\n",
    "        # Get the images and labels to transfer\n",
    "        indices = np.where(donor_device.labels == label)[0][:request_count]\n",
    "        images_to_transfer = donor_device.images[indices]\n",
    "        labels_to_transfer = donor_device.labels[indices]\n",
    "\n",
    "        # Distribute the samples to the devices in the cluster\n",
    "        num_devices = len(cluster_devices)\n",
    "        samples_per_device = request_count // num_devices\n",
    "        remainder = request_count % num_devices\n",
    "\n",
    "        start_idx = 0\n",
    "        for idx, (_, device_row) in enumerate(cluster_devices.iterrows()):\n",
    "            device = device_row.local_data\n",
    "            device_id = device_row.device_id\n",
    "            device_samples = samples_per_device + (1 if idx < remainder else 0)\n",
    "\n",
    "            if device_samples > 0:\n",
    "                end_idx = start_idx + device_samples\n",
    "                # Add samples to the recipient device\n",
    "                device.add_samples(images_to_transfer[start_idx:end_idx],\n",
    "                                   labels_to_transfer[start_idx:end_idx])\n",
    "\n",
    "                # Update device data info\n",
    "                device_data_info[device_id]['local_data'] = device\n",
    "                device_data_info[device_id]['label_counts'][label] += device_samples\n",
    "\n",
    "                start_idx = end_idx\n",
    "\n",
    "        # Remove samples from the donor device\n",
    "        donor_device.remove_samples(label, request_count)\n",
    "        device_data_info[donor_device_id]['local_data'] = donor_device\n",
    "        device_data_info[donor_device_id]['label_counts'][label] -= request_count\n",
    "\n",
    "    def save_metrics_to_json(self):\n",
    "        \"\"\"Save the collected metrics to a JSON file.\"\"\"\n",
    "        def convert_keys_to_serializable(data):\n",
    "            \"\"\"Recursively convert keys in dictionaries to serializable types.\"\"\"\n",
    "            if isinstance(data, dict):\n",
    "                return {str(key): convert_keys_to_serializable(value) for key, value in data.items()}\n",
    "            elif isinstance(data, list):\n",
    "                return [convert_keys_to_serializable(element) for element in data]\n",
    "            else:\n",
    "                return data\n",
    "\n",
    "        # Convert the metrics dictionary to ensure all keys are serializable\n",
    "        serializable_metrics = convert_keys_to_serializable(self.metrics)        \n",
    "        with open(self.metrics_file, 'w') as f:\n",
    "            json.dump(serializable_metrics, f, indent=4)\n",
    "\n",
    "    def redistribute_data(self, percentage_threshold=0.3):\n",
    "        \"\"\"Main method to perform hybrid data redistribution.\"\"\"\n",
    "        # Show the local datasets before data redistribution\n",
    "        label_presence = self.summarize_label_presence_by_cluster()\n",
    "        self.print_cluster_summary(label_presence)\n",
    "\n",
    "        print(\"\\nLocal datasets before hybrid data redistribution:\")\n",
    "        print(self.devices_df[['device_id', 'cpu_power', 'bandwidth', 'local_storage', 'disk_usage', 'cluster',\n",
    "                               'energy_usage', 'bandwidth_usage']])\n",
    "        \n",
    "        # Calculate metrics before redistribution\n",
    "        label_distribution_before = self.calculate_label_distribution()\n",
    "        global_distribution = self.calculate_global_distribution()\n",
    "        kl_divergence_before = self.calculate_kl_divergence(label_distribution_before, global_distribution)\n",
    "        data_volume_before = self.summarize_data_volume()\n",
    "\n",
    "        # Store pre-redistribution metrics\n",
    "        self.metrics['before'] = {\n",
    "            'label_distribution': label_distribution_before,\n",
    "            'kl_divergence': kl_divergence_before,\n",
    "            'data_volume': data_volume_before,\n",
    "        }        \n",
    "\n",
    "        # Perform hybrid data redistribution\n",
    "        total_bandwidth_usage, total_energy_consumption, total_time_delay = self.hybrid_data_redistribution(percentage_threshold=percentage_threshold)\n",
    "\n",
    "        # Calculate metrics after redistribution\n",
    "        label_distribution_after = self.calculate_label_distribution()\n",
    "        kl_divergence_after = self.calculate_kl_divergence(label_distribution_after, global_distribution)\n",
    "        data_volume_after = self.summarize_data_volume()\n",
    "\n",
    "        # Store post-redistribution metrics\n",
    "        self.metrics['after'] = {\n",
    "            'label_distribution': label_distribution_after,\n",
    "            'kl_divergence': kl_divergence_after,\n",
    "            'data_volume': data_volume_after,\n",
    "            'total_data_transferred': total_bandwidth_usage,\n",
    "        }\n",
    "\n",
    "        # Calculate resource impact\n",
    "        self.metrics['impact'] = {\n",
    "            'energy_consumption': self.devices_df['energy_usage'].sum(),\n",
    "            'bandwidth_usage': self.devices_df['bandwidth_usage'].sum(),\n",
    "        }\n",
    "\n",
    "        # Save metrics to JSON\n",
    "        self.save_metrics_to_json()\n",
    "\n",
    "        # Show the local datasets after data redistribution\n",
    "        label_presence = self.summarize_label_presence_by_cluster()\n",
    "        self.print_cluster_summary(label_presence)\n",
    "\n",
    "        print(\"\\nLocal datasets after hybrid data redistribution:\")\n",
    "        print(self.devices_df[['device_id', 'cpu_power', 'bandwidth', 'local_storage', 'disk_usage', 'cluster',\n",
    "                               'energy_usage', 'bandwidth_usage']])\n",
    "\n",
    "        return self.devices_df, label_presence "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b860f0",
   "metadata": {},
   "source": [
    "# DRL Assignment using Proximal Policy Optimization algorithm (PPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5c4e6f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "# Define a callback for logging and learning rate scheduling\n",
    "\n",
    "class CustomCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    A custom callback for logging and learning rate scheduling.\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.scheduler = None\n",
    "\n",
    "    def _on_training_start(self) -> None:\n",
    "        \"\"\"\n",
    "        Called before the first rollout starts.\n",
    "        Initialize the learning rate scheduler here since `self.model` is now available.\n",
    "        \"\"\"\n",
    "        self.scheduler = StepLR(self.model.policy.optimizer, step_size=1000, gamma=0.95)\n",
    "        if self.verbose > 0:\n",
    "            logging.info(\"Learning rate scheduler initialized.\")\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        \"\"\"\n",
    "        Called at each step after the action is taken.\n",
    "        Step the scheduler at desired intervals.\n",
    "        \"\"\"\n",
    "        if self.scheduler and self.num_timesteps % 1000 == 0:\n",
    "            self.scheduler.step()\n",
    "            if self.verbose > 0:\n",
    "                current_lr = self.scheduler.get_last_lr()[0]\n",
    "                logging.info(f\"Step {self.num_timesteps}: Learning rate updated to {current_lr:.6f}\")\n",
    "        return True  # Returning False would stop training\n",
    "\n",
    "    def _on_training_end(self) -> None:\n",
    "        \"\"\"\n",
    "        Called after training ends.\n",
    "        \"\"\"\n",
    "        if self.verbose > 0:\n",
    "            logging.info(\"Training completed.\")\n",
    "\n",
    "class ClusterAssignmentEnv(gym.Env):\n",
    "    def __init__(self, cluster_bandwidth, edge_server_capacities, devices_df):\n",
    "        super(ClusterAssignmentEnv, self).__init__()\n",
    "        self.devices_df = devices_df.reset_index(drop=True)\n",
    "        self.cluster_bandwidth = cluster_bandwidth\n",
    "        self.edge_server_capacities = edge_server_capacities\n",
    "        self.num_clusters = len(cluster_bandwidth)\n",
    "        self.num_servers = len(edge_server_capacities)\n",
    "\n",
    "        # Define action and observation spaces\n",
    "        self.action_space = spaces.MultiDiscrete([self.num_servers] * self.num_clusters)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0,\n",
    "            high=1,\n",
    "            shape=(self.num_clusters + self.num_servers * 2,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the environment and return the initial state.\"\"\"\n",
    "        self.state = self._get_state()\n",
    "        return self.state\n",
    "\n",
    "    def _get_state(self):\n",
    "        \"\"\"Generate a normalized state representation.\"\"\"\n",
    "        normalized_bandwidth = self.cluster_bandwidth / (np.max(self.cluster_bandwidth) + 1e-6)\n",
    "        normalized_capacities = self.edge_server_capacities / (np.max(self.edge_server_capacities) + 1e-6)\n",
    "\n",
    "        # Calculate current server loads\n",
    "        current_server_loads = np.zeros(self.num_servers)\n",
    "        assigned_clusters = self.devices_df['assigned_servers']\n",
    "        for cluster_idx in range(self.num_clusters):\n",
    "            server_idx = assigned_clusters[cluster_idx]\n",
    "            if server_idx >= 0:\n",
    "                current_server_loads[server_idx] += self.cluster_bandwidth[cluster_idx]\n",
    "\n",
    "        # Calculate unused capacities\n",
    "        unused_capacities = self.edge_server_capacities - current_server_loads\n",
    "        normalized_unused_capacities = unused_capacities / (np.max(self.edge_server_capacities) + 1e-6)\n",
    "\n",
    "        state = np.concatenate([\n",
    "            normalized_bandwidth,\n",
    "            normalized_capacities,\n",
    "            normalized_unused_capacities\n",
    "        ]).astype(np.float32)\n",
    "\n",
    "        return state\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Execute an action and assign clusters to servers.\"\"\"\n",
    "        assignments = dict(zip(range(self.num_clusters), action))\n",
    "        server_loads = np.zeros(self.num_servers)\n",
    "\n",
    "        for cluster_idx, server_idx in assignments.items():\n",
    "            server_loads[server_idx] += self.cluster_bandwidth[cluster_idx]\n",
    "\n",
    "        reward = self._calculate_reward(server_loads)\n",
    "        done = True  # Single-step environment\n",
    "        info = {\n",
    "            'server_loads': server_loads,\n",
    "            'cluster_assignments': assignments,\n",
    "        }\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def _calculate_reward(self, server_loads):\n",
    "        \"\"\"Calculate reward based on server loads.\"\"\"\n",
    "        total_capacity = np.sum(self.edge_server_capacities)\n",
    "        total_load = np.sum(server_loads)\n",
    "\n",
    "        # Overload penalty: Penalize loads exceeding capacity\n",
    "        overload = np.maximum(0, server_loads - self.edge_server_capacities)\n",
    "        overload_penalty = np.sum(overload) / (total_capacity + 1e-6)  # Total overload as a fraction\n",
    "\n",
    "        # Load variance penalty: Penalize imbalances in server loads\n",
    "        load_variance = np.var(server_loads)\n",
    "        load_variance_penalty = load_variance / (total_load + 1e-6)\n",
    "\n",
    "        # Resource utilization incentive: Encourage maximizing server usage\n",
    "        resource_utilization = total_load / total_capacity\n",
    "\n",
    "        # Further Optimized Reward calculation with better balance\n",
    "        reward = (\n",
    "            25 * resource_utilization\n",
    "            - 3 * overload_penalty\n",
    "            - 2 * load_variance_penalty\n",
    "        )\n",
    "\n",
    "        # Ensure non-negative reward\n",
    "        reward = max(reward, 0.0)\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def evaluate(self, assignments):\n",
    "        \"\"\"Evaluate a given set of assignments and return metrics.\"\"\"\n",
    "        server_loads = np.zeros(self.num_servers)\n",
    "        for cluster_idx, server_idx in assignments.items():\n",
    "            if server_idx >= 0:\n",
    "                server_loads[server_idx] += self.cluster_bandwidth[cluster_idx]\n",
    "\n",
    "        overload = np.maximum(0, server_loads - self.edge_server_capacities)\n",
    "        overload_penalty = np.sum(overload) / (np.sum(self.edge_server_capacities) + 1e-6)\n",
    "\n",
    "        load_variance = np.var(server_loads)\n",
    "        load_variance_penalty = load_variance / (np.sum(server_loads) + 1e-6)\n",
    "\n",
    "        resource_utilization = np.sum(server_loads) / np.sum(self.edge_server_capacities)\n",
    "\n",
    "        # Optimized Reward calculation with adjusted weights\n",
    "        reward = (\n",
    "            10 * resource_utilization\n",
    "            - 5 * overload_penalty\n",
    "            - 3 * load_variance_penalty\n",
    "        )\n",
    "\n",
    "        # Ensure non-negative reward\n",
    "        # reward = max(reward, 0.0)\n",
    "\n",
    "        metrics = {\n",
    "            'overload_penalty': overload_penalty,\n",
    "            'load_variance_penalty': load_variance_penalty,\n",
    "            'resource_utilization': resource_utilization,\n",
    "            'server_loads': server_loads.tolist()\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "def train_cluster_assignment_agent(cluster_bandwidth, edge_server_capacities, devices_df, timesteps=10000, metrics_file='metrics.json'):\n",
    "    \"\"\"Train a PPO-based agent for the cluster assignment problem.\"\"\"\n",
    "    if 'assigned_servers' not in devices_df.columns:\n",
    "        devices_df['assigned_servers'] = -1\n",
    "\n",
    "    cluster_env = ClusterAssignmentEnv(cluster_bandwidth, edge_server_capacities, devices_df)\n",
    "\n",
    "    cluster_model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        cluster_env,\n",
    "        verbose=1,\n",
    "        learning_rate=3e-4,\n",
    "        ent_coef=0.01,        # Encourage exploration\n",
    "        n_steps=2048,\n",
    "        batch_size=64,\n",
    "        clip_range=0.1,       # Stability in updates\n",
    "        max_grad_norm=0.5,    # Prevent exploding gradients\n",
    "        gae_lambda=0.95,      # GAE parameter\n",
    "        vf_coef=0.5,          # Value function coefficient\n",
    "        tensorboard_log=\"./cluster_tensorboard/\"\n",
    "    )\n",
    "\n",
    "    # Configure logging\n",
    "    logging.basicConfig(filename='cluster_training.log', level=logging.INFO)\n",
    "\n",
    "    # Initialize the custom callback\n",
    "    custom_callback = CustomCallback(verbose=1)  # Set verbose=1 for detailed logging\n",
    "\n",
    "    print(f\"Starting cluster assignment training for {timesteps} timesteps.\")\n",
    "    cluster_model.learn(total_timesteps=timesteps, callback=custom_callback)\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = metrics_file.replace('.json', '_cluster_assignment_agent')\n",
    "    cluster_model.save(model_filename)\n",
    "    print(f\"Cluster Assignment Agent trained and saved to {model_filename}.\")\n",
    "\n",
    "    # Evaluate the trained model\n",
    "    state = cluster_env.reset()\n",
    "    action, _ = cluster_model.predict(state)\n",
    "    evaluation_state, evaluation_reward, _, evaluation_info = cluster_env.step(action)\n",
    "    print(f\"Evaluation Reward: {evaluation_reward}\")\n",
    "    print(f\"Evaluation Info: {evaluation_info}\")\n",
    "\n",
    "    # **Fix: Convert action array to assignments dict before evaluation**\n",
    "    assignments = dict(zip(range(cluster_env.num_clusters), action))\n",
    "    evaluation_metrics = cluster_env.evaluate(assignments)\n",
    "    print(f\"Evaluation Metrics: {evaluation_metrics}\")\n",
    "\n",
    "    # Optionally, log evaluation metrics\n",
    "    with open(metrics_file.replace('.json', '_cluster_evaluation.json'), 'w') as f:\n",
    "        json.dump(evaluation_metrics, f, indent=4)\n",
    "\n",
    "    return cluster_model\n",
    "\n",
    "class DeviceSchedulingEnv(gym.Env):\n",
    "    def __init__(self, devices_df, cluster_to_server_map):\n",
    "        super(DeviceSchedulingEnv, self).__init__()\n",
    "        self.devices_df = devices_df.reset_index(drop=True)\n",
    "        self.cluster_to_server_map = cluster_to_server_map\n",
    "\n",
    "        # Number of devices\n",
    "        self.num_devices = len(devices_df)\n",
    "\n",
    "        # Define action and observation spaces\n",
    "        self.action_space = spaces.MultiBinary(self.num_devices)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0,\n",
    "            high=1,\n",
    "            shape=(self.num_devices * 3,),  # Bandwidth, energy, and diversity scores\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        # Initialize potential-based reward shaping\n",
    "        self.previous_potential = 0.0\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the environment and return the initial state.\"\"\"\n",
    "        self.state = self._get_state()\n",
    "        self.previous_potential = self.calculate_potential(self.state)\n",
    "        return self.state\n",
    "\n",
    "    def _get_state(self):\n",
    "        \"\"\"Generate a normalized state representation.\"\"\"\n",
    "        bandwidth_usage = self.devices_df['bandwidth_usage'].values\n",
    "        energy_usage = self.devices_df['energy_usage'].values\n",
    "\n",
    "        # Normalize bandwidth and energy usage\n",
    "        normalized_bandwidth_usage = bandwidth_usage / (np.max(bandwidth_usage) + 1e-6)\n",
    "        normalized_energy_usage = energy_usage / (np.max(energy_usage) + 1e-6)\n",
    "\n",
    "        # Generate diversity scores (mocked for now)\n",
    "        diversity_scores = np.random.random(self.num_devices)\n",
    "\n",
    "        # Combine into a single state\n",
    "        state = np.concatenate([normalized_bandwidth_usage, normalized_energy_usage, diversity_scores]).astype(np.float32)\n",
    "        return state\n",
    "\n",
    "    def _calculate_intrinsic_reward(self, state, next_state):\n",
    "        \"\"\"Calculate intrinsic reward based on state novelty.\"\"\"\n",
    "        prediction_error = np.linalg.norm(next_state - self.predict_next_state(state))\n",
    "        intrinsic_reward = min(prediction_error, 1.0)  # Cap intrinsic rewards\n",
    "        return intrinsic_reward\n",
    "\n",
    "    def predict_next_state(self, state):\n",
    "        \"\"\"Placeholder for a predictive model to estimate the next state.\"\"\"\n",
    "        # Implement a simple prediction or use a trained model\n",
    "        return state  # For simplicity, assume no change\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Perform an action and return the next state, reward, and status.\"\"\"\n",
    "        selected_devices = np.where(action == 1)[0]\n",
    "\n",
    "        # Simulate training and calculate performance metrics\n",
    "        accuracy_improvement, communication_cost, energy_consumption = self._simulate_training(selected_devices)\n",
    "\n",
    "        # Normalize components\n",
    "        normalized_accuracy = accuracy_improvement\n",
    "        normalized_communication = communication_cost / (self.devices_df['bandwidth_usage'].sum() + 1e-6)\n",
    "        normalized_energy = energy_consumption / (self.devices_df['energy_usage'].sum() + 1e-6)\n",
    "\n",
    "        # Calculate intrinsic reward\n",
    "        current_potential = self.calculate_potential(self.state)\n",
    "        intrinsic_reward = self._calculate_intrinsic_reward(self.state, self._get_state())\n",
    "        self.previous_potential = current_potential\n",
    "\n",
    "        # Optimized Reward calculation with intrinsic motivation\n",
    "        reward = (\n",
    "            25 * normalized_accuracy\n",
    "            - 3 * normalized_communication\n",
    "            - 2 * normalized_energy\n",
    "            + intrinsic_reward  # Add intrinsic reward\n",
    "        )\n",
    "        reward = max(reward, 0.0)  # Ensure reward is non-negative\n",
    "\n",
    "        self.state = self._get_state()  # Update the state\n",
    "        done = True  # Single-step environment\n",
    "\n",
    "        info = {\n",
    "            'selected_devices': selected_devices.tolist(),\n",
    "            'accuracy_improvement': accuracy_improvement,\n",
    "            'communication_cost': communication_cost,\n",
    "            'energy_consumption': energy_consumption,\n",
    "            'intrinsic_reward': intrinsic_reward,\n",
    "        }\n",
    "\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def calculate_potential(self, state):\n",
    "        \"\"\"Calculate potential based on the current state.\"\"\"\n",
    "        return np.sum(state)  # Simple potential function\n",
    "\n",
    "    def _simulate_training(self, selected_devices):\n",
    "        \"\"\"Simulate training metrics.\"\"\"\n",
    "        num_selected = len(selected_devices)\n",
    "        accuracy_improvement = num_selected / (self.num_devices + 1e-6)  # Normalize by number of devices\n",
    "        communication_cost = np.sum(self.devices_df.loc[selected_devices, 'bandwidth_usage'].values)\n",
    "        energy_consumption = np.sum(self.devices_df.loc[selected_devices, 'energy_usage'].values)\n",
    "\n",
    "        return accuracy_improvement, communication_cost, energy_consumption\n",
    "\n",
    "    def evaluate(self, action):\n",
    "        \"\"\"Evaluate a given action.\"\"\"\n",
    "        selected_devices = np.where(action == 1)[0]\n",
    "        accuracy_improvement, communication_cost, energy_consumption = self._simulate_training(selected_devices)\n",
    "\n",
    "        normalized_accuracy = accuracy_improvement\n",
    "        normalized_communication = communication_cost / (self.devices_df['bandwidth_usage'].sum() + 1e-6)\n",
    "        normalized_energy = energy_consumption / (self.devices_df['energy_usage'].sum() + 1e-6)\n",
    "\n",
    "        # Calculate intrinsic reward\n",
    "        current_potential = self.calculate_potential(self._get_state())\n",
    "        intrinsic_reward = self._calculate_intrinsic_reward(self.state, self._get_state())\n",
    "\n",
    "        reward = (\n",
    "            25 * normalized_accuracy\n",
    "            - 3 * normalized_communication\n",
    "            - 2 * normalized_energy\n",
    "            + intrinsic_reward\n",
    "        )\n",
    "        reward = max(reward, 0.0)\n",
    "\n",
    "        metrics = {\n",
    "            'accuracy_improvement': accuracy_improvement,\n",
    "            'communication_cost': communication_cost,\n",
    "            'energy_consumption': energy_consumption,\n",
    "            'intrinsic_reward': intrinsic_reward,\n",
    "            'reward': reward,\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "def train_device_scheduling_agent(devices_df, timesteps=10000, metrics_file='test.json', cluster_to_server_map=None):\n",
    "    \"\"\"\n",
    "    Train the PPO-based agent for device scheduling.\n",
    "    \"\"\"\n",
    "    if cluster_to_server_map is None:\n",
    "        raise ValueError(\"cluster_to_server_map is required for DeviceSchedulingEnv initialization.\")\n",
    "\n",
    "    # Initialize the environment\n",
    "    env = DeviceSchedulingEnv(devices_df, cluster_to_server_map)\n",
    "\n",
    "    # Initialize PPO model\n",
    "    scheduling_model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        verbose=1,\n",
    "        learning_rate=3e-4,\n",
    "        n_steps=2048,\n",
    "        batch_size=64,\n",
    "        n_epochs=10,\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.2,\n",
    "        vf_coef=0.5,\n",
    "        ent_coef=0.02,\n",
    "        max_grad_norm=0.5\n",
    "    )\n",
    "\n",
    "    print(f\"Starting device scheduling training for {timesteps} timesteps.\")\n",
    "    scheduling_model.learn(total_timesteps=timesteps)\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = metrics_file.replace('.json', '') + \"_device_scheduling_agent\"\n",
    "    scheduling_model.save(model_filename)\n",
    "    print(f\"Device Scheduling Agent trained and saved to {model_filename}.\")\n",
    "\n",
    "    # Perform evaluation\n",
    "    state = env.reset()\n",
    "    action, _ = scheduling_model.predict(state)\n",
    "    evaluation_metrics = env.evaluate(action)\n",
    "    print(f\"Final Evaluation Metrics: {evaluation_metrics}\")\n",
    "\n",
    "    # Save evaluation metrics\n",
    "    with open(metrics_file.replace('.json', '_scheduling_evaluation.json'), 'w') as f:\n",
    "        import json\n",
    "        json.dump(evaluation_metrics, f, indent=4)\n",
    "\n",
    "    return scheduling_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb0f549",
   "metadata": {},
   "source": [
    "# Semi-Synchronous Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4155297b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# MODELS\n",
    "# CIFAR-10\n",
    "# Models : https://github.com/kuangliu/pytorch-cifar\n",
    "\n",
    "'''DLA in PyTorch CIFAR-10\n",
    "\n",
    "Reference:\n",
    "    Deep Layer Aggregation. https://arxiv.org/abs/1707.06484\n",
    "'''\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class Root(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1):\n",
    "        super(Root, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size,\n",
    "            stride=1, padding=(kernel_size - 1) // 2, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, xs):\n",
    "        x = torch.cat(xs, 1)\n",
    "        out = F.relu(self.bn(self.conv(x)))\n",
    "        return out\n",
    "\n",
    "class Tree(nn.Module):\n",
    "    def __init__(self, block, in_channels, out_channels, level=1, stride=1):\n",
    "        super(Tree, self).__init__()\n",
    "        self.level = level\n",
    "        if level == 1:\n",
    "            self.root = Root(2*out_channels, out_channels)\n",
    "            self.left_node = block(in_channels, out_channels, stride=stride)\n",
    "            self.right_node = block(out_channels, out_channels, stride=1)\n",
    "        else:\n",
    "            self.root = Root((level+2)*out_channels, out_channels)\n",
    "            for i in reversed(range(1, level)):\n",
    "                subtree = Tree(block, in_channels, out_channels,\n",
    "                               level=i, stride=stride)\n",
    "                self.__setattr__('level_%d' % i, subtree)\n",
    "            self.prev_root = block(in_channels, out_channels, stride=stride)\n",
    "            self.left_node = block(out_channels, out_channels, stride=1)\n",
    "            self.right_node = block(out_channels, out_channels, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        xs = [self.prev_root(x)] if self.level > 1 else []\n",
    "        for i in reversed(range(1, self.level)):\n",
    "            level_i = self.__getattr__('level_%d' % i)\n",
    "            x = level_i(x)\n",
    "            xs.append(x)\n",
    "        x = self.left_node(x)\n",
    "        xs.append(x)\n",
    "        x = self.right_node(x)\n",
    "        xs.append(x)\n",
    "        out = self.root(xs)\n",
    "        return out\n",
    "\n",
    "class DLA(nn.Module):\n",
    "    def __init__(self, block=BasicBlock, num_classes=10):\n",
    "        super(DLA, self).__init__()\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.layer3 = Tree(block,  32,  64, level=1, stride=1)\n",
    "        self.layer4 = Tree(block,  64, 128, level=2, stride=2)\n",
    "        self.layer5 = Tree(block, 128, 256, level=2, stride=2)\n",
    "        self.layer6 = Tree(block, 256, 512, level=1, stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.base(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "############################################\n",
    "\n",
    "# MNIST & Fashion MNIST\n",
    "\n",
    "# Define BasicBlock for DLA if not already defined\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "    \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "    \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "    \n",
    "        return out\n",
    "\n",
    "# Revised Bottleneck\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        inter_channels = 4 * growth_rate\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, inter_channels, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(inter_channels)\n",
    "        self.conv2 = nn.Conv2d(inter_channels, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = torch.cat((x, out), 1)\n",
    "        return out\n",
    "\n",
    "# Revised SingleLayer\n",
    "class SingleLayer(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super(SingleLayer, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = torch.cat((x, out), 1)\n",
    "        return out\n",
    "\n",
    "# Revised Transition\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        return out\n",
    "\n",
    "# Revised DenseNet\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, in_channels, growthRate, depth, reduction, nClasses, bottleneck=True):\n",
    "        super(DenseNet, self).__init__()\n",
    "    \n",
    "        nDenseBlocks = (depth - 4) // 3\n",
    "        if bottleneck:\n",
    "            nDenseBlocks = nDenseBlocks // 2\n",
    "    \n",
    "        nChannels = 2 * growthRate\n",
    "        self.conv1 = nn.Conv2d(in_channels, nChannels, kernel_size=3, padding=1, bias=False)\n",
    "        self.dense1 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n",
    "        nChannels += nDenseBlocks * growthRate\n",
    "        nOutChannels = int(math.floor(nChannels * reduction))\n",
    "        self.trans1 = Transition(nChannels, nOutChannels)\n",
    "    \n",
    "        nChannels = nOutChannels\n",
    "        self.dense2 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n",
    "        nChannels += nDenseBlocks * growthRate\n",
    "        nOutChannels = int(math.floor(nChannels * reduction))\n",
    "        self.trans2 = Transition(nChannels, nOutChannels)\n",
    "    \n",
    "        nChannels = nOutChannels\n",
    "        self.dense3 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n",
    "        nChannels += nDenseBlocks * growthRate\n",
    "    \n",
    "        self.bn1 = nn.BatchNorm2d(nChannels)\n",
    "        self.fc = nn.Linear(nChannels, nClasses)\n",
    "    \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "    \n",
    "    def _make_dense(self, in_channels, growth_rate, nDenseBlocks, bottleneck):\n",
    "        layers = []\n",
    "        for _ in range(int(nDenseBlocks)):\n",
    "            if bottleneck:\n",
    "                layers.append(Bottleneck(in_channels, growth_rate))\n",
    "            else:\n",
    "                layers.append(SingleLayer(in_channels, growth_rate))\n",
    "            in_channels += growth_rate\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.trans1(self.dense1(out))\n",
    "        out = self.trans2(self.dense2(out))\n",
    "        out = self.dense3(out)\n",
    "        out = F.relu(self.bn1(out))\n",
    "        out = F.avg_pool2d(out, kernel_size=out.size()[2:])  # Adaptive pooling to 1x1\n",
    "        out = torch.flatten(out, 1)  # Flatten all dimensions except batch\n",
    "        out = self.fc(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf6df46",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# class FederatedLearningSystem:\n",
    "#     def __init__(self, devices_df, test_images, test_labels, dataset_name, metrics_file,\n",
    "#                  cluster_agent, scheduling_agent, cluster_env, scheduling_env, **kwargs):\n",
    "#         self.devices_df = devices_df.reset_index(drop=True)\n",
    "#         self.test_images = test_images\n",
    "#         self.test_labels = test_labels\n",
    "#         self.dataset_name = dataset_name\n",
    "#         self.metrics_file = metrics_file\n",
    "#         self.edge_servers = {}\n",
    "#         self.accuracies = {\n",
    "#             'local_epochs': {},       # Store local epoch accuracies\n",
    "#             'edge_iterations': {},    # Store edge iteration accuracies\n",
    "#             'global_iterations': []   # Store global iteration accuracies\n",
    "#         }\n",
    "\n",
    "#         # Model selection based on dataset name\n",
    "#         if dataset_name in ['mnist', 'fashion_mnist']:\n",
    "#             self.model_class = DenseNet  # Assign the class, not an instance\n",
    "#             self.model_args = {\n",
    "#                 'in_channels': 1,\n",
    "#                 'growthRate': 12,\n",
    "#                 'depth': 100,\n",
    "#                 'reduction': 0.5,\n",
    "#                 'nClasses': 10,\n",
    "#                 'bottleneck': True\n",
    "#             }\n",
    "#         elif dataset_name == 'cifar10':\n",
    "#             self.model_class = DLA  # Replace with DLA if needed\n",
    "#             self.model_args = {\n",
    "#                 'block': BasicBlock,\n",
    "#                 'num_classes': 10\n",
    "#             }\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
    "\n",
    "#         # Additional parameters\n",
    "#         self.global_iterations = kwargs.get('global_iterations', 5)\n",
    "#         self.edge_iterations = kwargs.get('edge_iterations', 3)\n",
    "#         self.local_epochs = kwargs.get('local_epochs', 1)\n",
    "#         self.input_channels = kwargs.get('input_channels', 1)\n",
    "#         self.num_classes = kwargs.get('num_classes', 10)\n",
    "#         self.batch_size = kwargs.get('batch_size', 32)\n",
    "\n",
    "#         # Parameters for Scenario 3\n",
    "#         self.k_edge = kwargs.get('k_edge', 2)\n",
    "#         self.m_global = kwargs.get('m_global', 1)\n",
    "#         self.alpha = kwargs.get('alpha', 0.1)\n",
    "\n",
    "#         # Initialize parameters for energy and time calculations\n",
    "#         self.model_size = kwargs.get('model_size', 1.0)                # Size in MB\n",
    "#         self.computation_energy_rate = kwargs.get('computation_energy_rate', 0.5)   # Energy per second\n",
    "#         self.communication_energy_rate = kwargs.get('communication_energy_rate', 0.1)  # Energy per MB\n",
    "#         self.device_latency = kwargs.get('device_latency', 0.1)        # Seconds\n",
    "#         self.edge_latency = kwargs.get('edge_latency', 0.05)           # Seconds\n",
    "\n",
    "#         # Dictionaries to store energy and time metrics\n",
    "#         self.energy_consumption = {\n",
    "#             'devices': {},\n",
    "#             'edge_servers': {},\n",
    "#             'cloud_server': 0.0\n",
    "#         }\n",
    "#         self.time_delays = {\n",
    "#             'devices': {},\n",
    "#             'edge_servers': {},\n",
    "#             'cloud_server': 0.0\n",
    "#         }\n",
    "#         self.bandwidth_usage = {\n",
    "#             'device_to_edge': 0.0,\n",
    "#             'edge_to_cloud': 0.0\n",
    "#         }\n",
    "\n",
    "#         # Store agents and environments for reuse\n",
    "#         self.cluster_agent = cluster_agent\n",
    "#         self.scheduling_agent = scheduling_agent\n",
    "#         self.cluster_env = cluster_env\n",
    "#         self.scheduling_env = scheduling_env\n",
    "\n",
    "#     def compute_computation_time(self, num_samples, cpu_power):\n",
    "#         # Simple model: Time = (Number of samples) / (CPU Power)\n",
    "#         return num_samples / cpu_power\n",
    "\n",
    "#     def compute_computation_energy(self, computation_time):\n",
    "#         # Energy = Computation Time * Energy Rate\n",
    "#         return computation_time * self.computation_energy_rate\n",
    "\n",
    "#     def compute_communication_time(self, data_size_mb, bandwidth_mbps, latency):\n",
    "#         # Time = Data Size / Bandwidth + Latency\n",
    "#         return (data_size_mb / bandwidth_mbps) + latency\n",
    "\n",
    "#     def compute_communication_energy(self, data_size_mb):\n",
    "#         # Energy = Data Size * Energy Rate\n",
    "#         return data_size_mb * self.communication_energy_rate\n",
    "\n",
    "#     def compute_batch_size(self, memory, cpu_power):\n",
    "#         base_batch_size = 24\n",
    "#         memory_factor = memory / 2  # Assume memory ranges from 1 to 4 GB\n",
    "#         cpu_factor = cpu_power / 1.0  # Assume CPU power ranges from 1.0 to 2.0 GHz\n",
    "#         batch_size = int(base_batch_size * memory_factor * cpu_factor)\n",
    "#         return int(round(max(16, min(batch_size, 32))))  # Batch size capped between 16 and 32\n",
    "\n",
    "#     def mix_models(self, local_state, global_state, alpha):\n",
    "#         \"\"\"\n",
    "#         Gradually mix the global/edge model into the local model using the formula:\n",
    "#         w_local = alpha * w_global/edge + (1 - alpha) * w_local\n",
    "#         \"\"\"\n",
    "#         mixed_state = {}\n",
    "#         for key in local_state.keys():\n",
    "#             mixed_state[key] = alpha * global_state[key] + (1 - alpha) * local_state[key]\n",
    "#         return mixed_state\n",
    "\n",
    "#     def layer_wise_update(self, local_state, global_state, shared_layers):\n",
    "#         \"\"\"\n",
    "#         Update only the shared layers in the local model with the global model.\n",
    "#         \"\"\"\n",
    "#         updated_state = deepcopy(local_state)\n",
    "#         for key in shared_layers:\n",
    "#             if key in global_state:\n",
    "#                 updated_state[key] = global_state[key]\n",
    "#         return updated_state\n",
    "\n",
    "#     def get_shared_layer_keys(self, model):\n",
    "#         \"\"\"\n",
    "#         Get the keys of the shared layers (e.g., feature extraction layers).\n",
    "#         \"\"\"\n",
    "#         shared_layers = []\n",
    "#         for name, param in model.named_parameters():\n",
    "#             if 'classifier' not in name and 'fc' not in name:\n",
    "#                 shared_layers.append(name)\n",
    "#         return shared_layers\n",
    "\n",
    "#     def train_local_model(self, device_id, local_model_state, edge_model_state, global_model_state, train_loader, epochs, edge_iteration, global_iteration, lr=0.01):\n",
    "#         \"\"\"\n",
    "#         Train the local model on a specific device while considering its CPU power and memory.\n",
    "#         \"\"\"\n",
    "#         device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         model = self.model_class(**self.model_args).to(device)\n",
    "\n",
    "#         # Load the local model state\n",
    "#         local_state = deepcopy(local_model_state)\n",
    "\n",
    "#         # Apply gradual mixing with edge/global model periodically\n",
    "#         if edge_iteration % self.k_edge == 0:\n",
    "#             # Mix with edge model\n",
    "#             alpha = min(self.alpha * (edge_iteration + 1), 1.0)  # Increase alpha over time\n",
    "#             local_state = self.mix_models(local_state, edge_model_state, alpha)\n",
    "\n",
    "#         if global_iteration % self.m_global == 0:\n",
    "#             # Mix with global model\n",
    "#             alpha = min(self.alpha * (global_iteration + 1), 1.0)\n",
    "#             local_state = self.mix_models(local_state, global_model_state, alpha)\n",
    "\n",
    "#         # Apply layer-wise updating to only update shared layers\n",
    "#         shared_layers = self.get_shared_layer_keys(model)\n",
    "#         local_state = self.layer_wise_update(local_state, local_model_state, shared_layers)\n",
    "\n",
    "#         model.load_state_dict(local_state)\n",
    "#         optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#         criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#         # Fetch device-specific characteristics\n",
    "#         device_info = self.devices_df.loc[self.devices_df['device_id'] == device_id].iloc[0]\n",
    "#         cpu_power = device_info['cpu_power']  # GHz\n",
    "#         memory = device_info['memory']       # GB\n",
    "\n",
    "#         # Adjust batch size based on memory\n",
    "#         adjusted_batch_size = self.compute_batch_size(memory, cpu_power)\n",
    "\n",
    "#         # Simulate adjusted training time and energy\n",
    "#         num_samples = len(train_loader.dataset)\n",
    "#         computation_time_per_epoch = self.compute_computation_time(num_samples, cpu_power)\n",
    "#         computation_energy_per_epoch = self.compute_computation_energy(computation_time_per_epoch)\n",
    "\n",
    "#         # Update DataLoader with adjusted batch size\n",
    "#         train_loader = DataLoader(train_loader.dataset, batch_size=adjusted_batch_size, shuffle=True)\n",
    "\n",
    "#         # Store energy and time metrics\n",
    "#         total_training_time = 0\n",
    "#         total_training_energy = 0\n",
    "\n",
    "#         # Training loop\n",
    "#         model.train()\n",
    "#         for epoch in range(epochs):\n",
    "#             correct, total = 0, 0\n",
    "\n",
    "#             # Simulate epoch training considering computation time and energy\n",
    "#             for images, labels in train_loader:\n",
    "#                 images, labels = images.to(device), labels.to(device)\n",
    "#                 optimizer.zero_grad()\n",
    "#                 outputs = model(images)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "\n",
    "#                 # Calculate training accuracy for the current batch\n",
    "#                 _, predicted = torch.max(outputs, 1)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "#                 total += labels.size(0)\n",
    "\n",
    "#             # Simulate time and energy per epoch\n",
    "#             total_training_time += computation_time_per_epoch\n",
    "#             total_training_energy += computation_energy_per_epoch\n",
    "\n",
    "#             # Log accuracy for the epoch\n",
    "#             epoch_accuracy = 100 * correct / total\n",
    "#             print(f\"Device {device_id} - Epoch {epoch + 1}/{epochs} - Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "#             # Store epoch accuracy\n",
    "#             if device_id not in self.accuracies['local_epochs']:\n",
    "#                 self.accuracies['local_epochs'][device_id] = []\n",
    "#             self.accuracies['local_epochs'][device_id].append(epoch_accuracy)\n",
    "\n",
    "#         # Update total time and energy for the device\n",
    "#         if device_id not in self.energy_consumption['devices']:\n",
    "#             self.energy_consumption['devices'][device_id] = 0.0\n",
    "#         if device_id not in self.time_delays['devices']:\n",
    "#             self.time_delays['devices'][device_id] = 0.0\n",
    "\n",
    "#         self.energy_consumption['devices'][device_id] += total_training_energy\n",
    "#         self.time_delays['devices'][device_id] += total_training_time\n",
    "\n",
    "#         print(f\"Device {device_id} - Total Training Time: {total_training_time:.2f}s\")\n",
    "#         print(f\"Device {device_id} - Total Training Energy: {total_training_energy:.2f}J\")\n",
    "\n",
    "#         return device_id, deepcopy(model.state_dict())\n",
    "\n",
    "#     def aggregate_models(self, models):\n",
    "#         avg_model = deepcopy(models[0])\n",
    "#         for key in avg_model.keys():\n",
    "#             for model in models[1:]:\n",
    "#                 avg_model[key] += model[key]\n",
    "#             avg_model[key] = avg_model[key] / len(models)\n",
    "#         return avg_model\n",
    "\n",
    "#     def evaluate_model(self, model_state, test_loader):\n",
    "#         device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         model = self.model_class(**self.model_args).to(device)\n",
    "#         model.load_state_dict(model_state)\n",
    "#         model.eval()\n",
    "#         total, correct = 0, 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for images, labels in test_loader:\n",
    "#                 images, labels = images.to(device), labels.to(device)\n",
    "#                 outputs = model(images)\n",
    "#                 _, predicted = torch.max(outputs, 1)\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "\n",
    "#         return 100 * correct / total\n",
    "\n",
    "#     def save_summary_metrics(self, summary_file=\"metrics_summary.json\"):\n",
    "#         \"\"\"\n",
    "#         Consolidate and save key metrics for communication costs, energy consumption, \n",
    "#         and training performance.\n",
    "#         \"\"\"\n",
    "#         summary_metrics = {\n",
    "#             \"global_iterations\": self.global_iterations,\n",
    "#             \"edge_iterations\": self.edge_iterations,\n",
    "#             \"local_epochs\": self.local_epochs,\n",
    "#             \"overall_energy_consumption\": self.energy_consumption,\n",
    "#             \"overall_time_delays\": self.time_delays,\n",
    "#             \"overall_bandwidth_usage\": self.bandwidth_usage,\n",
    "#             \"global_model_accuracy\": self.accuracies.get(\"global_iterations\", [])\n",
    "#         }\n",
    "\n",
    "#         # Save the summary to a JSON file\n",
    "#         with open(summary_file, 'w') as f:\n",
    "#             json.dump(summary_metrics, f, indent=4)\n",
    "\n",
    "#         print(f\"Summary metrics saved to {summary_file}\")\n",
    "\n",
    "#     def edge_server_training(self, edge_id, edge_devices, edge_model_state, edge_iteration, global_iteration):\n",
    "#         \"\"\"\n",
    "#         Train devices assigned to the edge server independently and update the local model after each edge iteration.\n",
    "#         \"\"\"\n",
    "#         edge_computation_time = 0.0\n",
    "#         edge_computation_energy = 0.0\n",
    "\n",
    "#         communication_costs = []\n",
    "#         communication_latencies = []\n",
    "#         communication_energies = []\n",
    "\n",
    "#         print(f\"Edge Server {edge_id}: Starting training\")\n",
    "#         # Edge server's current model state is passed as edge_model_state\n",
    "\n",
    "#         local_results = []  # Collect local model updates from devices\n",
    "\n",
    "#         for device_id, train_loader in edge_devices:\n",
    "#             print(f\"Edge Server {edge_id} sends model to Device {device_id} for training.\")\n",
    "#             # Train local model starting from edge_model_state\n",
    "#             local_result = self.train_local_model(\n",
    "#                 device_id,\n",
    "#                 edge_model_state,          # local_model_state\n",
    "#                 edge_model_state,          # edge_model_state\n",
    "#                 self.global_model_state,   # global_model_state\n",
    "#                 train_loader,\n",
    "#                 self.local_epochs,\n",
    "#                 edge_iteration,\n",
    "#                 global_iteration\n",
    "#             )\n",
    "#             local_results.append(local_result)\n",
    "\n",
    "#             # Communication metrics: time and energy from device to edge server\n",
    "#             device_info = self.devices_df.loc[self.devices_df['device_id'] == device_id].iloc[0]\n",
    "#             bandwidth = device_info['bandwidth']  # in Mbps\n",
    "#             communication_time = self.compute_communication_time(\n",
    "#                 self.model_size,\n",
    "#                 bandwidth,\n",
    "#                 self.device_latency\n",
    "#             )\n",
    "#             communication_energy = self.compute_communication_energy(self.model_size)\n",
    "\n",
    "#             communication_costs.append(self.model_size)\n",
    "#             communication_latencies.append(communication_time)\n",
    "#             communication_energies.append(communication_energy)\n",
    "\n",
    "#             # Update device energy and time\n",
    "#             self.time_delays['devices'][device_id] += communication_time\n",
    "#             self.energy_consumption['devices'][device_id] += communication_energy\n",
    "\n",
    "#             # Update total bandwidth usage\n",
    "#             self.bandwidth_usage['device_to_edge'] += self.model_size\n",
    "\n",
    "#         # Aggregate models from all devices at the edge server level\n",
    "#         local_states = [state for _, state in local_results]\n",
    "#         updated_edge_model_state = self.aggregate_models(local_states)\n",
    "#         print(f\"Edge Server {edge_id}: Aggregated models from devices\")\n",
    "\n",
    "#         # Edge server computation time for aggregation\n",
    "#         num_models = len(local_states)\n",
    "#         aggregation_time = num_models * 0.1  # 0.1 seconds per model\n",
    "#         edge_computation_time += aggregation_time\n",
    "#         edge_computation_energy += aggregation_time * self.computation_energy_rate\n",
    "\n",
    "#         # Store edge server energy and time\n",
    "#         if edge_id not in self.energy_consumption['edge_servers']:\n",
    "#             self.energy_consumption['edge_servers'][edge_id] = 0.0\n",
    "#         if edge_id not in self.time_delays['edge_servers']:\n",
    "#             self.time_delays['edge_servers'][edge_id] = 0.0\n",
    "#         self.time_delays['edge_servers'][edge_id] += edge_computation_time\n",
    "#         self.energy_consumption['edge_servers'][edge_id] += edge_computation_energy\n",
    "\n",
    "#         # Update total bandwidth usage for communication with cloud\n",
    "#         self.bandwidth_usage['edge_to_cloud'] += self.model_size\n",
    "\n",
    "#         # Evaluate aggregated edge model\n",
    "#         edge_accuracy = self.evaluate_model(updated_edge_model_state, self.get_test_loader())\n",
    "#         print(f\"Edge Server {edge_id} - Edge Iteration {edge_iteration + 1} - Edge Model Accuracy: {edge_accuracy:.2f}%\")\n",
    "\n",
    "#         # Record edge_iteration accuracy\n",
    "#         if global_iteration not in self.accuracies['edge_iterations']:\n",
    "#             self.accuracies['edge_iterations'][global_iteration] = {}\n",
    "#         if edge_iteration not in self.accuracies['edge_iterations'][global_iteration]:\n",
    "#             self.accuracies['edge_iterations'][global_iteration][edge_iteration] = {}\n",
    "#         self.accuracies['edge_iterations'][global_iteration][edge_iteration][edge_id] = edge_accuracy\n",
    "\n",
    "#         # Return the updated model state for this edge server\n",
    "#         return updated_edge_model_state\n",
    "\n",
    "#     def recalculate_assignments(self):\n",
    "#         # Re-run cluster assignment agent\n",
    "#         self.cluster_env.devices_df = self.devices_df  # Update devices_df in the environment\n",
    "#         cluster_state = self.cluster_env.reset()\n",
    "#         cluster_action, _ = self.cluster_agent.predict(cluster_state)\n",
    "#         assignments = dict(zip(range(self.cluster_env.num_clusters), cluster_action))\n",
    "#         self.devices_df['assigned_servers'] = self.devices_df['cluster'].map(assignments)\n",
    "\n",
    "#         # Re-run device scheduling agent\n",
    "#         self.scheduling_env.devices_df = self.devices_df.reset_index(drop=True)  # Update devices_df in the environment\n",
    "#         scheduling_state = self.scheduling_env.reset()\n",
    "#         scheduling_action, _ = self.scheduling_agent.predict(scheduling_state)\n",
    "#         scheduled_devices = [i for i, a in enumerate(scheduling_action) if a == 1]\n",
    "#         self.devices_df['is_scheduled'] = False\n",
    "#         self.devices_df.loc[scheduled_devices, 'is_scheduled'] = True\n",
    "\n",
    "#         # Reset edge_servers\n",
    "#         self.edge_servers = {}\n",
    "\n",
    "#         # Recreate edge_servers with updated assignments, initializing model_state from global model\n",
    "#         for idx, row in self.devices_df.iterrows():\n",
    "#             if not row['is_scheduled']:\n",
    "#                 continue  # Skip unscheduled devices\n",
    "\n",
    "#             local_dataset = row[\"local_data\"]\n",
    "#             if not isinstance(local_dataset, LocalDataset):\n",
    "#                 continue\n",
    "\n",
    "#             images, labels = local_dataset.get_data()\n",
    "#             if len(images) == 0 or len(labels) == 0:\n",
    "#                 continue\n",
    "\n",
    "#             memory = row[\"memory\"]\n",
    "#             cpu_power = row[\"cpu_power\"]\n",
    "#             batch_size = self.compute_batch_size(memory, cpu_power)\n",
    "\n",
    "#             tensor_dataset = TensorDataset(\n",
    "#                 torch.tensor(images, dtype=torch.float32),\n",
    "#                 torch.tensor(labels, dtype=torch.long)\n",
    "#             )\n",
    "#             loader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#             edge_server_id = row[\"assigned_servers\"]\n",
    "#             if edge_server_id not in self.edge_servers:\n",
    "#                 self.edge_servers[edge_server_id] = {\n",
    "#                     'devices': [],\n",
    "#                     'model_state': deepcopy(self.global_model_state)  # Initialize from global model\n",
    "#                 }\n",
    "#             self.edge_servers[edge_server_id]['devices'].append((row[\"device_id\"], loader))\n",
    "\n",
    "#         # Print updated device distribution across edge servers\n",
    "#         print(\"Updated device distribution across edge servers:\")\n",
    "#         for edge_id, edge_info in self.edge_servers.items():\n",
    "#             num_devices = len(edge_info['devices'])\n",
    "#             print(f\"Edge Server {edge_id}: {num_devices} devices\")\n",
    "\n",
    "#     def federated_learning(self, global_model_state, max_parallel_edge_servers=2):\n",
    "#         \"\"\"\n",
    "#         Perform semi-synchronous federated learning with independent device training\n",
    "#         and multiple edge server iterations, ensuring local model updates after each iteration.\n",
    "#         \"\"\"\n",
    "#         cloud_computation_time = 0.0\n",
    "#         cloud_computation_energy = 0.0\n",
    "\n",
    "#         for global_iteration in range(self.global_iterations):\n",
    "#             print(\"-\" * 60)\n",
    "#             print(f\"Global Iteration {global_iteration + 1}/{self.global_iterations}\")\n",
    "#             print(\"-\" * 60)\n",
    "\n",
    "#             # Recalculate assignments at the beginning of each global iteration\n",
    "#             self.global_model_state = deepcopy(global_model_state)  # Update global model state\n",
    "#             self.recalculate_assignments()\n",
    "\n",
    "#             # Initialize edge server models from the global model\n",
    "#             for edge_id in self.edge_servers.keys():\n",
    "#                 # Apply gradual mixing with the global model every m_global iterations\n",
    "#                 if global_iteration % self.m_global == 0:\n",
    "#                     alpha = min(self.alpha * (global_iteration + 1), 1.0)\n",
    "#                     self.edge_servers[edge_id]['model_state'] = self.mix_models(\n",
    "#                         self.edge_servers[edge_id]['model_state'],\n",
    "#                         self.global_model_state,\n",
    "#                         alpha\n",
    "#                     )\n",
    "\n",
    "#             for edge_iteration in range(self.edge_iterations):\n",
    "#                 print(f\"  Edge Iteration {edge_iteration + 1}/{self.edge_iterations}\")\n",
    "\n",
    "#                 edge_results = {}\n",
    "\n",
    "#                 # Use ThreadPoolExecutor to limit concurrent edge server training\n",
    "#                 with ThreadPoolExecutor(max_workers=max_parallel_edge_servers) as executor:\n",
    "#                     future_to_edge = {\n",
    "#                         executor.submit(\n",
    "#                             self.edge_server_training,\n",
    "#                             edge_id,\n",
    "#                             edge_info['devices'],\n",
    "#                             edge_info['model_state'],\n",
    "#                             edge_iteration,\n",
    "#                             global_iteration\n",
    "#                         ): edge_id\n",
    "#                         for edge_id, edge_info in self.edge_servers.items()\n",
    "#                     }\n",
    "\n",
    "#                     # Collect results as each edge server finishes\n",
    "#                     for future in as_completed(future_to_edge):\n",
    "#                         edge_id = future_to_edge[future]\n",
    "#                         try:\n",
    "#                             updated_state = future.result()  # Result is updated edge model state\n",
    "#                             edge_results[edge_id] = updated_state\n",
    "#                             # Update the edge server's model state\n",
    "#                             self.edge_servers[edge_id]['model_state'] = updated_state\n",
    "#                             print(f\"  Edge Server {edge_id}: Updated model after Edge Iteration {edge_iteration + 1}\")\n",
    "#                         except Exception as e:\n",
    "#                             print(f\"Edge Server {edge_id} encountered an error: {e}\")\n",
    "\n",
    "#                 # Periodically update edge models with global model\n",
    "#                 if (edge_iteration + 1) % self.k_edge == 0:\n",
    "#                     for edge_id in self.edge_servers.keys():\n",
    "#                         alpha = min(self.alpha * (edge_iteration + 1), 1.0)\n",
    "#                         self.edge_servers[edge_id]['model_state'] = self.mix_models(\n",
    "#                             self.edge_servers[edge_id]['model_state'],\n",
    "#                             self.global_model_state,\n",
    "#                             alpha\n",
    "#                         )\n",
    "\n",
    "#             # Perform global aggregation after all edge iterations\n",
    "#             global_states = [edge_info['model_state'] for edge_info in self.edge_servers.values()]\n",
    "#             self.global_model_state = self.aggregate_models(global_states)\n",
    "#             global_model_state = deepcopy(self.global_model_state)\n",
    "#             print(f\"Global Iteration {global_iteration + 1}: Aggregated all edge models\")\n",
    "\n",
    "#             # Cloud server computation time for aggregation\n",
    "#             num_edge_models = len(self.edge_servers)\n",
    "#             aggregation_time = num_edge_models * 0.2  # 0.2 seconds per edge model\n",
    "#             cloud_computation_time += aggregation_time\n",
    "#             cloud_computation_energy += aggregation_time * self.computation_energy_rate\n",
    "\n",
    "#             # Evaluate global model and store accuracy\n",
    "#             global_accuracy = self.evaluate_model(global_model_state, self.get_test_loader())\n",
    "#             print(f\"Global Iteration {global_iteration + 1}: Global Model Accuracy: {global_accuracy:.2f}%\")\n",
    "\n",
    "#             self.accuracies['global_iterations'].append(global_accuracy)\n",
    "\n",
    "#             # Periodically write accuracies to file\n",
    "#             with open(self.metrics_file, 'w') as f:\n",
    "#                 json.dump(self.accuracies, f, indent=4)\n",
    "\n",
    "#             # Note: Assignments will be recalculated at the beginning of the next global iteration\n",
    "\n",
    "#         # Store cloud server energy and time\n",
    "#         self.energy_consumption['cloud_server'] = cloud_computation_energy\n",
    "#         self.time_delays['cloud_server'] = cloud_computation_time\n",
    "\n",
    "#     def main(self, global_iterations, edge_iterations, local_epochs):\n",
    "#         self.global_iterations = global_iterations\n",
    "#         self.edge_iterations = edge_iterations\n",
    "#         self.local_epochs = local_epochs\n",
    "\n",
    "#         # Initialize global model state\n",
    "#         global_model = self.model_class(**self.model_args)\n",
    "#         self.global_model_state = deepcopy(global_model.state_dict())  # Initialize global model state\n",
    "\n",
    "#         # Run federated learning\n",
    "#         self.federated_learning(self.global_model_state, max_parallel_edge_servers=1)\n",
    "\n",
    "#         final_accuracy = self.evaluate_model(self.global_model_state, self.get_test_loader())\n",
    "#         print(f\"Final Global Model Accuracy: {final_accuracy:.2f}%\")\n",
    "\n",
    "#         # Save the accuracies to JSON\n",
    "#         with open(self.metrics_file.replace('.json', '_accuracies.json'), 'w') as json_file:\n",
    "#             json.dump(self.accuracies, json_file, indent=4)\n",
    "\n",
    "#         self.save_summary_metrics(self.metrics_file.replace('.json', '_full_metrics.json'))\n",
    "\n",
    "#         # After training, consolidate metrics into a single dictionary\n",
    "#         metrics_summary = {\n",
    "#             \"Energy Consumption\": self.energy_consumption,\n",
    "#             \"Time Delays\": self.time_delays,\n",
    "#             \"Bandwidth Usage\": self.bandwidth_usage,\n",
    "#         }\n",
    "\n",
    "#         # Save metrics to a JSON file\n",
    "#         with open(self.metrics_file.replace('.json', '_summary.json'), 'w') as f:\n",
    "#             json.dump(metrics_summary, f, indent=4)\n",
    "\n",
    "#     def get_test_loader(self):\n",
    "#         test_dataset = TensorDataset(\n",
    "#             torch.tensor(self.test_images, dtype=torch.float32),\n",
    "#             torch.tensor(self.test_labels, dtype=torch.long)\n",
    "#         )\n",
    "#         test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "#         return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b140675",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# class FederatedLearningSystem:\n",
    "#     def __init__(self, devices_df, test_images, test_labels, dataset_name, metrics_file,\n",
    "#                  cluster_agent, scheduling_agent, cluster_env, scheduling_env, **kwargs):\n",
    "#         self.devices_df = devices_df.reset_index(drop=True)\n",
    "#         self.test_images = test_images\n",
    "#         self.test_labels = test_labels\n",
    "#         self.dataset_name = dataset_name\n",
    "#         self.metrics_file = metrics_file\n",
    "#         self.edge_servers = {}\n",
    "#         self.accuracies = {\n",
    "#             'local_epochs': {},       # Store local epoch accuracies\n",
    "#             'edge_iterations': {},    # Store edge iteration accuracies\n",
    "#             'global_iterations': []   # Store global iteration accuracies\n",
    "#         }\n",
    "\n",
    "#         # Model selection based on dataset name\n",
    "#         if dataset_name in ['mnist', 'fashion_mnist']:\n",
    "#             self.model_class = DenseNet  # Assign the class, not an instance\n",
    "#             self.model_args = {\n",
    "#                 'in_channels': 1,\n",
    "#                 'growthRate': 12,\n",
    "#                 'depth': 100,\n",
    "#                 'reduction': 0.5,\n",
    "#                 'nClasses': 10,\n",
    "#                 'bottleneck': True\n",
    "#             }\n",
    "#         elif dataset_name == 'cifar10':\n",
    "#             self.model_class = DLA  # Replace with DLA if needed\n",
    "#             self.model_args = {\n",
    "#                 'block': BasicBlock,\n",
    "#                 'num_classes': 10\n",
    "#             }\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
    "\n",
    "#         # Additional parameters\n",
    "#         self.global_iterations = kwargs.get('global_iterations', 5)\n",
    "#         self.edge_iterations = kwargs.get('edge_iterations', 3)\n",
    "#         self.local_epochs = kwargs.get('local_epochs', 1)\n",
    "#         self.input_channels = kwargs.get('input_channels', 1)\n",
    "#         self.num_classes = kwargs.get('num_classes', 10)\n",
    "#         self.batch_size = kwargs.get('batch_size', 32)\n",
    "\n",
    "#         # Parameters for Scenario 3\n",
    "#         self.k_edge = kwargs.get('k_edge', 2)\n",
    "#         self.m_global = kwargs.get('m_global', 1)\n",
    "#         self.alpha = kwargs.get('alpha', 0.1)\n",
    "\n",
    "#         # Parameters for FedProx\n",
    "#         self.mu = kwargs.get('mu', 0.1)  # FedProx hyperparameter\n",
    "\n",
    "#         # Initialize parameters for energy and time calculations\n",
    "#         self.model_size = kwargs.get('model_size', 1.0)                # Size in MB\n",
    "#         self.computation_energy_rate = kwargs.get('computation_energy_rate', 0.5)   # Energy per second\n",
    "#         self.communication_energy_rate = kwargs.get('communication_energy_rate', 0.1)  # Energy per MB\n",
    "#         self.device_latency = kwargs.get('device_latency', 0.1)        # Seconds\n",
    "#         self.edge_latency = kwargs.get('edge_latency', 0.05)           # Seconds\n",
    "\n",
    "#         self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#         # Dictionaries to store energy and time metrics\n",
    "#         self.energy_consumption = {\n",
    "#             'devices': {},\n",
    "#             'edge_servers': {},\n",
    "#             'cloud_server': 0.0\n",
    "#         }\n",
    "#         self.time_delays = {\n",
    "#             'devices': {},\n",
    "#             'edge_servers': {},\n",
    "#             'cloud_server': 0.0\n",
    "#         }\n",
    "#         self.bandwidth_usage = {\n",
    "#             'device_to_edge': 0.0,\n",
    "#             'edge_to_cloud': 0.0\n",
    "#         }\n",
    "\n",
    "#         # Store agents and environments for reuse\n",
    "#         self.cluster_agent = cluster_agent\n",
    "#         self.scheduling_agent = scheduling_agent\n",
    "#         self.cluster_env = cluster_env\n",
    "#         self.scheduling_env = scheduling_env\n",
    "\n",
    "#     def compute_computation_time(self, num_samples, cpu_power):\n",
    "#         # Simple model: Time = (Number of samples) / (CPU Power)\n",
    "#         return num_samples / cpu_power\n",
    "\n",
    "#     def compute_computation_energy(self, computation_time):\n",
    "#         # Energy = Computation Time * Energy Rate\n",
    "#         return computation_time * self.computation_energy_rate\n",
    "\n",
    "#     def compute_communication_time(self, data_size_mb, bandwidth_mbps, latency):\n",
    "#         # Time = Data Size / Bandwidth + Latency\n",
    "#         return (data_size_mb / bandwidth_mbps) + latency\n",
    "\n",
    "#     def compute_communication_energy(self, data_size_mb):\n",
    "#         # Energy = Data Size * Energy Rate\n",
    "#         return data_size_mb * self.communication_energy_rate\n",
    "\n",
    "#     def compute_batch_size(self, memory, cpu_power):\n",
    "#         base_batch_size = 34\n",
    "#         memory_factor = memory / 2  # Assume memory ranges from 1 to 4 GB\n",
    "#         cpu_factor = cpu_power / 1.0  # Assume CPU power ranges from 1.0 to 2.0 GHz\n",
    "#         batch_size = int(base_batch_size * memory_factor * cpu_factor)\n",
    "#         return int(round(max(24, min(batch_size, 64))))  # Batch size capped between 16 and 32\n",
    "\n",
    "#     def mix_models(self, local_state, global_state, alpha):\n",
    "#         \"\"\"\n",
    "#         Gradually mix the global/edge model into the local model using the formula:\n",
    "#         w_local = alpha * w_global/edge + (1 - alpha) * w_local\n",
    "#         \"\"\"\n",
    "#         mixed_state = {}\n",
    "#         for key in local_state.keys():\n",
    "#             mixed_state[key] = alpha * global_state[key].to(self.device) + (1 - alpha) * local_state[key].to(self.device)\n",
    "#         return mixed_state\n",
    "\n",
    "#     def layer_wise_update(self, local_state, global_state, shared_layers):\n",
    "#         \"\"\"\n",
    "#         Update only the shared layers in the local model with the global model.\n",
    "#         \"\"\"\n",
    "#         updated_state = deepcopy(local_state)\n",
    "#         for key in shared_layers:\n",
    "#             if key in global_state:\n",
    "#                 updated_state[key] = global_state[key]\n",
    "#         return updated_state\n",
    "\n",
    "#     def get_shared_layer_keys(self, model):\n",
    "#         \"\"\"\n",
    "#         Get the keys of the shared layers (e.g., feature extraction layers).\n",
    "#         \"\"\"\n",
    "#         shared_layers = []\n",
    "#         for name, param in model.named_parameters():\n",
    "#             if 'classifier' not in name and 'fc' not in name:\n",
    "#                 shared_layers.append(name)\n",
    "#         return shared_layers\n",
    "\n",
    "#     def train_local_model(self, device_id, local_model_state, edge_model_state, global_model_state, train_loader, epochs, edge_iteration, global_iteration, lr=0.0001):\n",
    "#         \"\"\"\n",
    "#         Train the local model on a specific device while considering its CPU power and memory.\n",
    "#         Incorporates FedProx by adding a proximal term to the loss function.\n",
    "#         Includes ReduceLROnPlateau to dynamically adjust the learning rate.\n",
    "#         \"\"\"\n",
    "#         device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         model = self.model_class(**self.model_args).to(device)\n",
    "    \n",
    "#         # Load the local model state\n",
    "#         local_state = deepcopy(local_model_state)\n",
    "    \n",
    "#         # Apply gradual mixing with edge/global model periodically\n",
    "#         if edge_iteration % self.k_edge == 0:\n",
    "#             alpha = min(self.alpha * (edge_iteration + 1), 1.0)  # Increase alpha over time\n",
    "#             local_state = self.mix_models(local_state, edge_model_state, alpha)\n",
    "    \n",
    "#         if global_iteration % self.m_global == 0:\n",
    "#             alpha = min(self.alpha * (global_iteration + 1), 1.0)\n",
    "#             local_state = self.mix_models(local_state, global_model_state, alpha)\n",
    "    \n",
    "#         # Apply layer-wise updating to only update shared layers\n",
    "#         shared_layers = self.get_shared_layer_keys(model)\n",
    "#         local_state = self.layer_wise_update(local_state, local_model_state, shared_layers)\n",
    "    \n",
    "#         model.load_state_dict(local_state)\n",
    "#         optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#         scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "#         criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "#         # Fetch device-specific characteristics\n",
    "#         device_info = self.devices_df.loc[self.devices_df['device_id'] == device_id].iloc[0]\n",
    "#         cpu_power = device_info['cpu_power']  # GHz\n",
    "#         memory = device_info['memory']       # GB\n",
    "    \n",
    "#         # Adjust batch size based on memory\n",
    "#         adjusted_batch_size = self.compute_batch_size(memory, cpu_power)\n",
    "    \n",
    "#         # Simulate adjusted training time and energy\n",
    "#         num_samples = len(train_loader.dataset)\n",
    "#         computation_time_per_epoch = self.compute_computation_time(num_samples, cpu_power)\n",
    "#         computation_energy_per_epoch = self.compute_computation_energy(computation_time_per_epoch)\n",
    "    \n",
    "#         # Update DataLoader with adjusted batch size\n",
    "#         train_loader = DataLoader(train_loader.dataset, batch_size=adjusted_batch_size, shuffle=True)\n",
    "    \n",
    "#         # Store energy and time metrics\n",
    "#         total_training_time = 0\n",
    "#         total_training_energy = 0\n",
    "    \n",
    "#         # Training loop\n",
    "#         model.train()\n",
    "#         for epoch in range(epochs):\n",
    "#             correct, total = 0, 0\n",
    "#             running_loss = 0.0\n",
    "    \n",
    "#             for images, labels in train_loader:\n",
    "#                 images, labels = images.to(device), labels.to(device)\n",
    "#                 optimizer.zero_grad()\n",
    "    \n",
    "#                 outputs = model(images)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "    \n",
    "#                 # Compute FedProx proximal term\n",
    "#                 proximal_loss = 0.0\n",
    "#                 for name, param in model.named_parameters():\n",
    "#                     if name in shared_layers:\n",
    "#                         gl_param = global_model_state[name].clone().detach().to(device) \n",
    "#                         proximal_loss += torch.norm(param - gl_param)**2\n",
    "                        \n",
    "#                 proximal_loss = (self.mu / 2) * proximal_loss\n",
    "    \n",
    "#                 # Total loss\n",
    "#                 total_loss = loss + proximal_loss\n",
    "#                 total_loss.backward()\n",
    "#                 optimizer.step()\n",
    "    \n",
    "#                 running_loss += total_loss.item()\n",
    "    \n",
    "#                 # Calculate training accuracy for the current batch\n",
    "#                 _, predicted = torch.max(outputs, 1)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "#                 total += labels.size(0)\n",
    "    \n",
    "#             # Simulate time and energy per epoch\n",
    "#             total_training_time += computation_time_per_epoch\n",
    "#             total_training_energy += computation_energy_per_epoch\n",
    "    \n",
    "#             # Log accuracy for the epoch\n",
    "#             epoch_accuracy = 100 * correct / total\n",
    "#             epoch_loss = running_loss / len(train_loader)\n",
    "#             print(f\"Device {device_id} - Epoch {epoch + 1}/{epochs} - Accuracy: {epoch_accuracy:.2f}%, Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "#             # Adjust learning rate based on loss\n",
    "#             scheduler.step(epoch_loss)\n",
    "    \n",
    "#             # Store epoch accuracy\n",
    "#             if device_id not in self.accuracies['local_epochs']:\n",
    "#                 self.accuracies['local_epochs'][device_id] = []\n",
    "#             self.accuracies['local_epochs'][device_id].append(epoch_accuracy)\n",
    "    \n",
    "#         # Update total time and energy for the device\n",
    "#         if device_id not in self.energy_consumption['devices']:\n",
    "#             self.energy_consumption['devices'][device_id] = 0.0\n",
    "#         if device_id not in self.time_delays['devices']:\n",
    "#             self.time_delays['devices'][device_id] = 0.0\n",
    "    \n",
    "#         self.energy_consumption['devices'][device_id] += total_training_energy\n",
    "#         self.time_delays['devices'][device_id] += total_training_time\n",
    "    \n",
    "#         print(f\"Device {device_id} - Total Training Time: {total_training_time:.2f}s\")\n",
    "#         print(f\"Device {device_id} - Total Training Energy: {total_training_energy:.2f}J\")\n",
    "    \n",
    "#         return device_id, deepcopy(model.state_dict())\n",
    "\n",
    "#     def aggregate_models(self, models):\n",
    "#         avg_model = deepcopy(models[0])\n",
    "#         for key in avg_model.keys():\n",
    "#             for model in models[1:]:\n",
    "#                 avg_model[key] += model[key].to(self.device)\n",
    "#             avg_model[key] = avg_model[key].to(self.device) / len(models)\n",
    "#         return avg_model\n",
    "\n",
    "#     def evaluate_model(self, model_state, test_loader):\n",
    "#         device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#         model = self.model_class(**self.model_args).to(device)\n",
    "#         model.load_state_dict(model_state)\n",
    "#         model.eval()\n",
    "#         total, correct = 0, 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for images, labels in test_loader:\n",
    "#                 images, labels = images.to(device), labels.to(device)\n",
    "#                 outputs = model(images)\n",
    "#                 _, predicted = torch.max(outputs, 1)\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "\n",
    "#         return 100 * correct / total\n",
    "\n",
    "#     def save_summary_metrics(self, summary_file=\"metrics_summary.json\"):\n",
    "#         \"\"\"\n",
    "#         Consolidate and save key metrics for communication costs, energy consumption, \n",
    "#         and training performance.\n",
    "#         \"\"\"\n",
    "#         summary_metrics = {\n",
    "#             \"global_iterations\": self.global_iterations,\n",
    "#             \"edge_iterations\": self.edge_iterations,\n",
    "#             \"local_epochs\": self.local_epochs,\n",
    "#             \"overall_energy_consumption\": self.energy_consumption,\n",
    "#             \"overall_time_delays\": self.time_delays,\n",
    "#             \"overall_bandwidth_usage\": self.bandwidth_usage,\n",
    "#             \"global_model_accuracy\": self.accuracies.get(\"global_iterations\", [])\n",
    "#         }\n",
    "\n",
    "#         # Save the summary to a JSON file\n",
    "#         with open(summary_file, 'w') as f:\n",
    "#             json.dump(summary_metrics, f, indent=4)\n",
    "\n",
    "#         print(f\"Summary metrics saved to {summary_file}\")\n",
    "\n",
    "#     def edge_server_training(self, edge_id, edge_devices, edge_model_state, edge_iteration, global_iteration):\n",
    "#         \"\"\"\n",
    "#         Train devices assigned to the edge server independently and update the local model after each edge iteration.\n",
    "#         \"\"\"\n",
    "#         edge_computation_time = 0.0\n",
    "#         edge_computation_energy = 0.0\n",
    "\n",
    "#         communication_costs = []\n",
    "#         communication_latencies = []\n",
    "#         communication_energies = []\n",
    "\n",
    "#         print(f\"Edge Server {edge_id}: Starting training\")\n",
    "#         # Edge server's current model state is passed as edge_model_state\n",
    "\n",
    "#         local_results = []  # Collect local model updates from devices\n",
    "\n",
    "#         for device_id, train_loader in edge_devices:\n",
    "#             print(f\"Edge Server {edge_id} sends model to Device {device_id} for training.\")\n",
    "#             # Train local model starting from edge_model_state\n",
    "#             local_result = self.train_local_model(\n",
    "#                 device_id,\n",
    "#                 edge_model_state,          # local_model_state\n",
    "#                 edge_model_state,          # edge_model_state\n",
    "#                 self.global_model_state,   # global_model_state\n",
    "#                 train_loader,\n",
    "#                 self.local_epochs,\n",
    "#                 edge_iteration,\n",
    "#                 global_iteration\n",
    "#             )\n",
    "#             local_results.append(local_result)\n",
    "\n",
    "#             # Communication metrics: time and energy from device to edge server\n",
    "#             device_info = self.devices_df.loc[self.devices_df['device_id'] == device_id].iloc[0]\n",
    "#             bandwidth = device_info['bandwidth']  # in Mbps\n",
    "#             communication_time = self.compute_communication_time(\n",
    "#                 self.model_size,\n",
    "#                 bandwidth,\n",
    "#                 self.device_latency\n",
    "#             )\n",
    "#             communication_energy = self.compute_communication_energy(self.model_size)\n",
    "\n",
    "#             communication_costs.append(self.model_size)\n",
    "#             communication_latencies.append(communication_time)\n",
    "#             communication_energies.append(communication_energy)\n",
    "\n",
    "#             # Update device energy and time\n",
    "#             self.time_delays['devices'][device_id] += communication_time\n",
    "#             self.energy_consumption['devices'][device_id] += communication_energy\n",
    "\n",
    "#             # Update total bandwidth usage\n",
    "#             self.bandwidth_usage['device_to_edge'] += self.model_size\n",
    "\n",
    "#         # Aggregate models from all devices at the edge server level\n",
    "#         local_states = [state for _, state in local_results]\n",
    "#         updated_edge_model_state = self.aggregate_models(local_states)\n",
    "#         print(f\"Edge Server {edge_id}: Aggregated models from devices\")\n",
    "\n",
    "#         # Edge server computation time for aggregation\n",
    "#         num_models = len(local_states)\n",
    "#         aggregation_time = num_models * 0.1  # 0.1 seconds per model\n",
    "#         edge_computation_time += aggregation_time\n",
    "#         edge_computation_energy += aggregation_time * self.computation_energy_rate\n",
    "\n",
    "#         # Store edge server energy and time\n",
    "#         if edge_id not in self.energy_consumption['edge_servers']:\n",
    "#             self.energy_consumption['edge_servers'][edge_id] = 0.0\n",
    "#         if edge_id not in self.time_delays['edge_servers']:\n",
    "#             self.time_delays['edge_servers'][edge_id] = 0.0\n",
    "#         self.time_delays['edge_servers'][edge_id] += edge_computation_time\n",
    "#         self.energy_consumption['edge_servers'][edge_id] += edge_computation_energy\n",
    "\n",
    "#         # Update total bandwidth usage for communication with cloud\n",
    "#         self.bandwidth_usage['edge_to_cloud'] += self.model_size\n",
    "\n",
    "#         # Evaluate aggregated edge model\n",
    "#         edge_accuracy = self.evaluate_model(updated_edge_model_state, self.get_test_loader())\n",
    "#         print(f\"Edge Server {edge_id} - Edge Iteration {edge_iteration + 1} - Edge Model Accuracy: {edge_accuracy:.2f}%\")\n",
    "\n",
    "#         # Record edge_iteration accuracy\n",
    "#         if global_iteration not in self.accuracies['edge_iterations']:\n",
    "#             self.accuracies['edge_iterations'][global_iteration] = {}\n",
    "#         if edge_iteration not in self.accuracies['edge_iterations'][global_iteration]:\n",
    "#             self.accuracies['edge_iterations'][global_iteration][edge_iteration] = {}\n",
    "#         self.accuracies['edge_iterations'][global_iteration][edge_iteration][edge_id] = edge_accuracy\n",
    "\n",
    "#         # Return the updated model state for this edge server\n",
    "#         return updated_edge_model_state\n",
    "\n",
    "#     def recalculate_assignments(self):\n",
    "#         # Re-run cluster assignment agent\n",
    "#         self.cluster_env.devices_df = self.devices_df  # Update devices_df in the environment\n",
    "#         cluster_state = self.cluster_env.reset()\n",
    "#         cluster_action, _ = self.cluster_agent.predict(cluster_state)\n",
    "#         assignments = dict(zip(range(self.cluster_env.num_clusters), cluster_action))\n",
    "#         self.devices_df['assigned_servers'] = self.devices_df['cluster'].map(assignments)\n",
    "\n",
    "#         # Re-run device scheduling agent\n",
    "#         self.scheduling_env.devices_df = self.devices_df.reset_index(drop=True)  # Update devices_df in the environment\n",
    "#         scheduling_state = self.scheduling_env.reset()\n",
    "#         scheduling_action, _ = self.scheduling_agent.predict(scheduling_state)\n",
    "#         scheduled_devices = [i for i, a in enumerate(scheduling_action) if a == 1]\n",
    "#         self.devices_df['is_scheduled'] = False\n",
    "#         self.devices_df.loc[scheduled_devices, 'is_scheduled'] = True\n",
    "\n",
    "#         # Reset edge_servers\n",
    "#         self.edge_servers = {}\n",
    "\n",
    "#         # Recreate edge_servers with updated assignments, initializing model_state from global model\n",
    "#         for idx, row in self.devices_df.iterrows():\n",
    "#             if not row['is_scheduled']:\n",
    "#                 continue  # Skip unscheduled devices\n",
    "\n",
    "#             local_dataset = row[\"local_data\"]\n",
    "#             if not isinstance(local_dataset, LocalDataset):\n",
    "#                 continue\n",
    "\n",
    "#             images, labels = local_dataset.get_data()\n",
    "#             if len(images) == 0 or len(labels) == 0:\n",
    "#                 continue\n",
    "\n",
    "#             memory = row[\"memory\"]\n",
    "#             cpu_power = row[\"cpu_power\"]\n",
    "#             batch_size = self.compute_batch_size(memory, cpu_power)\n",
    "\n",
    "#             tensor_dataset = TensorDataset(\n",
    "#                 torch.tensor(images, dtype=torch.float32),\n",
    "#                 torch.tensor(labels, dtype=torch.long)\n",
    "#             )\n",
    "#             loader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#             edge_server_id = row[\"assigned_servers\"]\n",
    "#             if edge_server_id not in self.edge_servers:\n",
    "#                 self.edge_servers[edge_server_id] = {\n",
    "#                     'devices': [],\n",
    "#                     'model_state': deepcopy(self.global_model_state)  # Initialize from global model\n",
    "#                 }\n",
    "#             self.edge_servers[edge_server_id]['devices'].append((row[\"device_id\"], loader))\n",
    "\n",
    "#         # Print updated device distribution across edge servers\n",
    "#         print(\"Updated device distribution across edge servers:\")\n",
    "#         for edge_id, edge_info in self.edge_servers.items():\n",
    "#             num_devices = len(edge_info['devices'])\n",
    "#             print(f\"Edge Server {edge_id}: {num_devices} devices\")\n",
    "\n",
    "#     def federated_learning(self, global_model_state, max_parallel_edge_servers=2):\n",
    "#         \"\"\"\n",
    "#         Perform semi-synchronous federated learning with independent device training\n",
    "#         and multiple edge server iterations, ensuring local model updates after each iteration.\n",
    "#         Incorporates FedProx to stabilize training in heterogeneous environments.\n",
    "#         \"\"\"\n",
    "#         cloud_computation_time = 0.0\n",
    "#         cloud_computation_energy = 0.0\n",
    "\n",
    "#         for global_iteration in range(self.global_iterations):\n",
    "#             print(\"-\" * 60)\n",
    "#             print(f\"Global Iteration {global_iteration + 1}/{self.global_iterations}\")\n",
    "#             print(\"-\" * 60)\n",
    "\n",
    "#             # Recalculate assignments at the beginning of each global iteration\n",
    "#             self.global_model_state = deepcopy(global_model_state)  # Update global model state\n",
    "#             self.recalculate_assignments()\n",
    "\n",
    "#             # Initialize edge server models from the global model\n",
    "#             for edge_id in self.edge_servers.keys():\n",
    "#                 # Apply gradual mixing with the global model every m_global iterations\n",
    "#                 if global_iteration % self.m_global == 0:\n",
    "#                     alpha = min(self.alpha * (global_iteration + 1), 1.0)\n",
    "#                     self.edge_servers[edge_id]['model_state'] = self.mix_models(\n",
    "#                         self.edge_servers[edge_id]['model_state'],\n",
    "#                         self.global_model_state,\n",
    "#                         alpha\n",
    "#                     )\n",
    "\n",
    "#             for edge_iteration in range(self.edge_iterations):\n",
    "#                 print(f\"  Edge Iteration {edge_iteration + 1}/{self.edge_iterations}\")\n",
    "\n",
    "#                 edge_results = {}\n",
    "\n",
    "#                 # Use ThreadPoolExecutor to limit concurrent edge server training\n",
    "#                 with ThreadPoolExecutor(max_workers=max_parallel_edge_servers) as executor:\n",
    "#                     future_to_edge = {\n",
    "#                         executor.submit(\n",
    "#                             self.edge_server_training,\n",
    "#                             edge_id,\n",
    "#                             edge_info['devices'],\n",
    "#                             edge_info['model_state'],\n",
    "#                             edge_iteration,\n",
    "#                             global_iteration\n",
    "#                         ): edge_id\n",
    "#                         for edge_id, edge_info in self.edge_servers.items()\n",
    "#                     }\n",
    "\n",
    "#                     # Collect results as each edge server finishes\n",
    "#                     for future in as_completed(future_to_edge):\n",
    "#                         edge_id = future_to_edge[future]\n",
    "#                         try:\n",
    "#                             updated_state = future.result()  # Result is updated edge model state\n",
    "#                             edge_results[edge_id] = updated_state\n",
    "#                             # Update the edge server's model state\n",
    "#                             self.edge_servers[edge_id]['model_state'] = updated_state\n",
    "#                             print(f\"  Edge Server {edge_id}: Updated model after Edge Iteration {edge_iteration + 1}\")\n",
    "#                         except Exception as e:\n",
    "#                             print(f\"Edge Server {edge_id} encountered an error: {e}\")\n",
    "\n",
    "#                 # Periodically update edge models with global model\n",
    "#                 if (edge_iteration + 1) % self.k_edge == 0:\n",
    "#                     for edge_id in self.edge_servers.keys():\n",
    "#                         alpha = min(self.alpha * (edge_iteration + 1), 1.0)\n",
    "#                         self.edge_servers[edge_id]['model_state'] = self.mix_models(\n",
    "#                             self.edge_servers[edge_id]['model_state'],\n",
    "#                             self.global_model_state,\n",
    "#                             alpha\n",
    "#                         )\n",
    "\n",
    "#             # Perform global aggregation after all edge iterations\n",
    "#             global_states = [edge_info['model_state'] for edge_info in self.edge_servers.values()]\n",
    "#             self.global_model_state = self.aggregate_models(global_states)\n",
    "#             global_model_state = deepcopy(self.global_model_state)\n",
    "#             print(f\"Global Iteration {global_iteration + 1}: Aggregated all edge models\")\n",
    "\n",
    "#             # Cloud server computation time for aggregation\n",
    "#             num_edge_models = len(self.edge_servers)\n",
    "#             aggregation_time = num_edge_models * 0.2  # 0.2 seconds per edge model\n",
    "#             cloud_computation_time += aggregation_time\n",
    "#             cloud_computation_energy += aggregation_time * self.computation_energy_rate\n",
    "\n",
    "#             # Evaluate global model and store accuracy\n",
    "#             global_accuracy = self.evaluate_model(global_model_state, self.get_test_loader())\n",
    "#             print(f\"Global Iteration {global_iteration + 1}: Global Model Accuracy: {global_accuracy:.2f}%\")\n",
    "\n",
    "#             self.accuracies['global_iterations'].append(global_accuracy)\n",
    "\n",
    "#             # Periodically write accuracies to file\n",
    "#             with open(self.metrics_file, 'w') as f:\n",
    "#                 json.dump(self.accuracies, f, indent=4)\n",
    "\n",
    "#             # Note: Assignments will be recalculated at the beginning of the next global iteration\n",
    "\n",
    "#         # Store cloud server energy and time\n",
    "#         self.energy_consumption['cloud_server'] = cloud_computation_energy\n",
    "#         self.time_delays['cloud_server'] = cloud_computation_time\n",
    "\n",
    "#     def main(self, global_iterations, edge_iterations, local_epochs):\n",
    "#         self.global_iterations = global_iterations\n",
    "#         self.edge_iterations = edge_iterations\n",
    "#         self.local_epochs = local_epochs\n",
    "\n",
    "#         # Initialize global model state\n",
    "#         global_model = self.model_class(**self.model_args).to(self.device)\n",
    "#         self.global_model_state = deepcopy(global_model.state_dict())  # Initialize global model state\n",
    "\n",
    "#         # Run federated learning\n",
    "#         self.federated_learning(self.global_model_state, max_parallel_edge_servers=1)\n",
    "\n",
    "#         final_accuracy = self.evaluate_model(self.global_model_state, self.get_test_loader())\n",
    "#         print(f\"Final Global Model Accuracy: {final_accuracy:.2f}%\")\n",
    "\n",
    "#         # Save the accuracies to JSON\n",
    "#         with open(self.metrics_file.replace('.json', '_accuracies.json'), 'w') as json_file:\n",
    "#             json.dump(self.accuracies, json_file, indent=4)\n",
    "\n",
    "#         self.save_summary_metrics(self.metrics_file.replace('.json', '_full_metrics.json'))\n",
    "\n",
    "#         # After training, consolidate metrics into a single dictionary\n",
    "#         metrics_summary = {\n",
    "#             \"Energy Consumption\": self.energy_consumption,\n",
    "#             \"Time Delays\": self.time_delays,\n",
    "#             \"Bandwidth Usage\": self.bandwidth_usage,\n",
    "#         }\n",
    "\n",
    "#         # Save metrics to a JSON file\n",
    "#         with open(self.metrics_file.replace('.json', '_summary.json'), 'w') as f:\n",
    "#             json.dump(metrics_summary, f, indent=4)\n",
    "\n",
    "#     def get_test_loader(self):\n",
    "#         test_dataset = TensorDataset(\n",
    "#             torch.tensor(self.test_images, dtype=torch.float32),\n",
    "#             torch.tensor(self.test_labels, dtype=torch.long)\n",
    "#         )\n",
    "#         test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "#         return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from math import log\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "import os  # Added\n",
    "from datetime import datetime  # Optional: For timestamped checkpoints\n",
    "\n",
    "# Placeholder imports for model architectures and dataset\n",
    "# Replace these with actual imports from your project\n",
    "# from your_model_file import DenseNet, DLA, BasicBlock\n",
    "# from your_dataset_file import LocalDataset\n",
    "\n",
    "class FederatedLearningSystem:\n",
    "    def __init__(self, devices_df, test_images, test_labels, dataset_name, metrics_file,\n",
    "                 cluster_agent, scheduling_agent, cluster_env, scheduling_env, checkpoint_dir='checkpoints', **kwargs):\n",
    "        self.devices_df = devices_df.reset_index(drop=True)\n",
    "        self.test_images = test_images\n",
    "        self.test_labels = test_labels\n",
    "        self.dataset_name = dataset_name\n",
    "        self.metrics_file = metrics_file\n",
    "        self.edge_servers = {}\n",
    "        self.accuracies = {\n",
    "            'local_epochs': {},       # Store local epoch accuracies per device\n",
    "            'edge_iterations': {},    # Store edge iteration accuracies per edge server\n",
    "            'global_iterations': []   # Store global iteration accuracies\n",
    "        }\n",
    "\n",
    "        # Model selection based on dataset name\n",
    "        if dataset_name in ['mnist', 'fashion_mnist']:\n",
    "            self.model_class = DenseNet  # Assign the class, not an instance\n",
    "            self.model_args = {\n",
    "                'in_channels': 1,\n",
    "                'growthRate': 12,\n",
    "                'depth': 100,\n",
    "                'reduction': 0.5,\n",
    "                'nClasses': 10,\n",
    "                'bottleneck': True\n",
    "            }\n",
    "        elif dataset_name == 'cifar10':\n",
    "            self.model_class = DLA  # Replace with DLA if needed\n",
    "            self.model_args = {\n",
    "                'block': BasicBlock,\n",
    "                'num_classes': 10\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
    "\n",
    "        # Additional parameters\n",
    "        self.global_iterations = kwargs.get('global_iterations', 5)\n",
    "        self.edge_iterations = kwargs.get('edge_iterations', 3)\n",
    "        self.local_epochs = kwargs.get('local_epochs', 1)\n",
    "        self.input_channels = kwargs.get('input_channels', 1)\n",
    "        self.num_classes = kwargs.get('num_classes', 10)\n",
    "        self.batch_size = kwargs.get('batch_size', 32)\n",
    "\n",
    "        # Parameters for Scenario 3\n",
    "        self.k_edge = kwargs.get('k_edge', 2)\n",
    "        self.m_global = kwargs.get('m_global', 1)\n",
    "        self.alpha = kwargs.get('alpha', 0.1)\n",
    "\n",
    "        # Parameters for FedProx\n",
    "        self.mu = kwargs.get('mu', 0.1)  # FedProx hyperparameter\n",
    "\n",
    "        # Initialize parameters for energy and time calculations\n",
    "        self.model_size = kwargs.get('model_size', 1.0)                # Size in MB\n",
    "        self.computation_energy_rate = kwargs.get('computation_energy_rate', 0.5)   # Energy per second\n",
    "        self.communication_energy_rate = kwargs.get('communication_energy_rate', 0.1)  # Energy per MB\n",
    "        self.device_latency = kwargs.get('device_latency', 0.1)        # Seconds\n",
    "        self.edge_latency = kwargs.get('edge_latency', 0.05)           # Seconds\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Dictionaries to store energy and time metrics\n",
    "        self.energy_consumption = {\n",
    "            'devices': {},\n",
    "            'edge_servers': {},\n",
    "            'cloud_server': 0.0\n",
    "        }\n",
    "        self.time_delays = {\n",
    "            'devices': {},\n",
    "            'edge_servers': {},\n",
    "            'cloud_server': 0.0\n",
    "        }\n",
    "        self.bandwidth_usage = {\n",
    "            'device_to_edge': 0.0,\n",
    "            'edge_to_cloud': 0.0\n",
    "        }\n",
    "\n",
    "        # Store agents and environments for reuse\n",
    "        self.cluster_agent = cluster_agent\n",
    "        self.scheduling_agent = scheduling_agent\n",
    "        self.cluster_env = cluster_env\n",
    "        self.scheduling_env = scheduling_env\n",
    "\n",
    "        # Checkpointing setup (Added)\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        if not os.path.exists(self.checkpoint_dir):\n",
    "            os.makedirs(self.checkpoint_dir)\n",
    "            print(f\"Checkpoint directory '{self.checkpoint_dir}' created.\")\n",
    "        else:\n",
    "            print(f\"Checkpoint directory '{self.checkpoint_dir}' already exists.\")\n",
    "\n",
    "        # Verify and enforce parameter types\n",
    "        self.verify_and_enforce_parameter_types()\n",
    "\n",
    "    def verify_and_enforce_parameter_types(self):\n",
    "        \"\"\"\n",
    "        Verify that all model parameters are floating point. If not, cast them to float.\n",
    "        \"\"\"\n",
    "        model = self.model_class(**self.model_args).to(self.device)\n",
    "        for name, param in model.named_parameters():\n",
    "            if not param.dtype.is_floating_point:\n",
    "                print(f\"Parameter {name} is of type {param.dtype}. Casting to torch.float32.\")\n",
    "                param.data = param.data.float()\n",
    "        # Update the global model state after enforcement\n",
    "        self.global_model_state = deepcopy(model.state_dict())\n",
    "\n",
    "    def compute_computation_time(self, num_samples, cpu_power):\n",
    "        \"\"\"\n",
    "        Compute computation time based on number of samples and CPU power.\n",
    "        Simple linear model: Time = Number of samples / CPU Power\n",
    "        \"\"\"\n",
    "        return num_samples / cpu_power\n",
    "\n",
    "    def compute_computation_energy(self, computation_time):\n",
    "        \"\"\"\n",
    "        Compute computation energy based on computation time.\n",
    "        Energy = Computation Time * Energy Rate\n",
    "        \"\"\"\n",
    "        return computation_time * self.computation_energy_rate\n",
    "\n",
    "    def compute_communication_time(self, data_size_mb, bandwidth_mbps, latency):\n",
    "        \"\"\"\n",
    "        Compute communication time based on data size, bandwidth, and latency.\n",
    "        Time = Data Size / Bandwidth + Latency\n",
    "        \"\"\"\n",
    "        return (data_size_mb / bandwidth_mbps) + latency\n",
    "\n",
    "    def compute_communication_energy(self, data_size_mb):\n",
    "        \"\"\"\n",
    "        Compute communication energy based on data size.\n",
    "        Energy = Data Size * Energy Rate\n",
    "        \"\"\"\n",
    "        return data_size_mb * self.communication_energy_rate\n",
    "\n",
    "    def compute_batch_size(self, memory, cpu_power):\n",
    "        \"\"\"\n",
    "        Adjust batch size based on device memory and CPU power.\n",
    "        \"\"\"\n",
    "        base_batch_size = 34\n",
    "        memory_factor = memory / 2  # Assume memory ranges from 1 to 4 GB\n",
    "        cpu_factor = cpu_power / 1.0  # Assume CPU power ranges from 1.0 to 2.0 GHz\n",
    "        batch_size = int(base_batch_size * memory_factor * cpu_factor)\n",
    "        return int(round(max(24, min(batch_size, 64))))  # Batch size capped between 24 and 64\n",
    "\n",
    "    def mix_models(self, local_state, global_state, alpha):\n",
    "        \"\"\"\n",
    "        Gradually mix the global/edge model into the local model using the formula:\n",
    "        w_local = alpha * w_global/edge + (1 - alpha) * w_local\n",
    "        \"\"\"\n",
    "        mixed_state = {}\n",
    "        for key in local_state.keys():\n",
    "            # Ensure tensors are on CPU and detached\n",
    "            global_tensor = global_state[key].clone().detach().to(self.device)\n",
    "            local_tensor = local_state[key].clone().detach().to(self.device)\n",
    "            mixed_state[key] = alpha * global_tensor + (1 - alpha) * local_tensor\n",
    "        return mixed_state\n",
    "\n",
    "    def layer_wise_update(self, local_state, global_state, shared_layers):\n",
    "        \"\"\"\n",
    "        Update only the shared layers in the local model with the global model.\n",
    "        \"\"\"\n",
    "        updated_state = deepcopy(local_state)\n",
    "        for key in shared_layers:\n",
    "            if key in global_state:\n",
    "                updated_state[key] = global_state[key]\n",
    "        return updated_state\n",
    "\n",
    "    def get_shared_layer_keys(self, model):\n",
    "        \"\"\"\n",
    "        Get the keys of the shared layers (e.g., feature extraction layers).\n",
    "        \"\"\"\n",
    "        shared_layers = []\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'classifier' not in name and 'fc' not in name:\n",
    "                shared_layers.append(name)\n",
    "        return shared_layers\n",
    "\n",
    "    def calculate_label_distribution(self, edge_devices):\n",
    "        \"\"\"\n",
    "        Calculate label distribution for each edge server.\n",
    "\n",
    "        Args:\n",
    "            edge_devices (list): List of tuples containing device_id and DataLoader.\n",
    "\n",
    "        Returns:\n",
    "            dict: Mapping from label to count.\n",
    "        \"\"\"\n",
    "        label_counts = defaultdict(int)\n",
    "        for device_id, loader in edge_devices:\n",
    "            for _, labels in loader:\n",
    "                labels = labels.cpu().numpy()\n",
    "                for label in labels:\n",
    "                    label_counts[label] += 1\n",
    "        return label_counts\n",
    "\n",
    "    def save_checkpoint(self, model_state, global_iteration):\n",
    "        \"\"\"\n",
    "        Save the global model's state_dict as a checkpoint.\n",
    "\n",
    "        Args:\n",
    "            model_state (dict): The state_dict of the global model.\n",
    "            global_iteration (int): The current global iteration number.\n",
    "        \"\"\"\n",
    "        checkpoint_filename = f\"global_model_iter_{global_iteration + 1}.pth\"\n",
    "        checkpoint_path = os.path.join(self.checkpoint_dir, checkpoint_filename)\n",
    "        \n",
    "        try:\n",
    "            torch.save(model_state, checkpoint_path)\n",
    "            print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving checkpoint at iteration {global_iteration + 1}: {e}\")\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"\n",
    "        Load a model checkpoint.\n",
    "\n",
    "        Args:\n",
    "            checkpoint_path (str): Path to the checkpoint file.\n",
    "\n",
    "        Returns:\n",
    "            dict: The loaded state_dict.\n",
    "        \"\"\"\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            try:\n",
    "                state_dict = torch.load(checkpoint_path, map_location=self.device)\n",
    "                print(f\"Checkpoint loaded: {checkpoint_path}\")\n",
    "                return state_dict\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading checkpoint from {checkpoint_path}: {e}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Checkpoint file {checkpoint_path} does not exist.\")\n",
    "            return None\n",
    "\n",
    "    def train_local_model(self, device_id, local_model_state, edge_model_state, global_model_state,\n",
    "                          train_loader, epochs, edge_iteration, global_iteration, lr=0.0001):\n",
    "        \"\"\"\n",
    "        Train the local model on a specific device while considering its CPU power and memory.\n",
    "        Incorporates FedProx by adding a proximal term to the loss function.\n",
    "        Includes ReduceLROnPlateau to dynamically adjust the learning rate.\n",
    "        Returns:\n",
    "            tuple: (device_id, delta_model, local_steps)\n",
    "        \"\"\"\n",
    "        device = self.device\n",
    "        model = self.model_class(**self.model_args).to(device)\n",
    "\n",
    "        # Load the local model state\n",
    "        local_state = deepcopy(local_model_state)\n",
    "\n",
    "        # Apply gradual mixing with edge/global model periodically\n",
    "        if edge_iteration % self.k_edge == 0:\n",
    "            alpha = min(self.alpha * (edge_iteration + 1), 1.0)  # Increase alpha over time\n",
    "            local_state = self.mix_models(local_state, edge_model_state, alpha)\n",
    "\n",
    "        if global_iteration % self.m_global == 0:\n",
    "            alpha = min(self.alpha * (global_iteration + 1), 1.0)\n",
    "            local_state = self.mix_models(local_state, global_model_state, alpha)\n",
    "\n",
    "        # Apply layer-wise updating to only update shared layers\n",
    "        shared_layers = self.get_shared_layer_keys(model)\n",
    "        local_state = self.layer_wise_update(local_state, local_model_state, shared_layers)\n",
    "\n",
    "        model.load_state_dict(local_state)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)  # Added weight_decay\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Fetch device-specific characteristics\n",
    "        device_info = self.devices_df.loc[self.devices_df['device_id'] == device_id].iloc[0]\n",
    "        cpu_power = device_info['cpu_power']  # GHz\n",
    "        memory = device_info['memory']       # GB\n",
    "\n",
    "        # Adjust batch size based on memory\n",
    "        adjusted_batch_size = self.compute_batch_size(memory, cpu_power)\n",
    "\n",
    "        # Simulate adjusted training time and energy\n",
    "        num_samples = len(train_loader.dataset)\n",
    "        computation_time_per_epoch = self.compute_computation_time(num_samples, cpu_power)\n",
    "        computation_energy_per_epoch = self.compute_computation_energy(computation_time_per_epoch)\n",
    "\n",
    "        # Update DataLoader with adjusted batch size\n",
    "        train_loader = DataLoader(train_loader.dataset, batch_size=adjusted_batch_size, shuffle=True)\n",
    "\n",
    "        # Store energy and time metrics\n",
    "        total_training_time = 0\n",
    "        total_training_energy = 0\n",
    "\n",
    "        # Initialize local steps counter\n",
    "        local_steps = 0\n",
    "\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        best_loss = float('inf')\n",
    "        patience = 3\n",
    "        trigger_times = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            correct, total = 0, 0\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Compute FedProx proximal term in a vectorized manner\n",
    "                shared_params = [param for name, param in model.named_parameters() if name in shared_layers]\n",
    "                global_shared_params = [global_model_state[name].to(device) for name in shared_layers]\n",
    "\n",
    "                # Vectorize parameters using parameters_to_vector\n",
    "                local_params_vector = parameters_to_vector(shared_params)\n",
    "                global_params_vector = parameters_to_vector(global_shared_params)\n",
    "\n",
    "                proximal_loss = torch.norm(local_params_vector - global_params_vector) ** 2\n",
    "                proximal_loss = (self.mu / 2) * proximal_loss\n",
    "\n",
    "                # Total loss\n",
    "                total_loss = loss + proximal_loss\n",
    "                total_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += total_loss.item()\n",
    "\n",
    "                # Increment local steps\n",
    "                local_steps += 1\n",
    "\n",
    "                # Calculate training accuracy for the current batch\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "            # Simulate time and energy per epoch\n",
    "            total_training_time += computation_time_per_epoch\n",
    "            total_training_energy += computation_energy_per_epoch\n",
    "\n",
    "            # Log accuracy and loss for the epoch\n",
    "            epoch_accuracy = 100 * correct / total\n",
    "            epoch_loss = running_loss / len(train_loader)\n",
    "            print(f\"Device {device_id} - Epoch {epoch + 1}/{epochs} - Accuracy: {epoch_accuracy:.2f}%, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "            # Adjust learning rate based on loss\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "            # Early stopping logic\n",
    "            if epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                trigger_times = 0\n",
    "            else:\n",
    "                trigger_times += 1\n",
    "                print(f\"Device {device_id} - Early stopping trigger {trigger_times}/{patience}\")\n",
    "                if trigger_times >= patience:\n",
    "                    print(f\"Device {device_id} - Early stopping\")\n",
    "                    break\n",
    "\n",
    "            # Store epoch accuracy\n",
    "            if device_id not in self.accuracies['local_epochs']:\n",
    "                self.accuracies['local_epochs'][device_id] = []\n",
    "            self.accuracies['local_epochs'][device_id].append(epoch_accuracy)\n",
    "\n",
    "        # Update total time and energy for the device\n",
    "        if device_id not in self.energy_consumption['devices']:\n",
    "            self.energy_consumption['devices'][device_id] = 0.0\n",
    "        if device_id not in self.time_delays['devices']:\n",
    "            self.time_delays['devices'][device_id] = 0.0\n",
    "\n",
    "        self.energy_consumption['devices'][device_id] += total_training_energy\n",
    "        self.time_delays['devices'][device_id] += total_training_time\n",
    "\n",
    "        print(f\"Device {device_id} - Total Training Time: {total_training_time:.2f}s\")\n",
    "        print(f\"Device {device_id} - Total Training Energy: {total_training_energy:.2f}J\")\n",
    "\n",
    "        # Calculate delta (model update)\n",
    "        delta_model = {}\n",
    "        for key in model.state_dict().keys():\n",
    "            delta_model[key] = model.state_dict()[key] - local_state[key]\n",
    "\n",
    "        # Return the delta and effective number of local steps\n",
    "        return device_id, delta_model, local_steps\n",
    "\n",
    "    def aggregate_models_fednova(self, base_model_state, local_results, total_steps):\n",
    "        \"\"\"\n",
    "        Aggregate local updates using FedNova.\n",
    "\n",
    "        Args:\n",
    "            base_model_state (dict): The model state before local updates (edge_model_state).\n",
    "            local_results (list): List of tuples (delta_model, local_steps) from devices.\n",
    "            total_steps (int): Total effective local steps from all devices.\n",
    "\n",
    "        Returns:\n",
    "            dict: Updated model state after aggregation.\n",
    "        \"\"\"\n",
    "        aggregated_delta = {}\n",
    "        for key in base_model_state.keys():\n",
    "            # Initialize as float tensors\n",
    "            aggregated_delta[key] = torch.zeros_like(base_model_state[key], dtype=torch.float32)\n",
    "\n",
    "        # Aggregate normalized updates\n",
    "        for delta_model, local_steps in local_results:\n",
    "            scaling_factor = local_steps / total_steps\n",
    "            for key in delta_model.keys():\n",
    "                # Ensure delta_model[key] is float\n",
    "                delta_tensor = delta_model[key].to(self.device).float()\n",
    "                aggregated_delta[key] += delta_tensor * scaling_factor\n",
    "\n",
    "        # Update the base model state\n",
    "        updated_model_state = {}\n",
    "        for key in base_model_state.keys():\n",
    "            updated_model_state[key] = base_model_state[key].to(self.device).float() + aggregated_delta[key]\n",
    "\n",
    "        return updated_model_state\n",
    "\n",
    "    def aggregate_models_global_fednova(self, global_model_state, edge_deltas, edge_steps_list, total_global_steps):\n",
    "        \"\"\"\n",
    "        Aggregate edge server updates using FedNova at the global level.\n",
    "\n",
    "        Args:\n",
    "            global_model_state (dict): The current global model state.\n",
    "            edge_deltas (list): List of delta_model dicts from edge servers.\n",
    "            edge_steps_list (list): List of local steps from edge servers.\n",
    "            total_global_steps (int): Total steps from all edge servers.\n",
    "\n",
    "        Returns:\n",
    "            dict: Updated global model state after aggregation.\n",
    "        \"\"\"\n",
    "        aggregated_delta = {}\n",
    "        for key in global_model_state.keys():\n",
    "            # Initialize as float tensors\n",
    "            aggregated_delta[key] = torch.zeros_like(global_model_state[key], dtype=torch.float32)\n",
    "\n",
    "        # Aggregate normalized updates\n",
    "        for delta_model, edge_steps in zip(edge_deltas, edge_steps_list):\n",
    "            scaling_factor = edge_steps / total_global_steps\n",
    "            for key in delta_model.keys():\n",
    "                # Ensure delta_model[key] is float\n",
    "                delta_tensor = delta_model[key].to(self.device).float()\n",
    "                aggregated_delta[key] += delta_tensor * scaling_factor\n",
    "\n",
    "        # Update the global model state\n",
    "        updated_global_model_state = {}\n",
    "        for key in global_model_state.keys():\n",
    "            updated_global_model_state[key] = global_model_state[key].to(self.device).float() + aggregated_delta[key]\n",
    "\n",
    "        return updated_global_model_state\n",
    "\n",
    "    def evaluate_model(self, model_state, test_loader):\n",
    "        \"\"\"\n",
    "        Evaluate the model on the test dataset.\n",
    "\n",
    "        Args:\n",
    "            model_state (dict): Model state_dict.\n",
    "            test_loader (DataLoader): DataLoader for the test dataset.\n",
    "\n",
    "        Returns:\n",
    "            float: Overall accuracy percentage.\n",
    "        \"\"\"\n",
    "        device = self.device\n",
    "        model = self.model_class(**self.model_args).to(device)\n",
    "        model.load_state_dict(model_state)\n",
    "        model.eval()\n",
    "        total, correct = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate overall accuracy\n",
    "        overall_accuracy = 100 * correct / total\n",
    "\n",
    "        # Log accuracies\n",
    "        self.accuracies['global_iterations'].append(overall_accuracy)\n",
    "\n",
    "        # Print overall accuracy\n",
    "        print(f\"Overall Global Model Accuracy: {overall_accuracy:.2f}%\")\n",
    "\n",
    "        return overall_accuracy\n",
    "\n",
    "    def save_summary_metrics(self, summary_file=\"metrics_summary.json\"):\n",
    "        \"\"\"\n",
    "        Consolidate and save key metrics for communication costs, energy consumption, \n",
    "        and training performance.\n",
    "        \"\"\"\n",
    "        summary_metrics = {\n",
    "            \"global_iterations\": self.global_iterations,\n",
    "            \"edge_iterations\": self.edge_iterations,\n",
    "            \"local_epochs\": self.local_epochs,\n",
    "            \"overall_energy_consumption\": self.energy_consumption,\n",
    "            \"overall_time_delays\": self.time_delays,\n",
    "            \"overall_bandwidth_usage\": self.bandwidth_usage,\n",
    "            \"global_model_accuracy\": self.accuracies.get(\"global_iterations\", [])\n",
    "        }\n",
    "\n",
    "        # Save the summary to a JSON file\n",
    "        with open(summary_file, 'w') as f:\n",
    "            json.dump(summary_metrics, f, indent=4)\n",
    "\n",
    "        print(f\"Summary metrics saved to {summary_file}\")\n",
    "\n",
    "    def edge_server_training(self, edge_id, edge_devices, edge_model_state, edge_iteration, global_iteration):\n",
    "        \"\"\"\n",
    "        Train devices assigned to the edge server independently and update the local model after each edge iteration.\n",
    "        \"\"\"\n",
    "        edge_computation_time = 0.0\n",
    "        edge_computation_energy = 0.0\n",
    "\n",
    "        communication_costs = []\n",
    "        communication_latencies = []\n",
    "        communication_energies = []\n",
    "\n",
    "        print(f\"Edge Server {edge_id}: Starting training\")\n",
    "        # Edge server's current model state is passed as edge_model_state\n",
    "\n",
    "        local_results = []    # Collect (delta_model, local_steps) from devices\n",
    "        total_edge_steps = 0  # Total effective steps at the edge server\n",
    "\n",
    "        for device_id, train_loader in edge_devices:\n",
    "            print(f\"Edge Server {edge_id} sends model to Device {device_id} for training.\")\n",
    "            # Train local model starting from global_model_state\n",
    "            device_id, delta_model, local_steps = self.train_local_model(\n",
    "                device_id,\n",
    "                self.global_model_state,    # local_model_state initialized with global model\n",
    "                edge_model_state,           # edge_model_state\n",
    "                self.global_model_state,    # global_model_state\n",
    "                train_loader,\n",
    "                self.local_epochs,\n",
    "                edge_iteration,\n",
    "                global_iteration\n",
    "            )\n",
    "            local_results.append((delta_model, local_steps))\n",
    "            total_edge_steps += local_steps\n",
    "\n",
    "            # Communication metrics: time and energy from device to edge server\n",
    "            device_info = self.devices_df.loc[self.devices_df['device_id'] == device_id].iloc[0]\n",
    "            bandwidth = device_info['bandwidth']  # in Mbps\n",
    "            communication_time = self.compute_communication_time(\n",
    "                self.model_size,\n",
    "                bandwidth,\n",
    "                self.device_latency\n",
    "            )\n",
    "            communication_energy = self.compute_communication_energy(self.model_size)\n",
    "\n",
    "            communication_costs.append(self.model_size)\n",
    "            communication_latencies.append(communication_time)\n",
    "            communication_energies.append(communication_energy)\n",
    "\n",
    "            # Update device energy and time\n",
    "            self.time_delays['devices'][device_id] += communication_time\n",
    "            self.energy_consumption['devices'][device_id] += communication_energy\n",
    "\n",
    "            # Update total bandwidth usage\n",
    "            self.bandwidth_usage['device_to_edge'] += self.model_size\n",
    "\n",
    "        # Aggregate models from devices using FedNova\n",
    "        updated_edge_model_state = self.aggregate_models_fednova(\n",
    "            edge_model_state,\n",
    "            local_results,\n",
    "            total_edge_steps\n",
    "        )\n",
    "        print(f\"Edge Server {edge_id}: Aggregated models from devices\")\n",
    "\n",
    "        # Edge server computation time for aggregation\n",
    "        num_models = len(local_results)\n",
    "        aggregation_time = num_models * 0.1  # 0.1 seconds per model\n",
    "        edge_computation_time += aggregation_time\n",
    "        edge_computation_energy += aggregation_time * self.computation_energy_rate\n",
    "\n",
    "        # Store edge server energy and time\n",
    "        if edge_id not in self.energy_consumption['edge_servers']:\n",
    "            self.energy_consumption['edge_servers'][edge_id] = 0.0\n",
    "        if edge_id not in self.time_delays['edge_servers']:\n",
    "            self.time_delays['edge_servers'][edge_id] = 0.0\n",
    "        self.time_delays['edge_servers'][edge_id] += edge_computation_time\n",
    "        self.energy_consumption['edge_servers'][edge_id] += edge_computation_energy\n",
    "\n",
    "        # Update total bandwidth usage for communication with cloud\n",
    "        self.bandwidth_usage['edge_to_cloud'] += self.model_size\n",
    "\n",
    "        # Evaluate aggregated edge model\n",
    "        edge_accuracy = self.evaluate_model(updated_edge_model_state, self.get_test_loader())\n",
    "        print(f\"Edge Server {edge_id} - Edge Iteration {edge_iteration + 1} - Edge Model Accuracy: {edge_accuracy:.2f}%\")\n",
    "\n",
    "        # Record edge_iteration accuracy\n",
    "        if global_iteration not in self.accuracies['edge_iterations']:\n",
    "            self.accuracies['edge_iterations'][global_iteration] = {}\n",
    "        if edge_iteration not in self.accuracies['edge_iterations'][global_iteration]:\n",
    "            self.accuracies['edge_iterations'][global_iteration][edge_iteration] = {}\n",
    "        self.accuracies['edge_iterations'][global_iteration][edge_iteration][edge_id] = edge_accuracy\n",
    "\n",
    "        # Update edge server's total steps\n",
    "        self.edge_servers[edge_id]['total_edge_steps'] = total_edge_steps\n",
    "\n",
    "        # Return the updated model state for this edge server\n",
    "        return updated_edge_model_state\n",
    "\n",
    "    def recalculate_assignments(self):\n",
    "        \"\"\"\n",
    "        Re-run cluster and scheduling agents to assign devices to edge servers.\n",
    "        Recreate edge servers with updated assignments, initializing model_state from global model.\n",
    "        Calculate label distributions and total samples for each edge server.\n",
    "        \"\"\"\n",
    "        # Re-run cluster assignment agent\n",
    "        self.cluster_env.devices_df = self.devices_df  # Update devices_df in the environment\n",
    "        cluster_state = self.cluster_env.reset()\n",
    "        cluster_action, _ = self.cluster_agent.predict(cluster_state)\n",
    "        assignments = dict(zip(range(self.cluster_env.num_clusters), cluster_action))\n",
    "        self.devices_df['assigned_servers'] = self.devices_df['cluster'].map(assignments)\n",
    "\n",
    "        # Re-run device scheduling agent\n",
    "        self.scheduling_env.devices_df = self.devices_df.reset_index(drop=True)  # Update devices_df in the environment\n",
    "        scheduling_state = self.scheduling_env.reset()\n",
    "        scheduling_action, _ = self.scheduling_agent.predict(scheduling_state)\n",
    "        scheduled_devices = [i for i, a in enumerate(scheduling_action) if a == 1]\n",
    "        self.devices_df['is_scheduled'] = False\n",
    "        self.devices_df.loc[scheduled_devices, 'is_scheduled'] = True\n",
    "\n",
    "        # Reset edge_servers\n",
    "        self.edge_servers = {}\n",
    "\n",
    "        # Recreate edge_servers with updated assignments, initializing model_state from global model\n",
    "        for idx, row in self.devices_df.iterrows():\n",
    "            if not row['is_scheduled']:\n",
    "                continue  # Skip unscheduled devices\n",
    "\n",
    "            local_dataset = row[\"local_data\"]\n",
    "            if not isinstance(local_dataset, LocalDataset):\n",
    "                continue\n",
    "\n",
    "            images, labels = local_dataset.get_data()\n",
    "            if len(images) == 0 or len(labels) == 0:\n",
    "                continue\n",
    "\n",
    "            memory = row[\"memory\"]\n",
    "            cpu_power = row[\"cpu_power\"]\n",
    "            batch_size = self.compute_batch_size(memory, cpu_power)\n",
    "\n",
    "            # Ensure data types are correct\n",
    "            loader = self.prepare_data_loader(images, labels, batch_size)\n",
    "\n",
    "            edge_server_id = row[\"assigned_servers\"]\n",
    "            if edge_server_id not in self.edge_servers:\n",
    "                self.edge_servers[edge_server_id] = {\n",
    "                    'devices': [],\n",
    "                    'model_state': deepcopy(self.global_model_state),  # Initialize from global model\n",
    "                    'label_distribution': defaultdict(int),             # Initialize label distribution\n",
    "                    'total_samples': 0                                # Initialize sample count\n",
    "                }\n",
    "            self.edge_servers[edge_server_id]['devices'].append((row[\"device_id\"], loader))\n",
    "\n",
    "            # Update label distribution and sample count\n",
    "            label_counts = self.calculate_label_distribution([(row[\"device_id\"], loader)])\n",
    "            for label, count in label_counts.items():\n",
    "                self.edge_servers[edge_server_id]['label_distribution'][label] += count\n",
    "                self.edge_servers[edge_server_id]['total_samples'] += count\n",
    "\n",
    "        # Print updated device distribution across edge servers\n",
    "        print(\"Updated device distribution across edge servers:\")\n",
    "        for edge_id, edge_info in self.edge_servers.items():\n",
    "            num_devices = len(edge_info['devices'])\n",
    "            print(f\"Edge Server {edge_id}: {num_devices} devices\")\n",
    "            print(f\"  Label Distribution: {dict(edge_info['label_distribution'])}\")\n",
    "\n",
    "    def federated_learning(self, global_model_state, max_parallel_edge_servers=2):\n",
    "        \"\"\"\n",
    "        Perform semi-synchronous federated learning with independent device training\n",
    "        and multiple edge server iterations, ensuring local model updates after each iteration.\n",
    "        Incorporates FedProx and FedNova to stabilize training in heterogeneous environments.\n",
    "        \"\"\"\n",
    "        cloud_computation_time = 0.0\n",
    "        cloud_computation_energy = 0.0\n",
    "\n",
    "        for global_iteration in range(self.global_iterations):\n",
    "            print(\"-\" * 60)\n",
    "            print(f\"Global Iteration {global_iteration + 1}/{self.global_iterations}\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "            # Recalculate assignments at the beginning of each global iteration\n",
    "            self.global_model_state = deepcopy(global_model_state)  # Update global model state\n",
    "            self.recalculate_assignments()\n",
    "\n",
    "            # Initialize edge server models from the global model\n",
    "            for edge_id in self.edge_servers.keys():\n",
    "                # Apply gradual mixing with the global model every m_global iterations\n",
    "                if global_iteration % self.m_global == 0:\n",
    "                    alpha = min(self.alpha * (global_iteration + 1), 1.0)\n",
    "                    self.edge_servers[edge_id]['model_state'] = self.mix_models(\n",
    "                        self.edge_servers[edge_id]['model_state'],\n",
    "                        self.global_model_state,\n",
    "                        alpha\n",
    "                    )\n",
    "\n",
    "            for edge_iteration in range(self.edge_iterations):\n",
    "                print(f\"  Edge Iteration {edge_iteration + 1}/{self.edge_iterations}\")\n",
    "\n",
    "                # Use ThreadPoolExecutor to limit concurrent edge server training\n",
    "                with ThreadPoolExecutor(max_workers=max_parallel_edge_servers) as executor:\n",
    "                    future_to_edge = {\n",
    "                        executor.submit(\n",
    "                            self.edge_server_training,\n",
    "                            edge_id,\n",
    "                            edge_info['devices'],\n",
    "                            edge_info['model_state'],\n",
    "                            edge_iteration,\n",
    "                            global_iteration\n",
    "                        ): edge_id\n",
    "                        for edge_id, edge_info in self.edge_servers.items()\n",
    "                    }\n",
    "\n",
    "                    # Collect results as each edge server finishes\n",
    "                    for future in as_completed(future_to_edge):\n",
    "                        edge_id = future_to_edge[future]\n",
    "                        try:\n",
    "                            updated_state = future.result()  # Result is updated edge model state\n",
    "                            # Update the edge server's model state\n",
    "                            self.edge_servers[edge_id]['model_state'] = updated_state\n",
    "                            print(f\"  Edge Server {edge_id}: Updated model after Edge Iteration {edge_iteration + 1}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Edge Server {edge_id} encountered an error: {e}\")\n",
    "\n",
    "            # After all edge iterations, perform global aggregation using FedNova\n",
    "            edge_deltas = []\n",
    "            edge_steps_list = []\n",
    "            total_global_steps = 0\n",
    "\n",
    "            for edge_id, edge_info in self.edge_servers.items():\n",
    "                delta_model = {}\n",
    "                for key in edge_info['model_state'].keys():\n",
    "                    delta_model[key] = edge_info['model_state'][key] - self.global_model_state[key]\n",
    "                edge_deltas.append(delta_model)\n",
    "                edge_steps_list.append(edge_info['total_edge_steps'])\n",
    "                total_global_steps += edge_info['total_edge_steps']\n",
    "\n",
    "            # Aggregate edge server updates using FedNova\n",
    "            self.global_model_state = self.aggregate_models_global_fednova(\n",
    "                self.global_model_state,\n",
    "                edge_deltas,\n",
    "                edge_steps_list,\n",
    "                total_global_steps\n",
    "            )\n",
    "            global_model_state = deepcopy(self.global_model_state)\n",
    "            print(f\"Global Iteration {global_iteration + 1}: Aggregated all edge models using FedNova\")\n",
    "\n",
    "            # Update edge server models with the new global model\n",
    "            for edge_id in self.edge_servers.keys():\n",
    "                self.edge_servers[edge_id]['model_state'] = deepcopy(self.global_model_state)\n",
    "\n",
    "            # Cloud server computation time for aggregation\n",
    "            num_edge_models = len(self.edge_servers)\n",
    "            aggregation_time = num_edge_models * 0.2  # 0.2 seconds per edge model\n",
    "            cloud_computation_time += aggregation_time\n",
    "            cloud_computation_energy += aggregation_time * self.computation_energy_rate\n",
    "\n",
    "            # Evaluate global model and store accuracy\n",
    "            global_accuracy = self.evaluate_model(global_model_state, self.get_test_loader())\n",
    "            print(f\"Global Iteration {global_iteration + 1}: Global Model Accuracy: {global_accuracy:.2f}%\")\n",
    "\n",
    "            self.accuracies['global_iterations'].append(global_accuracy)\n",
    "\n",
    "            # Save the checkpoint after evaluating the global model\n",
    "            self.save_checkpoint(self.global_model_state, global_iteration)\n",
    "\n",
    "            # Periodically write accuracies to file\n",
    "            with open(self.metrics_file, 'w') as f:\n",
    "                json.dump(self.accuracies, f, indent=4)\n",
    "\n",
    "            # Note: Assignments will be recalculated at the beginning of the next global iteration\n",
    "\n",
    "        # Store cloud server energy and time\n",
    "        self.energy_consumption['cloud_server'] = cloud_computation_energy\n",
    "        self.time_delays['cloud_server'] = cloud_computation_time\n",
    "\n",
    "    def main(self, global_iterations, edge_iterations, local_epochs):\n",
    "        \"\"\"\n",
    "        Initialize the global model and start the federated learning process.\n",
    "        \"\"\"\n",
    "        self.global_iterations = global_iterations\n",
    "        self.edge_iterations = edge_iterations\n",
    "        self.local_epochs = local_epochs\n",
    "\n",
    "        # Initialize global model state on CPU/GPU\n",
    "        global_model = self.model_class(**self.model_args).to(self.device)\n",
    "        self.global_model_state = deepcopy(global_model.state_dict())  # Initialize global model state\n",
    "\n",
    "        print(\"Starting Federated Learning...\")\n",
    "        # Run federated learning\n",
    "        self.federated_learning(self.global_model_state, max_parallel_edge_servers=1)\n",
    "\n",
    "        # Evaluate final global model (Optional: Remove if federated_learning already does)\n",
    "        # If you want to evaluate the final model again, keep it. Otherwise, remove.\n",
    "        # final_accuracy = self.evaluate_model(self.global_model_state, self.get_test_loader())\n",
    "        # print(f\"Final Global Model Accuracy: {final_accuracy:.2f}%\")\n",
    "\n",
    "        # Save the accuracies to JSON\n",
    "        with open(self.metrics_file.replace('.json', '_accuracies.json'), 'w') as json_file:\n",
    "            json.dump(self.accuracies, json_file, indent=4)\n",
    "\n",
    "        # Save summary metrics\n",
    "        self.save_summary_metrics(self.metrics_file.replace('.json', '_full_metrics.json'))\n",
    "\n",
    "        # After training, consolidate metrics into a single dictionary\n",
    "        metrics_summary = {\n",
    "            \"Energy Consumption\": self.energy_consumption,\n",
    "            \"Time Delays\": self.time_delays,\n",
    "            \"Bandwidth Usage\": self.bandwidth_usage,\n",
    "        }\n",
    "\n",
    "        # Save metrics to a JSON file\n",
    "        with open(self.metrics_file.replace('.json', '_summary.json'), 'w') as f:\n",
    "            json.dump(metrics_summary, f, indent=4)\n",
    "\n",
    "    def get_test_loader(self):\n",
    "        \"\"\"\n",
    "        Create a DataLoader for the test dataset.\n",
    "        \"\"\"\n",
    "        test_dataset = TensorDataset(\n",
    "            torch.tensor(self.test_images, dtype=torch.float32),\n",
    "            torch.tensor(self.test_labels, dtype=torch.long)\n",
    "        )\n",
    "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "        return test_loader\n",
    "\n",
    "    def prepare_data_loader(self, images, labels, batch_size):\n",
    "        \"\"\"\n",
    "        Prepare DataLoader with correct tensor types.\n",
    "\n",
    "        Args:\n",
    "            images (numpy array or similar): Input images.\n",
    "            labels (numpy array or similar): Corresponding labels.\n",
    "            batch_size (int): Batch size.\n",
    "\n",
    "        Returns:\n",
    "            DataLoader: Prepared DataLoader.\n",
    "        \"\"\"\n",
    "        tensor_dataset = TensorDataset(\n",
    "            torch.tensor(images, dtype=torch.float32),  # Ensure images are float\n",
    "            torch.tensor(labels, dtype=torch.long)       # Labels should be long\n",
    "        )\n",
    "        loader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=True)\n",
    "        return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a24ca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MainAgent:\n",
    "    def __init__(self, devices_df, num_edge_servers, metrics_file, cluster_to_server_map):\n",
    "        self.devices_df = devices_df.reset_index(drop=True)\n",
    "        self.num_edge_servers = num_edge_servers\n",
    "        self.cluster_to_server_map = cluster_to_server_map  # Pass cluster-to-server map\n",
    "\n",
    "        # Prepare data for cluster assignment\n",
    "        self.cluster_bandwidth = self.devices_df.groupby('cluster')['bandwidth'].sum().values\n",
    "        self.edge_server_capacities = self.generate_edge_server_capacities()\n",
    "\n",
    "        # Create environments\n",
    "        self.cluster_env = ClusterAssignmentEnv(self.cluster_bandwidth, self.edge_server_capacities, devices_df=self.devices_df)\n",
    "        self.scheduling_env = DeviceSchedulingEnv(self.devices_df, self.cluster_to_server_map)  # Pass map\n",
    "\n",
    "        # Load trained sub-agents\n",
    "        self.cluster_agent = PPO.load(metrics_file.replace('.json', '') + \"_cluster_assignment_agent\")\n",
    "        self.scheduling_agent = PPO.load(metrics_file.replace('.json', '') + \"_device_scheduling_agent\")\n",
    "\n",
    "        self.accuracies = {\n",
    "            'local_epochs': {},       # Store local epoch accuracies\n",
    "            'edge_iterations': {},    # Store edge iteration accuracies\n",
    "            'global_iterations': []   # Store global iteration accuracies\n",
    "        }\n",
    "\n",
    "    def generate_edge_server_capacities(self):\n",
    "        max_cluster_bandwidth = self.cluster_bandwidth.max()\n",
    "        total_bandwidth_needed = self.cluster_bandwidth.sum()\n",
    "        base_capacity = max(total_bandwidth_needed / self.num_edge_servers, max_cluster_bandwidth)\n",
    "\n",
    "        # Ensure a minimum capacity to prevent zero-capacity servers\n",
    "        min_capacity = base_capacity * 0.8\n",
    "        max_capacity = base_capacity * 1.6\n",
    "\n",
    "        edge_server_capacities = np.random.uniform(\n",
    "            min_capacity,\n",
    "            max_capacity,\n",
    "            size=self.num_edge_servers\n",
    "        )\n",
    "        edge_server_capacities = np.round(edge_server_capacities).astype(int)\n",
    "\n",
    "        # Ensure no server has zero capacity\n",
    "        edge_server_capacities = np.maximum(edge_server_capacities, 1)\n",
    "        return edge_server_capacities\n",
    "\n",
    "    def run(self, federated_system_params):\n",
    "        \"\"\"\n",
    "        Executes cluster assignment and device scheduling, updates `devices_df`,\n",
    "        and integrates it into the Federated Learning System.\n",
    "        \"\"\"\n",
    "        print(\"Running Cluster Assignment and Device Scheduling Agents...\")\n",
    "\n",
    "        # Cluster Assignment\n",
    "        cluster_state = self.cluster_env.reset()\n",
    "        cluster_action, _ = self.cluster_agent.predict(cluster_state)\n",
    "        assignments = dict(zip(range(self.cluster_env.num_clusters), cluster_action))\n",
    "        self.devices_df['assigned_servers'] = self.devices_df['cluster'].map(assignments)\n",
    "\n",
    "        # Evaluate Cluster Assignment\n",
    "        cluster_metrics = self.cluster_env.evaluate(assignments)\n",
    "        print(f\"Cluster Assignment Evaluation Metrics: {cluster_metrics}\")\n",
    "        with open(federated_system_params['metrics_file'].replace('.json', '_cluster_assignment_evaluation.json'), 'w') as f:\n",
    "            json.dump(cluster_metrics, f, indent=4)\n",
    "\n",
    "        # Device Scheduling\n",
    "        scheduling_state = self.scheduling_env.reset()\n",
    "        scheduling_action, _ = self.scheduling_agent.predict(scheduling_state)\n",
    "        scheduled_devices = [i for i, a in enumerate(scheduling_action) if a == 1]\n",
    "        self.devices_df['is_scheduled'] = False\n",
    "        self.devices_df.loc[scheduled_devices, 'is_scheduled'] = True\n",
    "\n",
    "        # Evaluate Device Scheduling\n",
    "        scheduling_metrics = self.scheduling_env.evaluate(scheduling_action)\n",
    "        print(f\"Device Scheduling Evaluation Metrics: {scheduling_metrics}\")\n",
    "        with open(federated_system_params['metrics_file'].replace('.json', '_device_scheduling_evaluation.json'), 'w') as f:\n",
    "            json.dump(scheduling_metrics, f, indent=4)\n",
    "\n",
    "        print(\"Updated `devices_df` with assignments and scheduling information.\")\n",
    "\n",
    "        # Prepare parameters for the FederatedLearningSystem\n",
    "        filtered_params = {\n",
    "            k: v for k, v in federated_system_params.items()\n",
    "            if k not in ['test_images', 'test_labels', 'dataset_name', 'metrics_file']\n",
    "        }\n",
    "\n",
    "        # Create the FederatedLearningSystem\n",
    "        federated_system = FederatedLearningSystem(\n",
    "            devices_df=self.devices_df,\n",
    "            test_images=federated_system_params['test_images'],\n",
    "            test_labels=federated_system_params['test_labels'],\n",
    "            dataset_name=federated_system_params['dataset_name'],\n",
    "            metrics_file=federated_system_params['metrics_file'],\n",
    "            cluster_agent=self.cluster_agent,\n",
    "            scheduling_agent=self.scheduling_agent,\n",
    "            cluster_env=self.cluster_env,\n",
    "            scheduling_env=self.scheduling_env,\n",
    "            **filtered_params\n",
    "        )\n",
    "\n",
    "        # Run federated learning\n",
    "        print(\"Starting Federated Learning...\")\n",
    "        federated_system.main(\n",
    "            global_iterations=federated_system_params['global_iterations'],\n",
    "            edge_iterations=federated_system_params['edge_iterations'],\n",
    "            local_epochs=federated_system_params['local_epochs']\n",
    "        )\n",
    "        print(\"Federated Learning completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fef0755-3dff-4511-80e1-d12e57737566",
   "metadata": {},
   "source": [
    "# Excution Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be1de76-b64e-43b8-8b5b-a1e8e15dddec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example dynamic usage\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    gc.collect()    \n",
    "\n",
    "    # Set parameters dynamically for experimentation\n",
    "    configurations = [\n",
    "        {\"mfactor\": 7, \"dataset_name\": \"mnist\", \"edge_num\": 5, \"num_devices\": 20, \"global_iterations\": 10, \"edge_server_iterations\": 3, \"local_epochs\": 5, \"pr_data_redist\": 0.7}, \n",
    "        # {\"mfactor\": 5, \"dataset_name\": \"mnist\", \"edge_num\": 5, \"num_devices\": 30, \"global_iterations\": 10, \"edge_server_iterations\": 5, \"local_epochs\": 5},\n",
    "        # {\"mfactor\": 5, \"dataset_name\": \"mnist\", \"edge_num\": 5, \"num_devices\": 50, \"global_iterations\": 10, \"edge_server_iterations\": 5, \"local_epochs\": 5},\n",
    "        # {\"mfactor\": 5, \"dataset_name\": \"mnist\", \"edge_num\": 5, \"num_devices\": 70, \"global_iterations\": 10, \"edge_server_iterations\": 5, \"local_epochs\": 5},\n",
    "        # {\"mfactor\": 5, \"dataset_name\": \"mnist\", \"edge_num\": 5, \"num_devices\": 100, \"global_iterations\": 10, \"edge_server_iterations\": 5, \"local_epochs\": 5},\n",
    "        \n",
    "        {\"mfactor\": 7, \"dataset_name\": \"fashion_mnist\", \"edge_num\": 5, \"num_devices\": 20, \"global_iterations\": 10, \"edge_server_iterations\": 3, \"local_epochs\": 5, \"pr_data_redist\": 0.7},\n",
    "        # {\"mfactor\": 5, \"dataset_name\": \"fashion_mnist\", \"edge_num\": 5, \"num_devices\": 30, \"global_iterations\": 10, \"edge_server_iterations\": 5, \"local_epochs\": 5},\n",
    "        # {\"mfactor\": 5, \"dataset_name\": \"fashion_mnist\", \"edge_num\": 5, \"num_devices\": 50, \"global_iterations\": 10, \"edge_server_iterations\": 5, \"local_epochs\": 5},\n",
    "        # {\"mfactor\": 5, \"dataset_name\": \"fashion_mnist\", \"edge_num\": 5, \"num_devices\": 70, \"global_iterations\": 10, \"edge_server_iterations\": 5, \"local_epochs\": 5},\n",
    "        # {\"mfactor\": 5, \"dataset_name\": \"fashion_mnist\", \"edge_num\": 5, \"num_devices\": 100, \"global_iterations\": 10, \"edge_server_iterations\": 5, \"local_epochs\": 5},\n",
    "        \n",
    "        {\"mfactor\": 7, \"dataset_name\": \"cifar10\", \"edge_num\": 5, \"num_devices\": 20, \"global_iterations\": 10, \"edge_server_iterations\": 3, \"local_epochs\": 5, \"pr_data_redist\": 0.7},\n",
    "        # {\"mfactor\": 5, \"dataset_name\": \"cifar10\", \"edge_num\": 5, \"num_devices\": 30, \"global_iterations\": 10, \"edge_server_iterations\": 5, \"local_epochs\": 5},\n",
    "        # {\"mfactor\": 5, \"dataset_name\": \"cifar10\", \"edge_num\": 5, \"num_devices\": 50, \"global_iterations\": 10, \"edge_server_iterations\": 5, \"local_epochs\": 5},\n",
    "        # {\"mfactor\": 5, \"dataset_name\": \"cifar10\", \"edge_num\": 5, \"num_devices\": 70, \"global_iterations\": 10, \"edge_server_iterations\": 5, \"local_epochs\": 5},\n",
    "        # {\"mfactor\": 5, \"dataset_name\": \"cifar10\", \"edge_num\": 5, \"num_devices\": 100, \"global_iterations\": 10, \"edge_server_iterations\": 5, \"local_epochs\": 5}           \n",
    "    ]\n",
    "    \n",
    "    # Create a folder to store metric files\n",
    "    metrics_dir = \"metrics\"\n",
    "    os.makedirs(metrics_dir, exist_ok=True)\n",
    "    print(f\"Metrics will be stored in the directory: {metrics_dir}\")\n",
    "\n",
    "    for config in configurations:\n",
    "        print(f\"\\nRunning configuration: {config}\")\n",
    "\n",
    "        # Construct the metrics file path\n",
    "        metrics_file = os.path.join(\n",
    "            metrics_dir,\n",
    "            \"{}_{}_global_{}_edge_{}_local.json\".format(\n",
    "                config[\"dataset_name\"], \n",
    "                config[\"global_iterations\"], \n",
    "                config[\"edge_server_iterations\"], \n",
    "                config[\"local_epochs\"]\n",
    "            )\n",
    "        )    \n",
    "\n",
    "        # Initialize the data distributor with 5 edge servers\n",
    "        data_distributor = GNNClustering(num_devices=config[\"num_devices\"], \n",
    "                                        dataset_name=config[\"dataset_name\"], \n",
    "                                        mfactor=config[\"mfactor\"], \n",
    "                                        num_edge_servers=config[\"edge_num\"],\n",
    "                                        metrics_file=metrics_file)\n",
    "\n",
    "        # Distribute data and perform clustering\n",
    "        test_images, test_labels = data_distributor.distribute_data()\n",
    "\n",
    "        # Distribute data and perform clustering\n",
    "        devices_df = data_distributor.clustering_devices()\n",
    "\n",
    "        # Compare clustering methods\n",
    "        # data_distributor.compare_clustering_methods()\n",
    "\n",
    "        # Initialize the hybrid data redistributor\n",
    "        data_redistributor = HybridDataRedistributor(devices_df, \n",
    "                                                    dataset_name=config[\"dataset_name\"],\n",
    "                                                    metrics_file=metrics_file)\n",
    "\n",
    "        # Perform hybrid data redistribution\n",
    "        devices_df, label_presence = data_redistributor.redistribute_data(percentage_threshold=config[\"pr_data_redist\"])\n",
    "\n",
    "        # Prepare cluster bandwidth and edge server capacities for training the cluster assignment agent\n",
    "        cluster_bandwidth_series = devices_df.groupby('cluster')['bandwidth'].sum()\n",
    "        cluster_bandwidth = cluster_bandwidth_series.values\n",
    "        num_edge_servers = devices_df['cluster'].nunique()\n",
    "\n",
    "        print(f\"\\nNumber of Edge Servers (Clusters): {num_edge_servers}\")\n",
    "        print(f\"Cluster Bandwidths: {cluster_bandwidth_series.to_dict()}\")\n",
    "\n",
    "        # Calculate edge server capacities based on cluster bandwidths\n",
    "        max_cluster_bandwidth = cluster_bandwidth.max()\n",
    "        total_bandwidth_needed = cluster_bandwidth.sum()\n",
    "        base_capacity = max(total_bandwidth_needed / num_edge_servers, max_cluster_bandwidth)\n",
    "        edge_server_capacities = np.random.uniform(\n",
    "            base_capacity * 0.8,\n",
    "            base_capacity * 1.6,\n",
    "            size=num_edge_servers\n",
    "        )\n",
    "        edge_server_capacities = np.round(edge_server_capacities).astype(int)\n",
    "\n",
    "        print(f\"Edge Server Capacities: {edge_server_capacities}\")\n",
    "\n",
    "        # Train the cluster assignment agent and generate the cluster-to-server map\n",
    "        cluster_model = train_cluster_assignment_agent(\n",
    "            cluster_bandwidth, \n",
    "            edge_server_capacities, \n",
    "            devices_df, \n",
    "            timesteps=10000, \n",
    "            metrics_file=metrics_file\n",
    "        )\n",
    "\n",
    "        # Retrieve the cluster-to-server assignments\n",
    "        cluster_state = ClusterAssignmentEnv(cluster_bandwidth, edge_server_capacities, devices_df).reset()\n",
    "        cluster_action, _ = cluster_model.predict(cluster_state)\n",
    "        cluster_to_server_map = {cluster: server for cluster, server in enumerate(cluster_action)}\n",
    "\n",
    "        print(f\"Cluster-to-Server Map: {cluster_to_server_map}\")\n",
    "\n",
    "        # Train the device scheduling agent with the cluster-to-server map\n",
    "        scheduling_model = train_device_scheduling_agent(\n",
    "            devices_df, \n",
    "            timesteps=10000, \n",
    "            metrics_file=metrics_file, \n",
    "            cluster_to_server_map=cluster_to_server_map\n",
    "        )\n",
    "\n",
    "        # Initialize the main agent\n",
    "        main_agent = MainAgent(\n",
    "            devices_df, \n",
    "            config[\"edge_num\"], \n",
    "            metrics_file, \n",
    "            cluster_to_server_map\n",
    "        )\n",
    "\n",
    "        # Parameters for federated learning\n",
    "        federated_system_params = {\n",
    "            'test_images': test_images,\n",
    "            'test_labels': test_labels,\n",
    "            'dataset_name': config[\"dataset_name\"],\n",
    "            'metrics_file': metrics_file,\n",
    "            'global_iterations': config[\"global_iterations\"],\n",
    "            'edge_iterations': config[\"edge_server_iterations\"],\n",
    "            'local_epochs': config[\"local_epochs\"],\n",
    "            'input_channels': 1,\n",
    "            'num_classes': 10\n",
    "        }\n",
    "\n",
    "        # Run the main agent\n",
    "        main_agent.run(federated_system_params)\n",
    "\n",
    "        print(f\"Configuration {config} completed.\\n\")\n",
    "\n",
    "        gc.collect()  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
